{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5462cdcb",
   "metadata": {},
   "source": [
    "# üöÄ HIGH-LEVEL DESIGN (HLD) MASTERY NOTEBOOK\n",
    "\n",
    "## üéØ **SYSTEM ARCHITECTURE EXCELLENCE - YOUR PATH TO SENIOR+ ROLES!**\n",
    "\n",
    "### üî• What You'll Master:\n",
    "- **Distributed Systems Architecture** - Scale to millions of users\n",
    "- **Microservices Design** - Build resilient, maintainable systems\n",
    "- **Database Design** - SQL vs NoSQL, sharding, replication\n",
    "- **Caching Strategies** - Redis, Memcached, CDN optimization\n",
    "- **Load Balancing** - Horizontal scaling techniques\n",
    "- **Message Queues** - Async processing, event-driven architecture\n",
    "- **API Design** - REST, GraphQL, gRPC best practices\n",
    "- **Security** - Authentication, authorization, encryption\n",
    "- **Monitoring** - Observability, logging, metrics\n",
    "- **Cloud Architecture** - AWS, Azure, GCP patterns\n",
    "\n",
    "### üí∞ **CAREER TRANSFORMATION:**\n",
    "- **üìà $50K+ salary increase** potential for senior engineers\n",
    "- **üéØ System Design interviews** - Pass FAANG/unicorn companies\n",
    "- **üèÜ Technical leadership** - Lead architecture decisions\n",
    "- **üöÄ Principal Engineer** - Design systems for millions\n",
    "- **üíº Engineering Manager** - Technical strategy and vision\n",
    "\n",
    "### üé™ **Real-World Systems You'll Design:**\n",
    "- Social Media Platform (Instagram/Twitter scale)\n",
    "- Video Streaming Service (Netflix/YouTube)\n",
    "- E-commerce Platform (Amazon/eBay)\n",
    "- Chat Application (WhatsApp/Slack)\n",
    "- Ride-sharing Service (Uber/Lyft)\n",
    "- Search Engine (Google scale)\n",
    "- Payment System (PayPal/Stripe)\n",
    "\n",
    "---\n",
    "\n",
    "### üîß **Technologies Covered:**\n",
    "```\n",
    "Databases:     PostgreSQL, MongoDB, Cassandra, DynamoDB\n",
    "Caching:       Redis, Memcached, CloudFront, CDN\n",
    "Message Queue: Kafka, RabbitMQ, SQS, Pub/Sub\n",
    "Load Balancer: NGINX, HAProxy, AWS ALB, Cloudflare\n",
    "Monitoring:    Prometheus, Grafana, ELK Stack, Datadog\n",
    "Cloud:         AWS, Azure, GCP, Kubernetes, Docker\n",
    "```\n",
    "\n",
    "### üìö **Learning Path:**\n",
    "1. **Fundamentals** - Scalability, reliability, consistency\n",
    "2. **Components** - Databases, caches, load balancers\n",
    "3. **Patterns** - Microservices, event-driven, CQRS\n",
    "4. **Real Systems** - End-to-end design challenges\n",
    "5. **Advanced Topics** - Consistency, CAP theorem, consensus\n",
    "\n",
    "### üéØ **Interview Success Formula:**\n",
    "```\n",
    "‚úÖ Requirements Gathering (5 min)\n",
    "‚úÖ Capacity Estimation (5 min)\n",
    "‚úÖ High-Level Design (15 min)\n",
    "‚úÖ Detailed Design (15 min)\n",
    "‚úÖ Scale & Optimize (15 min)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Ready to become a system design expert? Let's build systems that scale!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64619003",
   "metadata": {},
   "source": [
    "## Chapter 1: System Design Fundamentals ‚≠ê‚≠ê‚≠ê\n",
    "> **The Foundation** - Master these concepts to design systems that scale to millions\n",
    "\n",
    "### üéØ Core Concepts:\n",
    "- **Scalability**: Handle increasing load gracefully\n",
    "- **Reliability**: System continues working despite failures\n",
    "- **Availability**: System remains operational over time\n",
    "- **Consistency**: All nodes see the same data simultaneously\n",
    "- **Partition Tolerance**: System continues despite network failures\n",
    "\n",
    "### üöÄ Key Principles:\n",
    "- **Horizontal vs Vertical Scaling**\n",
    "- **Load Distribution Strategies** \n",
    "- **Data Partitioning Techniques**\n",
    "- **Caching Mechanisms**\n",
    "- **Database Design Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM DESIGN FUNDAMENTALS - SCALE TO MILLIONS!\n",
    "\n",
    "print(\"üéØ SYSTEM DESIGN FUNDAMENTALS - CAREER TRANSFORMATION!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import math\n",
    "from typing import Dict, List, Tuple\n",
    "from enum import Enum\n",
    "\n",
    "# ===============================================================\n",
    "# 1. SCALABILITY CONCEPTS - Handle Growing Load\n",
    "# ===============================================================\n",
    "print(\"\\nüî• 1. SCALABILITY - HANDLE MILLIONS OF USERS\")\n",
    "print(\"The ability to handle increased load gracefully\")\n",
    "\n",
    "class ScalingType(Enum):\n",
    "    VERTICAL = \"vertical\"    # Scale UP - bigger machine\n",
    "    HORIZONTAL = \"horizontal\"  # Scale OUT - more machines\n",
    "\n",
    "class LoadCalculator:\n",
    "    \"\"\"Calculate system capacity and scaling needs\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_servers_needed(requests_per_second: int, server_capacity: int) -> int:\n",
    "        \"\"\"Calculate number of servers needed for given RPS\"\"\"\n",
    "        return math.ceil(requests_per_second / server_capacity)\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_storage_needed(users: int, data_per_user_mb: float) -> Tuple[float, str]:\n",
    "        \"\"\"Calculate storage needs in TB\"\"\"\n",
    "        total_mb = users * data_per_user_mb\n",
    "        total_gb = total_mb / 1024\n",
    "        total_tb = total_gb / 1024\n",
    "        \n",
    "        if total_tb < 1:\n",
    "            return total_gb, \"GB\"\n",
    "        else:\n",
    "            return total_tb, \"TB\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_bandwidth(requests_per_second: int, avg_response_kb: float) -> float:\n",
    "        \"\"\"Calculate bandwidth needed in Mbps\"\"\"\n",
    "        kb_per_second = requests_per_second * avg_response_kb\n",
    "        mb_per_second = kb_per_second / 1024\n",
    "        mbps = mb_per_second * 8  # Convert to bits per second\n",
    "        return mbps\n",
    "\n",
    "# Demonstrate scaling calculations\n",
    "print(\"\\nüìä SCALING CALCULATIONS:\")\n",
    "print(\"Scenario: Social Media Platform\")\n",
    "\n",
    "# User load estimation\n",
    "daily_active_users = 10_000_000  # 10M DAU\n",
    "peak_concurrent_users = daily_active_users * 0.1  # 10% concurrent peak\n",
    "requests_per_user_per_minute = 2\n",
    "peak_rps = int((peak_concurrent_users * requests_per_user_per_minute) / 60)\n",
    "\n",
    "print(f\"  Daily Active Users: {daily_active_users:,}\")\n",
    "print(f\"  Peak Concurrent Users: {peak_concurrent_users:,}\")\n",
    "print(f\"  Peak Requests/Second: {peak_rps:,}\")\n",
    "\n",
    "# Server capacity planning\n",
    "server_capacity_rps = 1000  # Each server handles 1000 RPS\n",
    "servers_needed = LoadCalculator.estimate_servers_needed(peak_rps, server_capacity_rps)\n",
    "print(f\"  Servers Needed: {servers_needed}\")\n",
    "\n",
    "# Storage estimation\n",
    "data_per_user_mb = 50  # 50MB per user (posts, images, metadata)\n",
    "storage, unit = LoadCalculator.estimate_storage_needed(daily_active_users, data_per_user_mb)\n",
    "print(f\"  Storage Required: {storage:.2f} {unit}\")\n",
    "\n",
    "# Bandwidth calculation\n",
    "avg_response_kb = 100  # 100KB average response\n",
    "bandwidth_mbps = LoadCalculator.estimate_bandwidth(peak_rps, avg_response_kb)\n",
    "print(f\"  Bandwidth Required: {bandwidth_mbps:.2f} Mbps\")\n",
    "\n",
    "# ===============================================================\n",
    "# 2. CAP THEOREM - The Fundamental Trade-off\n",
    "# ===============================================================\n",
    "print(\"\\n\\nüî• 2. CAP THEOREM - CHOOSE YOUR TRADE-OFFS\")\n",
    "print(\"You can only guarantee 2 out of 3: Consistency, Availability, Partition Tolerance\")\n",
    "\n",
    "class CAPChoice(Enum):\n",
    "    CP = \"CP\"  # Consistency + Partition Tolerance (sacrifice Availability)\n",
    "    AP = \"AP\"  # Availability + Partition Tolerance (sacrifice Consistency)\n",
    "    CA = \"CA\"  # Consistency + Availability (sacrifice Partition Tolerance - single node only)\n",
    "\n",
    "class SystemExample:\n",
    "    def __init__(self, name: str, cap_choice: CAPChoice, use_case: str, trade_off: str):\n",
    "        self.name = name\n",
    "        self.cap_choice = cap_choice\n",
    "        self.use_case = use_case\n",
    "        self.trade_off = trade_off\n",
    "\n",
    "# Real-world CAP theorem examples\n",
    "cap_examples = [\n",
    "    SystemExample(\n",
    "        \"Banking System\", \n",
    "        CAPChoice.CP,\n",
    "        \"Financial transactions, account balances\",\n",
    "        \"System goes down rather than show wrong balance\"\n",
    "    ),\n",
    "    SystemExample(\n",
    "        \"Social Media Feed\", \n",
    "        CAPChoice.AP,\n",
    "        \"Facebook/Twitter timeline, likes, comments\",\n",
    "        \"Show slightly stale data rather than error page\"\n",
    "    ),\n",
    "    SystemExample(\n",
    "        \"Traditional RDBMS\", \n",
    "        CAPChoice.CA,\n",
    "        \"Single-node PostgreSQL/MySQL\",\n",
    "        \"Perfect consistency until network partitions occur\"\n",
    "    ),\n",
    "    SystemExample(\n",
    "        \"DNS System\", \n",
    "        CAPChoice.AP,\n",
    "        \"Domain name resolution\",\n",
    "        \"Always available, eventual consistency is fine\"\n",
    "    ),\n",
    "    SystemExample(\n",
    "        \"MongoDB (default)\", \n",
    "        CAPChoice.CP,\n",
    "        \"Document database with strong consistency\",\n",
    "        \"Becomes read-only if can't reach majority of nodes\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\nüìö REAL-WORLD CAP EXAMPLES:\")\n",
    "for example in cap_examples:\n",
    "    print(f\"  {example.name} ({example.cap_choice.value}):\")\n",
    "    print(f\"    Use Case: {example.use_case}\")\n",
    "    print(f\"    Trade-off: {example.trade_off}\")\n",
    "    print()\n",
    "\n",
    "# ===============================================================\n",
    "# 3. CONSISTENCY MODELS - Data Consistency Patterns\n",
    "# ===============================================================\n",
    "print(\"\\nüî• 3. CONSISTENCY MODELS - DATA SYNCHRONIZATION\")\n",
    "print(\"Different levels of data consistency across distributed systems\")\n",
    "\n",
    "class ConsistencyLevel(Enum):\n",
    "    STRONG = \"strong\"           # All nodes have same data immediately\n",
    "    EVENTUAL = \"eventual\"       # All nodes will eventually have same data\n",
    "    WEAK = \"weak\"              # No guarantees about when data will be consistent\n",
    "    CAUSAL = \"causal\"          # Causally related operations are seen in order\n",
    "\n",
    "class ConsistencyExample:\n",
    "    def __init__(self, level: ConsistencyLevel, description: str, use_case: str, latency: str):\n",
    "        self.level = level\n",
    "        self.description = description\n",
    "        self.use_case = use_case\n",
    "        self.latency = latency\n",
    "\n",
    "consistency_examples = [\n",
    "    ConsistencyExample(\n",
    "        ConsistencyLevel.STRONG,\n",
    "        \"All reads receive the most recent write immediately\",\n",
    "        \"Banking transactions, inventory management\",\n",
    "        \"High latency, lower availability\"\n",
    "    ),\n",
    "    ConsistencyExample(\n",
    "        ConsistencyLevel.EVENTUAL,\n",
    "        \"System will become consistent over time\",\n",
    "        \"Social media feeds, DNS updates, email delivery\",\n",
    "        \"Low latency, high availability\"\n",
    "    ),\n",
    "    ConsistencyExample(\n",
    "        ConsistencyLevel.WEAK,\n",
    "        \"No guarantees about consistency timing\",\n",
    "        \"Real-time gaming, live streaming metrics\",\n",
    "        \"Very low latency\"\n",
    "    ),\n",
    "    ConsistencyExample(\n",
    "        ConsistencyLevel.CAUSAL,\n",
    "        \"Related operations are seen in correct order\",\n",
    "        \"Chat applications, collaborative editing\",\n",
    "        \"Moderate latency\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\nüìä CONSISTENCY MODELS:\")\n",
    "for example in consistency_examples:\n",
    "    print(f\"  {example.level.value.upper()} CONSISTENCY:\")\n",
    "    print(f\"    Definition: {example.description}\")\n",
    "    print(f\"    Use Case: {example.use_case}\")\n",
    "    print(f\"    Trade-off: {example.latency}\")\n",
    "    print()\n",
    "\n",
    "# ===============================================================\n",
    "# 4. PARTITIONING STRATEGIES - Divide and Conquer Data\n",
    "# ===============================================================\n",
    "print(\"\\nüî• 4. DATA PARTITIONING - DIVIDE TO SCALE\")\n",
    "print(\"Split large datasets across multiple machines\")\n",
    "\n",
    "class PartitionStrategy(Enum):\n",
    "    HORIZONTAL = \"horizontal\"   # Sharding - split rows\n",
    "    VERTICAL = \"vertical\"       # Split columns/tables\n",
    "    FUNCTIONAL = \"functional\"   # Split by feature/service\n",
    "\n",
    "class PartitioningCalculator:\n",
    "    @staticmethod\n",
    "    def hash_partition(user_id: int, num_shards: int) -> int:\n",
    "        \"\"\"Simple hash-based partitioning\"\"\"\n",
    "        return user_id % num_shards\n",
    "    \n",
    "    @staticmethod\n",
    "    def range_partition(user_id: int, ranges: List[Tuple[int, int]]) -> int:\n",
    "        \"\"\"Range-based partitioning\"\"\"\n",
    "        for i, (start, end) in enumerate(ranges):\n",
    "            if start <= user_id <= end:\n",
    "                return i\n",
    "        return -1  # Not found\n",
    "    \n",
    "    @staticmethod\n",
    "    def consistent_hash_partition(key: str, num_virtual_nodes: int = 100) -> int:\n",
    "        \"\"\"Simplified consistent hashing\"\"\"\n",
    "        hash_value = hash(key) % (num_virtual_nodes * 1000)\n",
    "        return hash_value % num_virtual_nodes\n",
    "\n",
    "# Demonstrate partitioning strategies\n",
    "print(\"\\nüìä PARTITIONING EXAMPLES:\")\n",
    "\n",
    "# Hash partitioning example\n",
    "num_shards = 4\n",
    "sample_user_ids = [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008]\n",
    "\n",
    "print(\"  HASH PARTITIONING:\")\n",
    "for user_id in sample_user_ids:\n",
    "    shard = PartitioningCalculator.hash_partition(user_id, num_shards)\n",
    "    print(f\"    User {user_id} ‚Üí Shard {shard}\")\n",
    "\n",
    "# Range partitioning example\n",
    "ranges = [(1, 2500), (2501, 5000), (5001, 7500), (7501, 10000)]\n",
    "print(\"\\n  RANGE PARTITIONING:\")\n",
    "test_users = [1500, 3000, 6000, 8500]\n",
    "for user_id in test_users:\n",
    "    shard = PartitioningCalculator.range_partition(user_id, ranges)\n",
    "    print(f\"    User {user_id} ‚Üí Shard {shard}\")\n",
    "\n",
    "# ===============================================================\n",
    "# 5. REPLICATION STRATEGIES - Data Redundancy for Reliability\n",
    "# ===============================================================\n",
    "print(\"\\n\\nüî• 5. REPLICATION - RELIABILITY & PERFORMANCE\")\n",
    "print(\"Keep multiple copies of data for fault tolerance and faster reads\")\n",
    "\n",
    "class ReplicationType(Enum):\n",
    "    MASTER_SLAVE = \"master_slave\"     # One writer, multiple readers\n",
    "    MASTER_MASTER = \"master_master\"   # Multiple writers\n",
    "    PEER_TO_PEER = \"peer_to_peer\"     # No distinguished master\n",
    "\n",
    "class ReplicationExample:\n",
    "    def __init__(self, type_: ReplicationType, pros: List[str], cons: List[str], use_case: str):\n",
    "        self.type = type_\n",
    "        self.pros = pros\n",
    "        self.cons = cons\n",
    "        self.use_case = use_case\n",
    "\n",
    "replication_strategies = [\n",
    "    ReplicationExample(\n",
    "        ReplicationType.MASTER_SLAVE,\n",
    "        [\"Simple to implement\", \"Strong consistency\", \"Clear data flow\"],\n",
    "        [\"Single point of failure\", \"Write bottleneck\", \"Read-only slaves\"],\n",
    "        \"Traditional databases, read-heavy workloads\"\n",
    "    ),\n",
    "    ReplicationExample(\n",
    "        ReplicationType.MASTER_MASTER,\n",
    "        [\"High availability\", \"Write scalability\", \"Load distribution\"],\n",
    "        [\"Conflict resolution needed\", \"Complex synchronization\", \"Consistency challenges\"],\n",
    "        \"Global applications, high-write workloads\"\n",
    "    ),\n",
    "    ReplicationExample(\n",
    "        ReplicationType.PEER_TO_PEER,\n",
    "        [\"Highly available\", \"Decentralized\", \"Fault tolerant\"],\n",
    "        [\"Complex consensus\", \"Network overhead\", \"Eventual consistency\"],\n",
    "        \"Blockchain, distributed file systems\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\nüìä REPLICATION STRATEGIES:\")\n",
    "for strategy in replication_strategies:\n",
    "    print(f\"  {strategy.type.value.upper().replace('_', '-')}:\")\n",
    "    print(f\"    Pros: {', '.join(strategy.pros)}\")\n",
    "    print(f\"    Cons: {', '.join(strategy.cons)}\")\n",
    "    print(f\"    Use Case: {strategy.use_case}\")\n",
    "    print()\n",
    "\n",
    "# ===============================================================\n",
    "# SYSTEM DESIGN FUNDAMENTALS SUMMARY\n",
    "# ===============================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"üèÜ SYSTEM DESIGN FUNDAMENTALS MASTERY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fundamentals = {\n",
    "    \"Scalability\": \"Design systems that grow with demand\",\n",
    "    \"CAP Theorem\": \"Understand trade-offs in distributed systems\",\n",
    "    \"Consistency\": \"Choose appropriate data consistency model\",\n",
    "    \"Partitioning\": \"Split data to scale beyond single machine\",\n",
    "    \"Replication\": \"Ensure availability and fault tolerance\"\n",
    "}\n",
    "\n",
    "print(\"\\nüìö CONCEPTS MASTERED:\")\n",
    "for concept, description in fundamentals.items():\n",
    "    print(f\"‚úÖ {concept}: {description}\")\n",
    "\n",
    "print(\"\\nüíº INTERVIEW IMPACT:\")\n",
    "print(\"üèÜ Foundation for all system design questions\")\n",
    "print(\"üèÜ Demonstrates understanding of trade-offs\")\n",
    "print(\"üèÜ Shows ability to design scalable systems\")\n",
    "print(\"üèÜ Required for senior+ engineering roles\")\n",
    "print(\"üèÜ Gateway to system architect positions\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"‚úÖ Master these fundamentals before diving into specific components\")\n",
    "print(\"‚úÖ Practice applying these concepts to real-world scenarios\")\n",
    "print(\"‚úÖ Study how major tech companies implement these patterns\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
