{"id":"terraform-guide","title":"üèóÔ∏è Terraform Complete Mastery","content":"# üöÄ Terraform Complete Mastery Guide\n**The Ultimate Zero to Hero Course - Everything You Need to Know**\n\n> **Complete standalone guide covering every Terraform concept, feature, and best practice**  \n> *From absolute beginner to production-ready expert*\n\n---\n\n## üìö Table of Contents\n\n### **PART 1: FOUNDATIONS** \n- [Day 1: What is Terraform?](#day-1-what-is-terraform)\n- [Day 1: Installation & Setup](#day-1-installation--setup)\n- [Day 2: First Project](#day-2-your-first-project)\n- [Day 2: Terraform Workflow](#day-2-terraform-workflow)\n- [Day 3: HCL Language Basics](#day-3-hcl-language-basics)\n\n### **PART 2: CORE CONCEPTS**\n- [Day 4: Providers Deep Dive](#day-4-providers-deep-dive)\n- [Day 4: Resources](#day-4-resources)\n- [Day 5: Variables](#day-5-variables)\n- [Day 5: Outputs](#day-5-outputs)\n- [Day 6: Data Sources](#day-6-data-sources)\n- [Day 7: State Management](#day-7-state-management)\n\n### **PART 3: ADVANCED FEATURES**\n- [Day 8: Count & For Each](#day-8-count--for-each)\n- [Day 9: Dynamic Blocks](#day-9-dynamic-blocks)\n- [Day 10: Functions](#day-10-terraform-functions)\n- [Day 11: Expressions & Conditionals](#day-11-expressions--conditionals)\n- [Day 12: Modules](#day-12-modules)\n- [Day 13: Workspaces](#day-13-workspaces)\n\n### **PART 4: PRODUCTION READY**\n- [Day 14: Remote State](#day-14-remote-state)\n- [Day 15: State Locking](#day-15-state-locking)\n- [Day 16: Import & Migration](#day-16-import--migration)\n- [Day 17: Provisioners](#day-17-provisioners)\n- [Day 18: Lifecycle Rules](#day-18-lifecycle-rules)\n\n### **PART 5: BEST PRACTICES**\n- [Day 19: Project Structure](#day-19-project-structure)\n- [Day 20: Security Best Practices](#day-20-security)\n- [Day 21: Testing Strategies](#day-21-testing)\n- [Day 22: CI/CD Integration](#day-22-cicd-integration)\n\n### **PART 6: REAL-WORLD PROJECTS**\n- [Project 1: Simple Web Server](#project-1-simple-web-server)\n- [Project 2: VPC & Networking](#project-2-vpc--networking)\n- [Project 3: Multi-Tier App](#project-3-multi-tier-application)\n- [Project 4: EKS Cluster](#project-4-eks-kubernetes-cluster)\n- [Project 5: Multi-Cloud](#project-5-multi-cloud-deployment)\n\n### **PART 7: MASTERY**\n- [Advanced Patterns](#advanced-patterns)\n- [Troubleshooting Guide](#troubleshooting-guide)\n- [Performance Optimization](#performance-optimization)\n- [Certification Prep](#certification-preparation)\n\n---\n\n# PART 1: FOUNDATIONS\n\n## Day 1: What is Terraform?\n\n### üéØ Learning Objectives\nBy the end of this section, you will understand:\n- What Terraform is and why it exists\n- The problem it solves\n- When to use Terraform vs other tools\n- How Terraform works under the hood\n\n---\n\n### ü§î The Problem: Manual Infrastructure Management\n\n**Before Terraform - The Painful Way:**\n\n```plaintext\nSCENARIO: Your startup needs 5 web servers\n\nMonday:\nüë®‚Äçüíª You: Login to AWS Console\n      Click EC2 ‚Üí Launch Instance\n      Select AMI, instance type, security group...\n      Click through 20+ settings\n      Wait 5 minutes\n      Repeat 4 more times... üò´\n      \nTuesday:\nüëî Boss: \"We need staging environment too\"\nüë®‚Äçüíª You: *Internal screaming* üò±\n      Do everything again...\n      \nWednesday:\nüëî Boss: \"Production needs 10 servers now\"\nüë®‚Äçüíª You: *Updates resume on LinkedIn* üíÄ\n\nFriday:\nüë®‚Äçüíª Junior Dev: \"How did you configure server 3?\"\nüë®‚Äçüíª You: \"Uhh... I don't remember...\"\n      *Documentation nowhere to be found*\n\nResult: \n‚ùå Time wasted: 10+ hours\n‚ùå Inconsistencies between environments\n‚ùå No documentation\n‚ùå Can't track who changed what\n‚ùå Can't reproduce setup\n‚ùå Manual errors everywhere\n```\n\n**With Terraform - The Smart Way:**\n\n```hcl\n# File: main.tf (5 minutes to write)\nresource \"aws_instance\" \"web\" {\n  count         = var.server_count  # Change this one number!\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags = {\n    Name = \"WebServer-${count.index + 1}\"\n  }\n}\n\n# Terminal (30 seconds to run)\n$ terraform apply\nCreating 5 servers... ‚úÖ Done in 2 minutes!\n\n# Need 10 servers? Change one line:\nserver_count = 10\n\n$ terraform apply\nAdding 5 more servers... ‚úÖ Done in 2 minutes!\n\n# Need staging? Copy folder, run again:\n$ terraform apply\nStaging environment created! ‚úÖ Identical to production!\n\nResult:\n‚úÖ Time saved: 9+ hours\n‚úÖ Consistent environments\n‚úÖ Code IS the documentation\n‚úÖ Version controlled (Git)\n‚úÖ Reproducible always\n‚úÖ Zero manual errors\n```\n\n---\n\n### üìñ What is Infrastructure as Code (IaC)?\n\n**Simple Analogy: Cooking**\n\n```plaintext\nTraditional Infrastructure:\nüç≥ Like cooking without a recipe\n   - Every time is different\n   - Can't share with others\n   - Forget ingredients\n   - Inconsistent results\n\nInfrastructure as Code:\nüìú Like having a detailed recipe\n   - Same result every time\n   - Share recipe with team\n   - All ingredients listed\n   - Consistent, perfect results\n```\n\n**Technical Definition:**\n\nInfrastructure as Code means managing and provisioning infrastructure through **machine-readable code** rather than manual processes or interactive configuration tools.\n\n---\n\n### üèóÔ∏è What is Terraform?\n\n**One-Line Summary:**  \nTerraform is a tool that lets you write code to create, change, and version your infrastructure safely and efficiently.\n\n**Detailed Explanation:**\n\nTerraform is:\n1. **Declarative** - You declare what you want, not how to get it\n2. **Cloud-Agnostic** - Works with AWS, Azure, GCP, and 1000+ providers\n3. **Open Source** - Free to use, large community\n4. **State-Based** - Tracks what it created\n5. **Immutable** - Replace instead of modify\n\n**Think of Terraform as:**\n- üèóÔ∏è **Architect** - Designs the infrastructure\n- üìù **Builder** - Creates the infrastructure  \n- üîç **Inspector** - Tracks what exists\n- üîß **Maintainer** - Updates infrastructure\n- üí• **Demolition** - Destroys infrastructure\n\n---\n\n### üÜö Terraform vs Other Tools\n\n#### **1. Terraform vs CloudFormation**\n\n| Feature | Terraform | CloudFormation |\n|---------|-----------|----------------|\n| **Cloud Support** | Multi-cloud ‚úÖ | AWS only ‚ùå |\n| **Language** | HCL (easy) ‚úÖ | JSON/YAML (verbose) ‚ùå |\n| **State** | Explicit ‚úÖ | AWS managed ‚úÖ |\n| **Community** | Huge ‚úÖ | AWS only ‚ùå |\n| **Cost** | Free ‚úÖ | Free ‚úÖ |\n\n**When to use CloudFormation:**\n- ‚úÖ AWS-only shop\n- ‚úÖ Need AWS-specific features\n- ‚úÖ Don't want to manage state\n\n**When to use Terraform:**\n- ‚úÖ Multi-cloud environment\n- ‚úÖ Need flexibility\n- ‚úÖ Want industry standard\n- ‚úÖ Better language (HCL)\n\n#### **2. Terraform vs Ansible**\n\n| Purpose | Terraform | Ansible |\n|---------|-----------|---------|\n| **Primary Use** | Create infrastructure | Configure infrastructure |\n| **Type** | Provisioning tool | Configuration management |\n| **Example** | Create 10 servers | Install nginx on servers |\n| **Approach** | Declarative | Procedural/Declarative |\n| **State** | Yes ‚úÖ | No ‚ùå |\n\n**The Perfect Combo:**\n```\nTerraform ‚Üí Creates the servers\n    ‚Üì\nAnsible ‚Üí Installs software on servers\n```\n\n**Real Example:**\n```hcl\n# Terraform creates server\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n}\n```\n\n```yaml\n# Ansible configures server\n- name: Install nginx\n  apt:\n    name: nginx\n    state: present\n```\n\n#### **3. Terraform vs Pulumi**\n\n| Feature | Terraform | Pulumi |\n|---------|-----------|--------|\n| **Language** | HCL | Python, TypeScript, Go |\n| **Learning Curve** | Easy | Harder (need programming) |\n| **Maturity** | Very mature ‚úÖ | Newer |\n| **Community** | Huge ‚úÖ | Growing |\n\n**Choose Terraform if:**\n- ‚úÖ You're new to IaC\n- ‚úÖ Want simplicity\n- ‚úÖ Need mature ecosystem\n\n**Choose Pulumi if:**\n- ‚úÖ Already know programming\n- ‚úÖ Want to use Python/TypeScript\n- ‚úÖ Need complex logic\n\n---\n\n### üîß How Terraform Works\n\n#### **The Terraform Workflow:**\n\n```plaintext\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                    TERRAFORM WORKFLOW                        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n1. WRITE CODE              2. INITIALIZE           3. PLAN\n   üìù main.tf          ‚Üí      ‚öôÔ∏è terraform init  ‚Üí    üîç terraform plan\n   \"I want a server\"         \"Download AWS plugin\"    \"Here's what I'll do\"\n                                                      \"+1 server to create\"\n           ‚Üì                         ‚Üì                        ‚Üì\n           \n4. APPLY                   5. STATE SAVED          6. MANAGE\n   üöÄ terraform apply  ‚Üí      üíæ terraform.tfstate ‚Üí  üîß Update/Destroy\n   \"Creating server...\"       \"Server ID: i-123\"      \"Modify as needed\"\n```\n\n#### **Under the Hood:**\n\n```plaintext\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Your Code   ‚îÇ  main.tf\n‚îÇ   (HCL)      ‚îÇ  \"create an EC2 instance\"\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ\n       ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Terraform   ‚îÇ  Reads your code\n‚îÇ    Core      ‚îÇ  Understands what you want\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ\n       ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Provider   ‚îÇ  AWS Provider Plugin\n‚îÇ   (Plugin)   ‚îÇ  Knows how to talk to AWS\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ\n       ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  AWS API     ‚îÇ  Actually creates server\n‚îÇ              ‚îÇ  Returns server ID\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ\n       ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  State File  ‚îÇ  terraform.tfstate\n‚îÇ              ‚îÇ  \"Server i-123 exists\"\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n---\n\n### üéØ When to Use Terraform\n\n#### ‚úÖ **Perfect Use Cases:**\n\n1. **Multi-Cloud Infrastructure**\n   ```hcl\n   # Same workflow for AWS, Azure, GCP\n   resource \"aws_instance\" \"web\" { }\n   resource \"azurerm_virtual_machine\" \"app\" { }\n   resource \"google_compute_instance\" \"db\" { }\n   ```\n\n2. **Consistent Environments**\n   ```bash\n   # Same code creates dev, staging, prod\n   terraform workspace select dev && terraform apply\n   terraform workspace select prod && terraform apply\n   ```\n\n3. **Version-Controlled Infrastructure**\n   ```bash\n   git log infrastructure/\n   # See who changed what, when, why\n   ```\n\n4. **Automated Deployments**\n   ```yaml\n   # CI/CD pipeline\n   - terraform plan\n   - terraform apply -auto-approve\n   ```\n\n5. **Complex Dependencies**\n   ```hcl\n   # Terraform handles order automatically\n   resource \"aws_vpc\" \"main\" { }\n   resource \"aws_subnet\" \"public\" {\n     vpc_id = aws_vpc.main.id  # Terraform creates VPC first\n   }\n   ```\n\n#### ‚ùå **Not Great For:**\n\n1. **Configuration Management**\n   - Use Ansible, Chef, Puppet instead\n   - Terraform creates, doesn't configure\n\n2. **Application Deployment**\n   - Use Docker, Kubernetes instead\n   - Terraform can create K8s cluster, not deploy apps\n\n3. **Adhoc Changes**\n   - Terraform is for infrastructure, not scripts\n   - Use shell scripts for one-off tasks\n\n---\n\n### üìä Terraform Architecture\n\n```plaintext\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                    TERRAFORM ARCHITECTURE                    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                    ‚îÇ  Terraform   ‚îÇ\n                    ‚îÇ     CLI      ‚îÇ\n                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                           ‚îÇ\n            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n            ‚îÇ              ‚îÇ              ‚îÇ\n            ‚Üì              ‚Üì              ‚Üì\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ   Core    ‚îÇ  ‚îÇ   State   ‚îÇ  ‚îÇ  Config   ‚îÇ\n    ‚îÇ  Engine   ‚îÇ  ‚îÇ  Manager  ‚îÇ  ‚îÇ  Parser   ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n          ‚îÇ              ‚îÇ              ‚îÇ\n          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                         ‚îÇ\n                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                    ‚îÇ Provider‚îÇ\n                    ‚îÇInterface‚îÇ\n                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                         ‚îÇ\n        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n        ‚îÇ                ‚îÇ                ‚îÇ\n        ‚Üì                ‚Üì                ‚Üì\n  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n  ‚îÇ   AWS    ‚îÇ    ‚îÇ  Azure   ‚îÇ    ‚îÇ   GCP    ‚îÇ\n  ‚îÇ Provider ‚îÇ    ‚îÇ Provider ‚îÇ    ‚îÇ Provider ‚îÇ\n  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ               ‚îÇ               ‚îÇ\n       ‚Üì               ‚Üì               ‚Üì\n  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n  ‚îÇ   AWS    ‚îÇ    ‚îÇ  Azure   ‚îÇ    ‚îÇ  Google  ‚îÇ\n  ‚îÇ   API    ‚îÇ    ‚îÇ   API    ‚îÇ    ‚îÇ   API    ‚îÇ\n  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n---\n\n### üéì Key Terminology\n\n#### **1. Provider**\n```plaintext\nWhat: Plugin that talks to a service (AWS, Azure, etc.)\nThink: Like a language translator\nExample: AWS provider translates Terraform ‚Üí AWS API\n```\n\n#### **2. Resource**\n```plaintext\nWhat: Something you want to create (server, database, etc.)\nThink: Building blocks of your infrastructure\nExample: aws_instance, aws_s3_bucket\n```\n\n#### **3. State**\n```plaintext\nWhat: Terraform's memory of what it created\nThink: Like a spreadsheet tracking everything\nExample: terraform.tfstate file\n```\n\n#### **4. Module**\n```plaintext\nWhat: Reusable group of resources\nThink: Like a function in programming\nExample: VPC module used by multiple projects\n```\n\n#### **5. Plan**\n```plaintext\nWhat: Preview of changes before applying\nThink: Like \"print preview\" before printing\nExample: terraform plan output\n```\n\n#### **6. Apply**\n```plaintext\nWhat: Actually create/update infrastructure\nThink: Like clicking \"Submit\" button\nExample: terraform apply command\n```\n\n---\n\n### üèÜ Why Terraform is Popular\n\n#### **Statistics:**\n- üìà **40,000+** GitHub stars\n- üë• **10M+** downloads per week\n- üè¢ **Fortune 500** companies use it\n- üíº **Top 10** most wanted DevOps skill\n\n#### **Industry Adoption:**\n\n```plaintext\nCompanies Using Terraform:\n‚úÖ Uber          ‚úÖ Slack         ‚úÖ Twitch\n‚úÖ Airbnb        ‚úÖ GitHub        ‚úÖ Shopify\n‚úÖ Netflix       ‚úÖ Pinterest     ‚úÖ Square\n‚úÖ Lyft          ‚úÖ Stripe        ‚úÖ Datadog\n```\n\n#### **Job Market:**\n\n```plaintext\nAverage Salaries (USA, 2025):\nüí∞ DevOps Engineer with Terraform: $120K - $180K\nüí∞ Cloud Engineer with Terraform:  $130K - $190K\nüí∞ SRE with Terraform:             $140K - $200K\nüí∞ Infrastructure Engineer:        $115K - $175K\n```\n\n---\n\n### ‚úÖ Summary: Day 1 Checklist\n\nBy now you should understand:\n\n- [x] What problem Terraform solves\n- [x] How Terraform differs from other tools\n- [x] When to use (and not use) Terraform\n- [x] Basic Terraform architecture\n- [x] Key terminology\n- [x] Why Terraform is valuable to learn\n\n**Next:** Let's install Terraform and set up your environment!\n\n---\n\n## Day 1: Installation & Setup\n\n### üéØ Learning Objectives\n- Install Terraform on your OS\n- Set up development environment\n- Configure cloud provider credentials\n- Verify everything works\n\n---\n\n### üíª Installation by Operating System\n\n#### **macOS Installation** üçé\n\n**Method 1: Homebrew (Recommended)**\n```bash\n# Install Homebrew if you don't have it\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Add HashiCorp tap\nbrew tap hashicorp/tap\n\n# Install Terraform\nbrew install hashicorp/tap/terraform\n\n# Verify installation\nterraform --version\n# Output: Terraform v1.7.0\n```\n\n**Method 2: Manual Download**\n```bash\n# Download latest version\ncurl -O https://releases.hashicorp.com/terraform/1.7.0/terraform_1.7.0_darwin_amd64.zip\n\n# Unzip\nunzip terraform_1.7.0_darwin_amd64.zip\n\n# Move to PATH\nsudo mv terraform /usr/local/bin/\n\n# Verify\nterraform --version\n```\n\n#### **Linux Installation** üêß\n\n**Ubuntu/Debian:**\n```bash\n# Update package manager\nsudo apt-get update\n\n# Install dependencies\nsudo apt-get install -y gnupg software-properties-common\n\n# Add HashiCorp GPG key\nwget -O- https://apt.releases.hashicorp.com/gpg | \\\n    gpg --dearmor | \\\n    sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg\n\n# Add HashiCorp repository\necho \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\\n    https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | \\\n    sudo tee /etc/apt/sources.list.d/hashicorp.list\n\n# Update and install\nsudo apt-get update\nsudo apt-get install terraform\n\n# Verify\nterraform --version\n```\n\n**RHEL/CentOS/Fedora:**\n```bash\n# Add HashiCorp repository\nsudo yum install -y yum-utils\nsudo yum-config-manager --add-repo \\\n    https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo\n\n# Install Terraform\nsudo yum install terraform\n\n# Verify\nterraform --version\n```\n\n**Arch Linux:**\n```bash\n# Install from official repository\nsudo pacman -S terraform\n\n# Verify\nterraform --version\n```\n\n#### **Windows Installation** ü™ü\n\n**Method 1: Chocolatey (Recommended)**\n```powershell\n# Install Chocolatey (if not installed)\n# Run PowerShell as Administrator\nSet-ExecutionPolicy Bypass -Scope Process -Force\n[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072\niex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n\n# Install Terraform\nchoco install terraform\n\n# Verify\nterraform --version\n```\n\n**Method 2: Manual Installation**\n```powershell\n# 1. Download from: https://www.terraform.io/downloads\n# 2. Unzip the file\n# 3. Add to PATH:\n#    - Right-click \"This PC\" ‚Üí Properties\n#    - Advanced system settings ‚Üí Environment Variables\n#    - Add terraform.exe location to PATH\n# 4. Open new terminal and verify\nterraform --version\n```\n\n---\n\n### üîß Development Environment Setup\n\n#### **Step 1: Install VS Code**\n\n```bash\n# macOS\nbrew install --cask visual-studio-code\n\n# Ubuntu\nsudo snap install code --classic\n\n# Windows\nchoco install vscode\n\n# Or download from: https://code.visualstudio.com/\n```\n\n#### **Step 2: Install Terraform Extension**\n\n1. Open VS Code\n2. Press `Cmd+Shift+X` (Mac) or `Ctrl+Shift+X` (Windows/Linux)\n3. Search: \"HashiCorp Terraform\"\n4. Click \"Install\"\n\n**What you get:**\n- ‚úÖ Syntax highlighting\n- ‚úÖ Auto-completion\n- ‚úÖ IntelliSense\n- ‚úÖ Error detection\n- ‚úÖ Format on save\n- ‚úÖ Code snippets\n\n#### **Step 3: Configure VS Code for Terraform**\n\nCreate `.vscode/settings.json` in your workspace:\n\n```json\n{\n  \"terraform.experimentalFeatures\": {\n    \"validateOnSave\": true,\n    \"prefillRequiredFields\": true\n  },\n  \"terraform.languageServer\": {\n    \"external\": true,\n    \"args\": [\"serve\"]\n  },\n  \"[terraform]\": {\n    \"editor.formatOnSave\": true,\n    \"editor.defaultFormatter\": \"hashicorp.terraform\"\n  },\n  \"files.associations\": {\n    \"*.tf\": \"terraform\",\n    \"*.tfvars\": \"terraform\"\n  }\n}\n```\n\n#### **Step 4: Install Terraform-Docs (Optional but Recommended)**\n\n```bash\n# macOS\nbrew install terraform-docs\n\n# Linux\ncurl -sSLo ./terraform-docs.tar.gz \\\n    https://terraform-docs.io/dl/v0.17.0/terraform-docs-v0.17.0-$(uname)-amd64.tar.gz\ntar -xzf terraform-docs.tar.gz\nchmod +x terraform-docs\nsudo mv terraform-docs /usr/local/bin/\n\n# Windows\nchoco install terraform-docs\n```\n\n#### **Step 5: Install TFLint (Terraform Linter)**\n\n```bash\n# macOS\nbrew install tflint\n\n# Linux\ncurl -s https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash\n\n# Windows\nchoco install tflint\n```\n\n---\n\n### ‚òÅÔ∏è Cloud Provider Setup\n\n#### **AWS Setup**\n\n**Step 1: Create AWS Account**\n1. Go to https://aws.amazon.com/\n2. Click \"Create an AWS Account\"\n3. Complete registration\n4. Add credit card (required, but won't be charged with free tier)\n\n**Step 2: Create IAM User**\n\n```bash\n# Login to AWS Console ‚Üí IAM ‚Üí Users ‚Üí Add User\n\nName: terraform-user\nAccess type: ‚òëÔ∏è Programmatic access\n\n# Attach policies:\n‚òëÔ∏è AdministratorAccess (for learning)\n# For production, use least privilege!\n\n# Download credentials CSV file\n```\n\n**Step 3: Install AWS CLI**\n\n```bash\n# macOS\nbrew install awscli\n\n# Linux\nsudo apt-get install awscli  # Ubuntu\nsudo yum install awscli      # RHEL/CentOS\n\n# Windows\nmsiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi\n\n# Verify\naws --version\n```\n\n**Step 4: Configure AWS CLI**\n\n```bash\naws configure\n\n# Enter your credentials:\nAWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE\nAWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nDefault region name [None]: us-east-1\nDefault output format [None]: json\n\n# Test connection\naws sts get-caller-identity\n```\n\n**Step 5: Set Environment Variables (Alternative)**\n\n```bash\n# Add to ~/.bashrc or ~/.zshrc\nexport AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport AWS_DEFAULT_REGION=\"us-east-1\"\n\n# Reload shell\nsource ~/.bashrc\n```\n\n#### **Azure Setup**\n\n**Step 1: Create Azure Account**\n```bash\n# Go to: https://azure.microsoft.com/free/\n# Sign up for free tier ($200 credit for 30 days)\n```\n\n**Step 2: Install Azure CLI**\n\n```bash\n# macOS\nbrew install azure-cli\n\n# Linux\ncurl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n\n# Windows\nmsiexec.exe /i https://aka.ms/installazurecliwindows\n\n# Verify\naz --version\n```\n\n**Step 3: Login to Azure**\n\n```bash\n# Login\naz login\n\n# This opens browser for authentication\n# After login, you'll see your subscriptions\n\n# List subscriptions\naz account list --output table\n\n# Set default subscription\naz account set --subscription=\"SUBSCRIPTION_ID\"\n```\n\n**Step 4: Create Service Principal**\n\n```bash\n# Create service principal for Terraform\naz ad sp create-for-rbac --name=\"terraform-sp\" --role=\"Contributor\" --scopes=\"/subscriptions/SUBSCRIPTION_ID\"\n\n# Output (SAVE THIS!):\n{\n  \"appId\": \"00000000-0000-0000-0000-000000000000\",\n  \"displayName\": \"terraform-sp\",\n  \"password\": \"0000-0000-0000-0000-000000000000\",\n  \"tenant\": \"00000000-0000-0000-0000-000000000000\"\n}\n\n# Set environment variables\nexport ARM_CLIENT_ID=\"appId\"\nexport ARM_CLIENT_SECRET=\"password\"\nexport ARM_SUBSCRIPTION_ID=\"your-subscription-id\"\nexport ARM_TENANT_ID=\"tenant\"\n```\n\n#### **Google Cloud Setup**\n\n**Step 1: Create GCP Account**\n```bash\n# Go to: https://cloud.google.com/free\n# Sign up ($300 credit for 90 days)\n```\n\n**Step 2: Install gcloud CLI**\n\n```bash\n# macOS\nbrew install --cask google-cloud-sdk\n\n# Linux\ncurl https://sdk.cloud.google.com | bash\nexec -l $SHELL\n\n# Windows\n# Download from: https://cloud.google.com/sdk/docs/install\n\n# Verify\ngcloud --version\n```\n\n**Step 3: Initialize gcloud**\n\n```bash\n# Initialize\ngcloud init\n\n# Login\ngcloud auth login\n\n# Set project\ngcloud config set project PROJECT_ID\n\n# Create service account for Terraform\ngcloud iam service-accounts create terraform \\\n    --display-name=\"Terraform Service Account\"\n\n# Grant permissions\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n    --member=\"serviceAccount:terraform@PROJECT_ID.iam.gserviceaccount.com\" \\\n    --role=\"roles/editor\"\n\n# Create and download key\ngcloud iam service-accounts keys create ~/terraform-key.json \\\n    --iam-account=terraform@PROJECT_ID.iam.gserviceaccount.com\n\n# Set environment variable\nexport GOOGLE_APPLICATION_CREDENTIALS=\"$HOME/terraform-key.json\"\n```\n\n---\n\n### üß™ Verify Installation\n\nCreate this test file to verify everything works:\n\n**File: `test.tf`**\n```hcl\nterraform {\n  required_version = \">= 1.0\"\n  \n  required_providers {\n    local = {\n      source  = \"hashicorp/local\"\n      version = \"~> 2.0\"\n    }\n  }\n}\n\nresource \"local_file\" \"test\" {\n  filename = \"${path.module}/test.txt\"\n  content  = \"Terraform is working! ‚úÖ\"\n}\n\noutput \"message\" {\n  value = \"Installation successful!\"\n}\n```\n\n**Run the test:**\n```bash\n# Initialize\nterraform init\n\n# Expected output:\n# Initializing provider plugins...\n# - Finding hashicorp/local versions matching \"~> 2.0\"...\n# - Installing hashicorp/local v2.4.1...\n# Terraform has been successfully initialized!\n\n# Plan\nterraform plan\n\n# Expected output:\n# Terraform will perform the following actions:\n#   # local_file.test will be created\n# Plan: 1 to add, 0 to change, 0 to destroy.\n\n# Apply\nterraform apply -auto-approve\n\n# Expected output:\n# local_file.test: Creating...\n# local_file.test: Creation complete\n# message = \"Installation successful!\"\n\n# Verify file was created\ncat test.txt\n# Output: Terraform is working! ‚úÖ\n\n# Clean up\nterraform destroy -auto-approve\nrm test.tf\n```\n\n---\n\n### üìÅ Project Directory Structure\n\nCreate your learning workspace:\n\n```bash\n# Create directory structure\nmkdir -p ~/terraform-learning/{day1-basics,day2-resources,day3-variables,projects}\n\ncd ~/terraform-learning\n\n# Create gitignore\ncat > .gitignore << 'EOF'\n# Terraform files\n.terraform/\n*.tfstate\n*.tfstate.backup\n*.tfplan\n.terraform.lock.hcl\n\n# Environment variables\n*.tfvars\n.env\n\n# IDE\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# OS\n.DS_Store\nThumbs.db\nEOF\n\n# Initialize git\ngit init\ngit add .gitignore\ngit commit -m \"Initial commit\"\n```\n\n---\n\n### ‚öôÔ∏è Configure Terraform CLI\n\n**Enable autocomplete:**\n```bash\n# For bash\nterraform -install-autocomplete\n\n# For zsh\necho 'autoload -U +X bashcompinit && bashcompinit' >> ~/.zshrc\necho 'complete -o nospace -C /usr/local/bin/terraform terraform' >> ~/.zshrc\nsource ~/.zshrc\n```\n\n**Set up aliases (optional):**\n```bash\n# Add to ~/.bashrc or ~/.zshrc\nalias tf='terraform'\nalias tfi='terraform init'\nalias tfp='terraform plan'\nalias tfa='terraform apply'\nalias tfd='terraform destroy'\nalias tfv='terraform validate'\nalias tff='terraform fmt -recursive'\n\n# Reload\nsource ~/.bashrc  # or source ~/.zshrc\n```\n\n---\n\n### ‚úÖ Installation Checklist\n\nVerify you have everything:\n\n```bash\n# 1. Terraform installed\nterraform --version\n# ‚úÖ Should show v1.7.0 or higher\n\n# 2. VS Code installed\ncode --version\n# ‚úÖ Should show VS Code version\n\n# 3. AWS CLI configured (if using AWS)\naws sts get-caller-identity\n# ‚úÖ Should show your AWS account info\n\n# 4. Git installed\ngit --version\n# ‚úÖ Should show git version\n\n# 5. Terraform extension in VS Code\n# ‚úÖ Open VS Code, check Extensions panel\n\n# 6. Test terraform works\ncd /tmp\necho 'resource \"local_file\" \"test\" { filename = \"test.txt\"; content = \"OK\" }' > test.tf\nterraform init && terraform apply -auto-approve\n# ‚úÖ Should create test.txt\n\n# Clean up\nrm -rf test.tf test.txt .terraform* terraform.tfstate*\n```\n\n---\n\n### üéâ Congratulations!\n\nYou've successfully:\n- ‚úÖ Installed Terraform\n- ‚úÖ Set up development environment\n- ‚úÖ Configured cloud provider\n- ‚úÖ Verified installation\n- ‚úÖ Created workspace structure\n\n**Next:** Let's create your first real Terraform project!\n\n---\n\n## Day 2: Your First Project\n\n### üéØ Learning Objectives\n- Create your first real infrastructure\n- Understand Terraform workflow\n- Learn basic Terraform commands\n- Deploy to AWS\n\n---\n\n### üöÄ Project: Deploy Your First S3 Bucket\n\nWe'll start with the simplest possible AWS resource - an S3 bucket (cloud storage).\n\n#### **Step 1: Create Project Directory**\n\n```bash\nmkdir -p ~/terraform-learning/day2-first-project\ncd ~/terraform-learning/day2-first-project\n```\n\n#### **Step 2: Write Terraform Configuration**\n\nCreate `main.tf`:\n\n```hcl\n#============================================================================\n# TERRAFORM CONFIGURATION\n#============================================================================\n# This block tells Terraform which providers we need\n\nterraform {\n  # Require Terraform 1.0 or higher\n  required_version = \">= 1.0\"\n  \n  # Declare providers we'll use\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"  # Official AWS provider\n      version = \"~> 5.0\"          # Use version 5.x\n    }\n  }\n}\n\n#============================================================================\n# PROVIDER CONFIGURATION  \n#============================================================================\n# Configure the AWS provider\n\nprovider \"aws\" {\n  region = \"us-east-1\"  # Virginia region (cheapest, most services)\n  \n  # Credentials are automatically loaded from:\n  # - Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n  # - AWS CLI configuration (~/.aws/credentials)\n  # - IAM role (if running on EC2)\n}\n\n#============================================================================\n# RESOURCES\n#============================================================================\n# Define what we want to create\n\nresource \"aws_s3_bucket\" \"my_first_bucket\" {\n  # Bucket name must be globally unique across all of AWS\n  # Use your name or add random suffix to ensure uniqueness\n  bucket = \"my-terraform-learning-bucket-2025\"\n  \n  # Tags help organize and identify resources\n  tags = {\n    Name        = \"My First Terraform Bucket\"\n    Environment = \"Learning\"\n    ManagedBy   = \"Terraform\"\n    CreatedAt   = \"2025-12-19\"\n    Owner       = \"YourName\"\n  }\n}\n\n# Enable versioning for the bucket (optional but recommended)\nresource \"aws_s3_bucket_versioning\" \"my_bucket_versioning\" {\n  bucket = aws_s3_bucket.my_first_bucket.id\n  \n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\n# Block all public access (security best practice)\nresource \"aws_s3_bucket_public_access_block\" \"my_bucket_pab\" {\n  bucket = aws_s3_bucket.my_first_bucket.id\n  \n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\n#============================================================================\n# OUTPUTS\n#============================================================================\n# Display information after Terraform runs\n\noutput \"bucket_name\" {\n  description = \"The name of the S3 bucket\"\n  value       = aws_s3_bucket.my_first_bucket.id\n}\n\noutput \"bucket_arn\" {\n  description = \"The ARN of the S3 bucket\"\n  value       = aws_s3_bucket.my_first_bucket.arn\n}\n\noutput \"bucket_region\" {\n  description = \"The region where the bucket is created\"\n  value       = aws_s3_bucket.my_first_bucket.region\n}\n\noutput \"creation_date\" {\n  description = \"The creation date of the bucket\"\n  value       = aws_s3_bucket.my_first_bucket.tags[\"CreatedAt\"]\n}\n```\n\n---\n\n#### **Step 3: Understanding the Code**\n\nLet's break down each part:\n\n**1. Terraform Block:**\n```hcl\nterraform {\n  required_version = \">= 1.0\"\n  \n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n```\n**What it does:**\n- Tells Terraform which version to use\n- Declares we need the AWS provider\n- Specifies AWS provider version\n\n**Why it matters:**\n- Prevents version conflicts\n- Ensures compatibility\n- Makes infrastructure reproducible\n\n---\n\n**2. Provider Block:**\n```hcl\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n```\n**What it does:**\n- Configures AWS provider\n- Sets default region\n\n**How authentication works:**\n1. Checks environment variables\n2. Checks `~/.aws/credentials`\n3. Checks IAM role (if on EC2)\n\n---\n\n**3. Resource Block:**\n```hcl\nresource \"aws_s3_bucket\" \"my_first_bucket\" {\n  bucket = \"my-terraform-learning-bucket-2025\"\n  tags = { ... }\n}\n```\n**What it does:**\n- Creates an S3 bucket\n- Names it \"my-terraform-learning-bucket-2025\"\n- Adds metadata tags\n\n**Syntax breakdown:**\n- `resource` - Terraform keyword\n- `\"aws_s3_bucket\"` - Resource type (from AWS provider)\n- `\"my_first_bucket\"` - Local name (for referencing in code)\n- `bucket = \"...\"` - Argument (actual bucket name in AWS)\n\n---\n\n**4. Output Block:**\n```hcl\noutput \"bucket_name\" {\n  description = \"The name of the S3 bucket\"\n  value       = aws_s3_bucket.my_first_bucket.id\n}\n```\n**What it does:**\n- Displays values after terraform apply\n- Can be used by other Terraform configurations\n- Useful for debugging and automation\n\n---\n\n## Day 2: Terraform Workflow\n\n### üîÑ The Complete Workflow\n\n```plaintext\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                     TERRAFORM WORKFLOW                           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n1. WRITE              2. INIT             3. FMT              4. VALIDATE\n   üìù Code        ‚Üí      ‚öôÔ∏è Setup      ‚Üí     üé® Format    ‚Üí     ‚úÖ Check\n   main.tf            Download plugins     Clean code         Syntax OK?\n                                                                    \n           ‚Üì                  ‚Üì                  ‚Üì                  ‚Üì\n           \n5. PLAN              6. APPLY            7. VERIFY           8. DESTROY\n   üîç Preview    ‚Üí      üöÄ Create     ‚Üí     üëÄ Check     ‚Üí     üí• Delete\n   See changes         Execute plan        Test it           Clean up\n```\n\nNow let's execute each step!\n\n---\n\n### Step 4: Initialize Terraform\n\n```bash\nterraform init\n```\n\n**What happens:**\n```plaintext\nInitializing the backend...\n\nInitializing provider plugins...\n- Finding hashicorp/aws versions matching \"~> 5.0\"...\n- Installing hashicorp/aws v5.31.0...\n- Installed hashicorp/aws v5.31.0 (signed by HashiCorp)\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \"terraform plan\" to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n```\n\n**What Terraform did:**\n1. ‚úÖ Created `.terraform/` directory\n2. ‚úÖ Downloaded AWS provider plugin\n3. ‚úÖ Created `.terraform.lock.hcl` (locks provider versions)\n4. ‚úÖ Initialized backend (state storage)\n\n**Check what was created:**\n```bash\nls -la\n# .terraform/          # Provider plugins\n# .terraform.lock.hcl  # Version lock file\n# main.tf              # Your configuration\n```\n\n---\n\n### Step 5: Format Code\n\n```bash\nterraform fmt\n```\n\n**What it does:**\n- Formats code to Terraform standards\n- Fixes indentation\n- Aligns arguments\n- Makes code consistent\n\n**Example:**\n```hcl\n# Before formatting (messy)\nresource \"aws_s3_bucket\" \"my_bucket\" {\nbucket=\"my-bucket\"\n  tags={\n      Name=\"MyBucket\"\n    Environment = \"Dev\"\n  }\n}\n\n# After formatting (clean)\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  bucket = \"my-bucket\"\n  \n  tags = {\n    Name        = \"MyBucket\"\n    Environment = \"Dev\"\n  }\n}\n```\n\n---\n\n### Step 6: Validate Configuration\n\n```bash\nterraform validate\n```\n\n**Possible outputs:**\n\n**Success:**\n```\nSuccess! The configuration is valid.\n```\n\n**Error example:**\n```\nError: Missing required argument\n\n  on main.tf line 10:\n  10: resource \"aws_s3_bucket\" \"my_bucket\" {\n\nThe argument \"bucket\" is required, but no definition was found.\n```\n\n---\n\n### Step 7: Plan Changes\n\n```bash\nterraform plan\n```\n\n**Output:**\n```hcl\nTerraform used the selected providers to generate the following execution plan.\nResource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # aws_s3_bucket.my_first_bucket will be created\n  + resource \"aws_s3_bucket\" \"my_first_bucket\" {\n      + acceleration_status         = (known after apply)\n      + acl                         = (known after apply)\n      + arn                         = (known after apply)\n      + bucket                      = \"my-terraform-learning-bucket-2025\"\n      + bucket_domain_name          = (known after apply)\n      + bucket_regional_domain_name = (known after apply)\n      + force_destroy               = false\n      + hosted_zone_id              = (known after apply)\n      + id                          = (known after apply)\n      + object_lock_enabled         = (known after apply)\n      + policy                      = (known after apply)\n      + region                      = (known after apply)\n      + request_payer               = (known after apply)\n      + tags                        = {\n          + \"CreatedAt\"   = \"2025-12-19\"\n          + \"Environment\" = \"Learning\"\n          + \"ManagedBy\"   = \"Terraform\"\n          + \"Name\"        = \"My First Terraform Bucket\"\n          + \"Owner\"       = \"YourName\"\n        }\n      + tags_all                    = {\n          + \"CreatedAt\"   = \"2025-12-19\"\n          + \"Environment\" = \"Learning\"\n          + \"ManagedBy\"   = \"Terraform\"\n          + \"Name\"        = \"My First Terraform Bucket\"\n          + \"Owner\"       = \"YourName\"\n        }\n      + website_domain              = (known after apply)\n      + website_endpoint            = (known after apply)\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nChanges to Outputs:\n  + bucket_arn      = (known after apply)\n  + bucket_name     = \"my-terraform-learning-bucket-2025\"\n  + bucket_region   = (known after apply)\n  + creation_date   = \"2025-12-19\"\n```\n\n**Understanding the symbols:**\n- `+` = Create new resource\n- `-` = Destroy resource\n- `~` = Update in-place\n- `-/+` = Destroy and recreate\n- `(known after apply)` = Value not known until resource is created\n\n**Save plan (optional):**\n```bash\nterraform plan -out=tfplan\n```\n\n---\n\n### Step 8: Apply Changes\n\n```bash\nterraform apply\n```\n\n**Interactive mode:**\n```\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value: yes\n\naws_s3_bucket.my_first_bucket: Creating...\naws_s3_bucket.my_first_bucket: Creation complete after 2s [id=my-terraform-learning-bucket-2025]\naws_s3_bucket_versioning.my_bucket_versioning: Creating...\naws_s3_bucket_public_access_block.my_bucket_pab: Creating...\naws_s3_bucket_versioning.my_bucket_versioning: Creation complete after 1s\naws_s3_bucket_public_access_block.my_bucket_pab: Creation complete after 1s\n\nApply complete! Resources: 3 added, 0 changed, 0 destroyed.\n\nOutputs:\n\nbucket_arn = \"arn:aws:s3:::my-terraform-learning-bucket-2025\"\nbucket_name = \"my-terraform-learning-bucket-2025\"\nbucket_region = \"us-east-1\"\ncreation_date = \"2025-12-19\"\n```\n\n**Auto-approve (skip confirmation):**\n```bash\nterraform apply -auto-approve\n```\n\n---\n\n### Step 9: Verify in AWS\n\n**Method 1: AWS Console**\n```\n1. Go to https://console.aws.amazon.com/\n2. Navigate to S3 service\n3. Look for \"my-terraform-learning-bucket-2025\"\n4. Click on it to see details\n```\n\n**Method 2: AWS CLI**\n```bash\naws s3 ls | grep terraform-learning\n# Should show your bucket\n\naws s3api get-bucket-versioning --bucket my-terraform-learning-bucket-2025\n# Should show versioning status\n```\n\n---\n\n### Step 10: View Outputs\n\n```bash\n# View all outputs\nterraform output\n\n# View specific output\nterraform output bucket_name\n\n# View as JSON\nterraform output -json\n```\n\n---\n\n### Step 11: Inspect State\n\n```bash\n# Show current state\nterraform show\n\n# List resources in state\nterraform state list\n\n# Show specific resource\nterraform state show aws_s3_bucket.my_first_bucket\n```\n\n---\n\n### Step 12: Make Changes\n\nLet's update the bucket by adding a new tag.\n\n**Edit `main.tf`:**\n```hcl\nresource \"aws_s3_bucket\" \"my_first_bucket\" {\n  bucket = \"my-terraform-learning-bucket-2025\"\n  \n  tags = {\n    Name        = \"My First Terraform Bucket\"\n    Environment = \"Learning\"\n    ManagedBy   = \"Terraform\"\n    CreatedAt   = \"2025-12-19\"\n    Owner       = \"YourName\"\n    Project     = \"Terraform Learning\"  # NEW TAG\n  }\n}\n```\n\n**Plan the change:**\n```bash\nterraform plan\n```\n\n**Output:**\n```\nTerraform will perform the following actions:\n\n  # aws_s3_bucket.my_first_bucket will be updated in-place\n  ~ resource \"aws_s3_bucket\" \"my_first_bucket\" {\n        id                          = \"my-terraform-learning-bucket-2025\"\n      ~ tags                        = {\n          + \"Project\"     = \"Terraform Learning\"\n            # (5 unchanged elements hidden)\n        }\n      ~ tags_all                    = {\n          + \"Project\"     = \"Terraform Learning\"\n            # (5 unchanged elements hidden)\n        }\n        # (12 unchanged attributes hidden)\n    }\n\nPlan: 0 to add, 1 to change, 0 to destroy.\n```\n\n**Apply the change:**\n```bash\nterraform apply -auto-approve\n```\n\n---\n\n### Step 13: Destroy Infrastructure\n\nWhen you're done learning, clean up to avoid charges:\n\n```bash\nterraform destroy\n```\n\n**Output:**\n```\nTerraform will perform the following actions:\n\n  # aws_s3_bucket.my_first_bucket will be destroyed\n  - resource \"aws_s3_bucket\" \"my_first_bucket\" {\n      - arn                         = \"arn:aws:s3:::my-terraform-learning-bucket-2025\"\n      - bucket                      = \"my-terraform-learning-bucket-2025\"\n      - id                          = \"my-terraform-learning-bucket-2025\"\n      - tags                        = {\n          - \"CreatedAt\"   = \"2025-12-19\"\n          - \"Environment\" = \"Learning\"\n          - \"ManagedBy\"   = \"Terraform\"\n          - \"Name\"        = \"My First Terraform Bucket\"\n          - \"Owner\"       = \"YourName\"\n          - \"Project\"     = \"Terraform Learning\"\n        }\n    }\n\nPlan: 0 to add, 0 to change, 3 to destroy.\n\nDo you really want to destroy all resources?\n  Terraform will destroy all your managed infrastructure, as shown above.\n  There is no undo. Only 'yes' will be accepted to confirm.\n\n  Enter a value: yes\n\naws_s3_bucket_versioning.my_bucket_versioning: Destroying...\naws_s3_bucket_public_access_block.my_bucket_pab: Destroying...\naws_s3_bucket_versioning.my_bucket_versioning: Destruction complete after 1s\naws_s3_bucket_public_access_block.my_bucket_pab: Destruction complete after 1s\naws_s3_bucket.my_first_bucket: Destroying...\naws_s3_bucket.my_first_bucket: Destruction complete after 1s\n\nDestroy complete! Resources: 3 destroyed.\n```\n\n---\n\n### üéì Complete Command Reference\n\n#### **Basic Commands**\n```bash\n# Initialize working directory\nterraform init\n\n# Format code\nterraform fmt\nterraform fmt -recursive       # Format all files\nterraform fmt -check           # Check if files need formatting\n\n# Validate configuration\nterraform validate\n\n# Show execution plan\nterraform plan\nterraform plan -out=tfplan     # Save plan to file\n\n# Apply changes\nterraform apply\nterraform apply -auto-approve  # Skip confirmation\nterraform apply tfplan         # Apply saved plan\n\n# Destroy infrastructure\nterraform destroy\nterraform destroy -auto-approve\n```\n\n#### **State Commands**\n```bash\n# List resources in state\nterraform state list\n\n# Show resource details\nterraform state show aws_s3_bucket.my_first_bucket\n\n# Remove resource from state (doesn't delete real resource)\nterraform state rm aws_s3_bucket.my_first_bucket\n\n# Move resource in state\nterraform state mv aws_s3_bucket.old aws_s3_bucket.new\n\n# Pull remote state\nterraform state pull\n\n# Push local state to remote\nterraform state push\n```\n\n#### **Output Commands**\n```bash\n# Show all outputs\nterraform output\n\n# Show specific output\nterraform output bucket_name\n\n# Output as JSON\nterraform output -json\n```\n\n#### **Workspace Commands**\n```bash\n# List workspaces\nterraform workspace list\n\n# Create workspace\nterraform workspace new dev\n\n# Select workspace\nterraform workspace select prod\n\n# Delete workspace\nterraform workspace delete staging\n```\n\n#### **Other Useful Commands**\n```bash\n# Show current state or saved plan\nterraform show\nterraform show tfplan\n\n# Generate dependency graph\nterraform graph | dot -Tsvg > graph.svg\n\n# Interactive console\nterraform console\n\n# Get provider information\nterraform providers\n\n# Check Terraform version\nterraform version\n\n# Refresh state (sync with real infrastructure)\nterraform refresh\n\n# Import existing resource\nterraform import aws_s3_bucket.my_bucket bucket-name\n```\n\n---\n\n### üêõ Common Errors and Solutions\n\n#### **Error 1: Bucket name already exists**\n```\nError: Error creating S3 bucket: BucketAlreadyExists\n```\n**Solution:** Change bucket name to something unique\n```hcl\nbucket = \"my-terraform-learning-bucket-yourname-2025\"\n```\n\n#### **Error 2: No AWS credentials**\n```\nError: No valid credential sources found for AWS Provider\n```\n**Solution:** Configure AWS CLI\n```bash\naws configure\n```\n\n#### **Error 3: Region not specified**\n```\nError: Insufficient information to construct AWS client\n```\n**Solution:** Add region to provider block or set environment variable\n```bash\nexport AWS_DEFAULT_REGION=us-east-1\n```\n\n#### **Error 4: Permission denied**\n```\nError: AccessDenied: Access Denied\n```\n**Solution:** Check IAM permissions for your user\n\n#### **Error 5: State lock**\n```\nError: Error acquiring the state lock\n```\n**Solution:** Wait for other operation to complete or force unlock (careful!)\n```bash\nterraform force-unlock LOCK_ID\n```\n\n---\n\n### ‚úÖ Day 2 Checklist\n\nBy now you should be able to:\n\n- [x] Write basic Terraform configuration\n- [x] Initialize a Terraform project\n- [x] Create AWS resources\n- [x] Use terraform plan/apply/destroy\n- [x] Understand outputs\n- [x] Make changes to infrastructure\n- [x] Clean up resources\n\n**Congratulations! üéâ** You've deployed your first infrastructure with Terraform!\n\n**Next:** Let's learn the HCL language in depth...\n\n---\n\n## Day 3: HCL Language Basics\n\n### üéØ Learning Objectives\n- Master HCL (HashiCorp Configuration Language) syntax\n- Understand all data types\n- Learn string interpolation and expressions\n- Use built-in functions\n\n---\n\n### üìñ HCL Syntax Fundamentals\n\n#### **Block Structure**\n```hcl\n# Basic block syntax\nblock_type \"label_one\" \"label_two\" {\n  argument_name = \"argument_value\"\n  \n  nested_block {\n    nested_argument = \"value\"\n  }\n}\n```\n\n**Real Example:**\n```hcl\nresource \"aws_instance\" \"web_server\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags {\n    Name = \"WebServer\"\n  }\n}\n```\n\n**Breakdown:**\n- `resource` = Block type (keyword)\n- `\"aws_instance\"` = First label (resource type)\n- `\"web_server\"` = Second label (resource name)\n- `ami = \"...\"` = Argument\n- `tags { }` = Nested block\n\n---\n\n### üìù Comments\n\n```hcl\n# This is a single-line comment\n\n// This also works for single-line comments\n\n/*\n  This is a\n  multi-line comment\n  spanning multiple lines\n*/\n\n# Use comments to explain WHY, not WHAT\nresource \"aws_instance\" \"web\" {\n  # Using t2.micro for cost optimization in dev environment\n  instance_type = \"t2.micro\"  # Free tier eligible\n}\n```\n\n---\n\n### üî§ Data Types\n\n#### **1. Primitive Types**\n\n**String:**\n```hcl\nvariable \"instance_name\" {\n  type    = string\n  default = \"web-server\"\n}\n\nvariable \"region\" {\n  type    = string\n  default = \"us-east-1\"\n}\n\n# Multi-line strings\nvariable \"user_data\" {\n  type    = string\n  default = <<-EOF\n    #!/bin/bash\n    echo \"Hello World\"\n    apt-get update\n  EOF\n}\n\n# Heredoc with indentation stripped\nvariable \"script\" {\n  type = string\n  default = <<-EOT\n    Line 1\n      Line 2 (indented)\n    Line 3\n  EOT\n}\n```\n\n**Number:**\n```hcl\nvariable \"instance_count\" {\n  type    = number\n  default = 3\n}\n\nvariable \"disk_size\" {\n  type    = number\n  default = 100\n}\n\nvariable \"price\" {\n  type    = number\n  default = 0.50  # Decimals work too\n}\n```\n\n**Boolean:**\n```hcl\nvariable \"enable_monitoring\" {\n  type    = bool\n  default = true\n}\n\nvariable \"is_production\" {\n  type    = bool\n  default = false\n}\n\n# Use in conditionals\nresource \"aws_instance\" \"web\" {\n  monitoring = var.enable_monitoring  # true or false\n}\n```\n\n---\n\n#### **2. Collection Types**\n\n**List (Ordered collection of values):**\n```hcl\nvariable \"availability_zones\" {\n  type = list(string)\n  default = [\n    \"us-east-1a\",\n    \"us-east-1b\",\n    \"us-east-1c\"\n  ]\n}\n\nvariable \"allowed_ports\" {\n  type = list(number)\n  default = [22, 80, 443, 3306]\n}\n\n# Access list elements\nlocals {\n  first_az  = var.availability_zones[0]      # \"us-east-1a\"\n  second_az = var.availability_zones[1]      # \"us-east-1b\"\n  last_port = var.allowed_ports[length(var.allowed_ports) - 1]  # 3306\n}\n\n# Loop through list\nresource \"aws_subnet\" \"public\" {\n  count             = length(var.availability_zones)\n  availability_zone = var.availability_zones[count.index]\n  cidr_block        = \"10.0.${count.index}.0/24\"\n}\n```\n\n**Map (Key-value pairs):**\n```hcl\nvariable \"instance_types\" {\n  type = map(string)\n  default = {\n    dev     = \"t2.micro\"\n    staging = \"t2.small\"\n    prod    = \"t3.large\"\n  }\n}\n\nvariable \"tags\" {\n  type = map(string)\n  default = {\n    Environment = \"Production\"\n    Team        = \"DevOps\"\n    Project     = \"WebApp\"\n    CostCenter  = \"Engineering\"\n  }\n}\n\n# Access map values\nresource \"aws_instance\" \"web\" {\n  instance_type = var.instance_types[\"prod\"]  # \"t3.large\"\n  tags          = var.tags\n}\n\n# Loop through map\nresource \"aws_instance\" \"servers\" {\n  for_each      = var.instance_types\n  instance_type = each.value  # \"t2.micro\", \"t2.small\", etc.\n  \n  tags = {\n    Name = \"${each.key}-server\"  # \"dev-server\", \"staging-server\", etc.\n  }\n}\n```\n\n**Set (Unique collection, no duplicates):**\n```hcl\nvariable \"security_group_ids\" {\n  type = set(string)\n  default = [\n    \"sg-12345\",\n    \"sg-67890\",\n    \"sg-12345\"  # Duplicate ignored\n  ]\n  # Result: [\"sg-12345\", \"sg-67890\"]\n}\n\n# Sets are useful for ensuring uniqueness\nresource \"aws_instance\" \"web\" {\n  vpc_security_group_ids = var.security_group_ids\n}\n```\n\n---\n\n#### **3. Structural Types**\n\n**Object (Complex structure with different types):**\n```hcl\nvariable \"database_config\" {\n  type = object({\n    engine            = string\n    engine_version    = string\n    instance_class    = string\n    allocated_storage = number\n    multi_az          = bool\n    backup_retention  = number\n  })\n  \n  default = {\n    engine            = \"mysql\"\n    engine_version    = \"8.0.33\"\n    instance_class    = \"db.t3.micro\"\n    allocated_storage = 20\n    multi_az          = false\n    backup_retention  = 7\n  }\n}\n\n# Use object properties\nresource \"aws_db_instance\" \"main\" {\n  engine               = var.database_config.engine\n  engine_version       = var.database_config.engine_version\n  instance_class       = var.database_config.instance_class\n  allocated_storage    = var.database_config.allocated_storage\n  multi_az             = var.database_config.multi_az\n  backup_retention_period = var.database_config.backup_retention\n}\n```\n\n**Tuple (Fixed-length ordered collection):**\n```hcl\nvariable \"server_config\" {\n  type = tuple([string, number, bool])\n  default = [\"t2.micro\", 20, true]\n  # [instance_type, disk_size, enable_monitoring]\n}\n\nlocals {\n  instance_type     = var.server_config[0]  # \"t2.micro\"\n  disk_size         = var.server_config[1]  # 20\n  enable_monitoring = var.server_config[2]  # true\n}\n```\n\n---\n\n### üîó String Interpolation\n\n```hcl\nvariable \"project\" {\n  default = \"myapp\"\n}\n\nvariable \"environment\" {\n  default = \"prod\"\n}\n\nvariable \"region\" {\n  default = \"us-east-1\"\n}\n\nlocals {\n  # Basic interpolation\n  server_name = \"${var.project}-${var.environment}-server\"\n  # Result: \"myapp-prod-server\"\n  \n  # Interpolation with functions\n  upper_project = \"${upper(var.project)}-${var.environment}\"\n  # Result: \"MYAPP-prod\"\n  \n  # Multi-variable interpolation\n  full_name = \"${var.project}-${var.environment}-${var.region}\"\n  # Result: \"myapp-prod-us-east-1\"\n  \n  # Embedded expressions\n  description = \"This is ${var.project} running in ${var.environment}\"\n  # Result: \"This is myapp running in prod\"\n  \n  # Conditional in interpolation\n  display_name = \"${var.environment == \"prod\" ? \"PRODUCTION\" : \"DEVELOPMENT\"}-${var.project}\"\n  # Result: \"PRODUCTION-myapp\"\n}\n\nresource \"aws_instance\" \"web\" {\n  tags = {\n    Name = \"${var.project}-${var.environment}-web-${count.index + 1}\"\n    Description = \"Server for ${var.project} in ${var.region}\"\n  }\n}\n```\n\n**Template Strings:**\n```hcl\nlocals {\n  # Heredoc with interpolation\n  user_data = <<-EOF\n    #!/bin/bash\n    echo \"Setting up ${var.project}\"\n    export ENVIRONMENT=${var.environment}\n    export REGION=${var.region}\n    \n    # Install application\n    apt-get update\n    apt-get install -y ${var.project}-server\n  EOF\n  \n  # JSON template\n  config = <<-EOT\n    {\n      \"app_name\": \"${var.project}\",\n      \"environment\": \"${var.environment}\",\n      \"region\": \"${var.region}\",\n      \"debug\": ${var.environment != \"prod\"}\n    }\n  EOT\n}\n```\n\n---\n\n### ‚öôÔ∏è Expressions\n\n#### **Arithmetic Operators:**\n```hcl\nlocals {\n  # Basic math\n  total         = 5 + 3              # 8\n  difference    = 10 - 4             # 6\n  product       = 2 * 50             # 100\n  quotient      = 100 / 5            # 20\n  remainder     = 10 % 3             # 1\n  \n  # More complex\n  disk_size     = var.base_size * var.multiplier\n  total_cost    = var.instance_count * var.price_per_instance\n  subnet_count  = var.az_count * 2  # 2 subnets per AZ\n}\n```\n\n#### **Comparison Operators:**\n```hcl\nlocals {\n  # Equality\n  is_prod       = var.environment == \"prod\"     # true/false\n  is_not_dev    = var.environment != \"dev\"      # true/false\n  \n  # Comparison\n  is_many       = var.instance_count > 5        # true/false\n  is_few        = var.instance_count < 10       # true/false\n  is_enough     = var.instance_count >= 3       # true/false\n  is_limited    = var.instance_count <= 20      # true/false\n}\n```\n\n#### **Logical Operators:**\n```hcl\nlocals {\n  # AND - both must be true\n  create_large = var.environment == \"prod\" && var.instance_count > 10\n  \n  # OR - at least one must be true\n  allow_access = var.is_admin || var.is_developer\n  \n  # NOT - reverse boolean\n  disable_debug = !var.enable_debug\n  \n  # Complex logic\n  should_backup = (var.environment == \"prod\" || var.environment == \"staging\") && \n                  var.enable_backups &&\n                  !var.is_test_mode\n}\n```\n\n#### **Conditional (Ternary) Operator:**\n```hcl\nlocals {\n  # condition ? true_value : false_value\n  \n  # Choose instance type\n  instance_type = var.environment == \"prod\" ? \"t3.large\" : \"t2.micro\"\n  \n  # Set monitoring\n  monitoring = var.environment == \"prod\" ? true : false\n  \n  # Determine count\n  instance_count = var.environment == \"prod\" ? 3 : 1\n  \n  # Nested conditionals\n  storage_size = var.environment == \"prod\" ? 100 : (\n    var.environment == \"staging\" ? 50 : 20\n  )\n  \n  # With expressions\n  name_suffix = var.use_random_suffix ? random_id.suffix.hex : \"static\"\n}\n\nresource \"aws_instance\" \"web\" {\n  instance_type = local.instance_type\n  monitoring    = local.monitoring\n  \n  tags = {\n    Name = var.environment == \"prod\" ? \"PROD-Server\" : \"DEV-Server\"\n  }\n}\n```\n\n---\n\n### üîß Built-in Functions\n\nTerraform has 100+ built-in functions. Here are the most useful ones:\n\n#### **Numeric Functions:**\n```hcl\nlocals {\n  # abs - Absolute value\n  positive = abs(-5)              # 5\n  \n  # ceil - Round up\n  rounded_up = ceil(3.2)          # 4\n  \n  # floor - Round down\n  rounded_down = floor(3.8)       # 3\n  \n  # max - Maximum value\n  highest = max(5, 12, 9)         # 12\n  \n  # min - Minimum value\n  lowest = min(5, 12, 9)          # 5\n  \n  # pow - Power\n  squared = pow(2, 3)             # 8\n  \n  # log - Logarithm\n  logarithm = log(100, 10)        # 2\n}\n```\n\n#### **String Functions:**\n```hcl\nlocals {\n  # upper - Convert to uppercase\n  uppercase = upper(\"hello\")               # \"HELLO\"\n  \n  # lower - Convert to lowercase\n  lowercase = lower(\"WORLD\")               # \"world\"\n  \n  # title - Title case\n  titled = title(\"hello world\")            # \"Hello World\"\n  \n  # trim - Remove whitespace\n  trimmed = trim(\"  hello  \")              # \"hello\"\n  \n  # trimprefix - Remove prefix\n  no_prefix = trimprefix(\"Mr. John\", \"Mr. \")  # \"John\"\n  \n  # trimsuffix - Remove suffix\n  no_suffix = trimsuffix(\"file.txt\", \".txt\")  # \"file\"\n  \n  # replace - Replace substring\n  replaced = replace(\"hello world\", \"world\", \"terraform\")  # \"hello terraform\"\n  \n  # split - Split into list\n  parts = split(\",\", \"a,b,c\")              # [\"a\", \"b\", \"c\"]\n  \n  # join - Join list into string\n  joined = join(\"-\", [\"a\", \"b\", \"c\"])      # \"a-b-c\"\n  \n  # substr - Substring\n  sub = substr(\"hello world\", 0, 5)        # \"hello\"\n  \n  # format - Format string\n  formatted = format(\"Server-%03d\", 5)     # \"Server-005\"\n  \n  # regex - Regular expression\n  matched = regex(\"[0-9]+\", \"abc123def\")   # \"123\"\n  \n  # regexall - All matches\n  all_matches = regexall(\"[0-9]+\", \"a1b2c3\")  # [\"1\", \"2\", \"3\"]\n}\n```\n\n#### **Collection Functions:**\n```hcl\nvariable \"servers\" {\n  default = [\"web1\", \"web2\", \"web3\"]\n}\n\nvariable \"ports\" {\n  default = [80, 443, 22]\n}\n\nlocals {\n  # length - Get count\n  server_count = length(var.servers)       # 3\n  \n  # element - Get item by index (with wraparound)\n  first_server = element(var.servers, 0)   # \"web1\"\n  wrapped = element(var.servers, 5)        # \"web3\" (5 % 3 = 2)\n  \n  # index - Find index of value\n  port_index = index(var.ports, 443)       # 1\n  \n  # contains - Check if value exists\n  has_https = contains(var.ports, 443)     # true\n  \n  # concat - Combine lists\n  all_servers = concat(var.servers, [\"db1\", \"db2\"])\n  # [\"web1\", \"web2\", \"web3\", \"db1\", \"db2\"]\n  \n  # distinct - Remove duplicates\n  unique = distinct([\"a\", \"b\", \"a\", \"c\"]) # [\"a\", \"b\", \"c\"]\n  \n  # flatten - Flatten nested lists\n  flat = flatten([[\"a\", \"b\"], [\"c\", \"d\"]])  # [\"a\", \"b\", \"c\", \"d\"]\n  \n  # slice - Get sublist\n  subset = slice(var.servers, 0, 2)        # [\"web1\", \"web2\"]\n  \n  # sort - Sort list\n  sorted_ports = sort(var.ports)           # [22, 80, 443]\n  \n  # reverse - Reverse list\n  reversed = reverse(var.servers)          # [\"web3\", \"web2\", \"web1\"]\n  \n  # range - Generate numeric list\n  numbers = range(5)                       # [0, 1, 2, 3, 4]\n  custom_range = range(2, 10, 2)          # [2, 4, 6, 8]\n  \n  # zipmap - Create map from two lists\n  server_ips = zipmap(\n    [\"web1\", \"web2\"],\n    [\"10.0.1.1\", \"10.0.1.2\"]\n  )\n  # { web1 = \"10.0.1.1\", web2 = \"10.0.1.2\" }\n}\n```\n\n#### **Map Functions:**\n```hcl\nvariable \"tags\" {\n  default = {\n    Environment = \"prod\"\n    Team        = \"DevOps\"\n  }\n}\n\nvariable \"extra_tags\" {\n  default = {\n    Project = \"WebApp\"\n    Owner   = \"John\"\n  }\n}\n\nlocals {\n  # keys - Get map keys\n  tag_keys = keys(var.tags)               # [\"Environment\", \"Team\"]\n  \n  # values - Get map values\n  tag_values = values(var.tags)           # [\"prod\", \"DevOps\"]\n  \n  # lookup - Get value by key with default\n  env = lookup(var.tags, \"Environment\", \"dev\")  # \"prod\"\n  missing = lookup(var.tags, \"Missing\", \"default\")  # \"default\"\n  \n  # merge - Combine maps\n  all_tags = merge(var.tags, var.extra_tags)\n  # {\n  #   Environment = \"prod\"\n  #   Team        = \"DevOps\"\n  #   Project     = \"WebApp\"\n  #   Owner       = \"John\"\n  # }\n}\n```\n\n#### **Type Conversion Functions:**\n```hcl\nlocals {\n  # tostring - Convert to string\n  str = tostring(123)                     # \"123\"\n  \n  # tonumber - Convert to number\n  num = tonumber(\"456\")                   # 456\n  \n  # tobool - Convert to boolean\n  boolean = tobool(\"true\")                # true\n  \n  # tolist - Convert to list\n  list_val = tolist([\"a\", \"b\"])          # [\"a\", \"b\"]\n  \n  # toset - Convert to set\n  set_val = toset([\"a\", \"b\", \"a\"])       # [\"a\", \"b\"]\n  \n  # tomap - Convert to map\n  map_val = tomap({key = \"value\"})       # {key = \"value\"}\n}\n```\n\n#### **Date/Time Functions:**\n```hcl\nlocals {\n  # timestamp - Current time (UTC)\n  now = timestamp()                       # \"2025-12-19T10:30:00Z\"\n  \n  # formatdate - Format timestamp\n  formatted = formatdate(\"DD MMM YYYY hh:mm:ss\", timestamp())\n  # \"19 Dec 2025 10:30:00\"\n  \n  # timeadd - Add duration\n  future = timeadd(timestamp(), \"24h\")    # Tomorrow\n  past = timeadd(timestamp(), \"-1h\")      # One hour ago\n}\n```\n\n#### **Filesystem Functions:**\n```hcl\nlocals {\n  # file - Read file contents\n  script = file(\"${path.module}/script.sh\")\n  \n  # fileexists - Check if file exists\n  has_config = fileexists(\"${path.module}/config.json\")\n  \n  # fileset - List files matching pattern\n  yaml_files = fileset(path.module, \"*.yaml\")\n  \n  # basename - Get filename\n  filename = basename(\"/path/to/file.txt\")  # \"file.txt\"\n  \n  # dirname - Get directory path\n  dirpath = dirname(\"/path/to/file.txt\")   # \"/path/to\"\n  \n  # abspath - Absolute path\n  absolute = abspath(\"relative/path\")\n  \n  # pathexpand - Expand home directory\n  expanded = pathexpand(\"~/documents\")\n}\n```\n\n#### **Encoding Functions:**\n```hcl\nlocals {\n  # base64encode - Encode to base64\n  encoded = base64encode(\"Hello World\")\n  \n  # base64decode - Decode from base64\n  decoded = base64decode(local.encoded)\n  \n  # jsonencode - Convert to JSON\n  json = jsonencode({\n    name = \"server\"\n    count = 3\n  })\n  # '{\"name\":\"server\",\"count\":3}'\n  \n  # jsondecode - Parse JSON\n  parsed = jsondecode('{\"name\":\"server\"}')\n  # {name = \"server\"}\n  \n  # yamlencode - Convert to YAML\n  yaml = yamlencode({\n    name = \"server\"\n    ports = [80, 443]\n  })\n  \n  # yamldecode - Parse YAML\n  yaml_parsed = yamldecode(file(\"config.yaml\"))\n}\n```\n\n#### **IP Network Functions:**\n```hcl\nlocals {\n  # cidrsubnet - Calculate subnet\n  subnet1 = cidrsubnet(\"10.0.0.0/16\", 8, 0)  # \"10.0.0.0/24\"\n  subnet2 = cidrsubnet(\"10.0.0.0/16\", 8, 1)  # \"10.0.1.0/24\"\n  \n  # cidrhost - Get IP from CIDR\n  first_ip = cidrhost(\"10.0.1.0/24\", 0)      # \"10.0.1.0\"\n  second_ip = cidrhost(\"10.0.1.0/24\", 1)     # \"10.0.1.1\"\n  \n  # cidrnetmask - Get netmask\n  netmask = cidrnetmask(\"10.0.0.0/16\")       # \"255.255.0.0\"\n}\n```\n\n---\n\n### üéì Practical Examples\n\n#### **Example 1: Dynamic Resource Naming**\n```hcl\nvariable \"project\" {\n  default = \"webapp\"\n}\n\nvariable \"environment\" {\n  default = \"prod\"\n}\n\nvariable \"region\" {\n  default = \"us-east-1\"\n}\n\nlocals {\n  # Create consistent naming\n  name_prefix = \"${var.project}-${var.environment}\"\n  \n  # Add region for multi-region deployments\n  full_name = \"${var.project}-${var.environment}-${var.region}\"\n  \n  # Common tags\n  common_tags = {\n    Project     = var.project\n    Environment = var.environment\n    ManagedBy   = \"Terraform\"\n    CreatedAt   = formatdate(\"YYYY-MM-DD\", timestamp())\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  count = 3\n  \n  ami           = \"ami-12345\"\n  instance_type = var.environment == \"prod\" ? \"t3.large\" : \"t2.micro\"\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name  = \"${local.name_prefix}-web-${count.index + 1}\"\n      Role  = \"webserver\"\n      Index = count.index + 1\n    }\n  )\n}\n```\n\n#### **Example 2: Conditional Resource Creation**\n```hcl\nvariable \"create_database\" {\n  type    = bool\n  default = true\n}\n\nvariable \"environment\" {\n  default = \"dev\"\n}\n\nresource \"aws_db_instance\" \"main\" {\n  count = var.create_database ? 1 : 0\n  \n  engine         = \"mysql\"\n  instance_class = var.environment == \"prod\" ? \"db.t3.medium\" : \"db.t3.micro\"\n  \n  # Only enable backups in production\n  backup_retention_period = var.environment == \"prod\" ? 7 : 0\n  \n  # Multi-AZ only in production\n  multi_az = var.environment == \"prod\" ? true : false\n}\n\noutput \"database_endpoint\" {\n  value = var.create_database ? aws_db_instance.main[0].endpoint : \"No database created\"\n}\n```\n\n#### **Example 3: Working with Lists and Maps**\n```hcl\nvariable \"environments\" {\n  type = map(object({\n    instance_type = string\n    instance_count = number\n    enable_monitoring = bool\n  }))\n  \n  default = {\n    dev = {\n      instance_type     = \"t2.micro\"\n      instance_count    = 1\n      enable_monitoring = false\n    }\n    staging = {\n      instance_type     = \"t2.small\"\n      instance_count    = 2\n      enable_monitoring = false\n    }\n    prod = {\n      instance_type     = \"t3.large\"\n      instance_count    = 5\n      enable_monitoring = true\n    }\n  }\n}\n\nvariable \"current_environment\" {\n  default = \"prod\"\n}\n\nlocals {\n  config = var.environments[var.current_environment]\n}\n\nresource \"aws_instance\" \"servers\" {\n  count = local.config.instance_count\n  \n  ami           = \"ami-12345\"\n  instance_type = local.config.instance_type\n  monitoring    = local.config.enable_monitoring\n  \n  tags = {\n    Name = \"server-${count.index + 1}\"\n    Environment = var.current_environment\n  }\n}\n```\n\n---\n\n### ‚úÖ Day 3 Checklist\n\nBy now you should understand:\n\n- [x] HCL syntax and structure\n- [x] All data types (primitive, collection, structural)\n- [x] String interpolation\n- [x] All expression types\n- [x] Built-in functions\n- [x] How to combine them in real scenarios\n\n**Next:** Deep dive into Providers!\n\n---\n\n## Day 4: Providers Deep Dive\n\n### üéØ Learning Objectives\n- Master provider configuration\n- Work with multiple providers\n- Use provider aliases\n- Configure authentication\n- Understand provider versioning\n\n---\n\n### üîå Understanding Providers\n\n**What is a Provider?**\n\nA provider is a plugin that enables Terraform to interact with an API (cloud provider, SaaS, etc.).\n\n```plaintext\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Your Code    ‚îÇ  \"create an EC2 instance\"\n‚îÇ   (HCL)      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ\n       ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Terraform   ‚îÇ  Understands what you want\n‚îÇ    Core      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ\n       ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Provider   ‚îÇ  Translates to AWS API calls\n‚îÇ   Plugin     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n       ‚îÇ\n       ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  AWS API     ‚îÇ  Actually creates the resource\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n---\n\n### üì¶ Provider Configuration\n\n#### **Basic Provider Setup**\n\n```hcl\nterraform {\n  required_version = \">= 1.0\"\n  \n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"    # Where to download from\n      version = \"~> 5.0\"            # Which version to use\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n```\n\n#### **Understanding Version Constraints**\n\n```hcl\n# Exact version\nversion = \"5.0.0\"              # Only 5.0.0\n\n# Greater than or equal\nversion = \">= 5.0.0\"           # 5.0.0, 5.1.0, 6.0.0, etc.\n\n# Less than\nversion = \"< 6.0.0\"            # Any version before 6.0.0\n\n# Pessimistic constraint (~>)\nversion = \"~> 5.0\"             # 5.0, 5.1, 5.2, ... 5.x (not 6.0)\nversion = \"~> 5.0.0\"           # 5.0.0, 5.0.1, ... 5.0.x (not 5.1)\n\n# Combined constraints\nversion = \">= 5.0, < 6.0\"      # 5.x versions only\n\n# Best practice for production\nversion = \"5.31.0\"             # Pin exact version\n```\n\n---\n\n### üåç Popular Providers\n\n#### **1. AWS Provider - Complete Configuration**\n\n```hcl\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region     = \"us-east-1\"\n  profile    = \"default\"        # AWS CLI profile\n  \n  # Optional: Assume role\n  assume_role {\n    role_arn     = \"arn:aws:iam::123456789012:role/TerraformRole\"\n    session_name = \"terraform-session\"\n    external_id  = \"EXTERNAL_ID\"\n  }\n  \n  # Optional: Default tags for ALL resources\n  default_tags {\n    tags = {\n      ManagedBy   = \"Terraform\"\n      Environment = \"Production\"\n      Team        = \"Platform\"\n    }\n  }\n  \n  # Optional: Ignore specific tags\n  ignore_tags {\n    key_prefixes = [\"kubernetes.io/\"]\n    keys         = [\"aws:createdBy\"]\n  }\n  \n  # Optional: Custom endpoints (for testing/localstack)\n  endpoints {\n    s3  = \"http://localhost:4566\"\n    ec2 = \"http://localhost:4566\"\n  }\n}\n\n# Example resource - automatically gets default_tags\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"my-bucket\"\n  \n  # These tags merge with default_tags\n  tags = {\n    Name = \"MyBucket\"\n  }\n  # Final tags:\n  # - ManagedBy = \"Terraform\"\n  # - Environment = \"Production\"\n  # - Team = \"Platform\"\n  # - Name = \"MyBucket\"\n}\n```\n\n**AWS Authentication Methods:**\n\n```bash\n# Method 1: Environment Variables (RECOMMENDED)\nexport AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport AWS_SESSION_TOKEN=\"your-session-token\"  # If using MFA\nexport AWS_DEFAULT_REGION=\"us-east-1\"\n\n# Method 2: AWS CLI Profile\naws configure --profile terraform\n# Then in Terraform:\nprovider \"aws\" {\n  profile = \"terraform\"\n}\n\n# Method 3: Shared Credentials File\nprovider \"aws\" {\n  shared_credentials_files = [\"~/.aws/credentials\"]\n  profile                  = \"default\"\n}\n\n# Method 4: IAM Role (if running on EC2/ECS/Lambda)\nprovider \"aws\" {\n  region = \"us-east-1\"\n  # Automatically uses attached IAM role\n}\n\n# Method 5: AWS SSO\naws sso login --profile my-sso-profile\n# Then:\nprovider \"aws\" {\n  profile = \"my-sso-profile\"\n}\n```\n\n---\n\n#### **2. Azure Provider**\n\n```hcl\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~> 3.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}  # Required, even if empty\n  \n  subscription_id = \"00000000-0000-0000-0000-000000000000\"\n  tenant_id       = \"11111111-1111-1111-1111-111111111111\"\n  \n  # Optional: Use specific subscription\n  skip_provider_registration = true\n  \n  # Optional: Custom resource provider registration\n  features {\n    resource_group {\n      prevent_deletion_if_contains_resources = true\n    }\n    \n    key_vault {\n      purge_soft_delete_on_destroy    = true\n      recover_soft_deleted_key_vaults = true\n    }\n    \n    virtual_machine {\n      delete_os_disk_on_deletion     = true\n      graceful_shutdown              = false\n      skip_shutdown_and_force_delete = false\n    }\n  }\n}\n\n# Azure authentication methods\n```\n\n**Azure Authentication:**\n\n```bash\n# Method 1: Azure CLI (RECOMMENDED for development)\naz login\n# Terraform automatically uses Azure CLI credentials\n\n# Method 2: Service Principal\nexport ARM_CLIENT_ID=\"00000000-0000-0000-0000-000000000000\"\nexport ARM_CLIENT_SECRET=\"your-client-secret\"\nexport ARM_SUBSCRIPTION_ID=\"00000000-0000-0000-0000-000000000000\"\nexport ARM_TENANT_ID=\"11111111-1111-1111-1111-111111111111\"\n\n# Method 3: Managed Identity (when running on Azure VM/App Service)\nprovider \"azurerm\" {\n  features {}\n  use_msi = true\n}\n\n# Method 4: In Terraform code (NOT RECOMMENDED - security risk)\nprovider \"azurerm\" {\n  features {}\n  client_id       = \"00000000-0000-0000-0000-000000000000\"\n  client_secret   = \"your-secret\"\n  subscription_id = \"00000000-0000-0000-0000-000000000000\"\n  tenant_id       = \"11111111-1111-1111-1111-111111111111\"\n}\n```\n\n**Azure Example Resource:**\n\n```hcl\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"example-resources\"\n  location = \"East US\"\n}\n\nresource \"azurerm_virtual_network\" \"example\" {\n  name                = \"example-vnet\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n}\n\nresource \"azurerm_subnet\" \"example\" {\n  name                 = \"internal\"\n  resource_group_name  = azurerm_resource_group.example.name\n  virtual_network_name = azurerm_virtual_network.example.name\n  address_prefixes     = [\"10.0.2.0/24\"]\n}\n```\n\n---\n\n#### **3. Google Cloud Provider**\n\n```hcl\nterraform {\n  required_providers {\n    google = {\n      source  = \"hashicorp/google\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"google\" {\n  project     = \"my-project-id\"\n  region      = \"us-central1\"\n  zone        = \"us-central1-a\"\n  credentials = file(\"path/to/service-account-key.json\")\n  \n  # Optional: Default labels\n  default_labels = {\n    managed_by  = \"terraform\"\n    environment = \"production\"\n  }\n  \n  # Optional: Batching for API calls\n  batching {\n    send_after      = \"10s\"\n    enable_batching = true\n  }\n}\n\n# GCP authentication methods\n```\n\n**GCP Authentication:**\n\n```bash\n# Method 1: Service Account Key (RECOMMENDED for CI/CD)\nexport GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/key.json\"\n\n# Method 2: gcloud CLI (for development)\ngcloud auth application-default login\n\n# Method 3: In Terraform code\nprovider \"google\" {\n  credentials = file(\"service-account-key.json\")\n}\n\n# Method 4: GCE Metadata (when running on GCE)\nprovider \"google\" {\n  # Automatically uses GCE metadata service\n}\n```\n\n**GCP Example Resources:**\n\n```hcl\nresource \"google_compute_network\" \"vpc\" {\n  name                    = \"my-vpc\"\n  auto_create_subnetworks = false\n}\n\nresource \"google_compute_subnetwork\" \"subnet\" {\n  name          = \"my-subnet\"\n  ip_cidr_range = \"10.0.1.0/24\"\n  region        = \"us-central1\"\n  network       = google_compute_network.vpc.id\n}\n\nresource \"google_compute_instance\" \"vm\" {\n  name         = \"my-instance\"\n  machine_type = \"f1-micro\"\n  zone         = \"us-central1-a\"\n  \n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-11\"\n    }\n  }\n  \n  network_interface {\n    subnetwork = google_compute_subnetwork.subnet.id\n    \n    access_config {\n      // Ephemeral public IP\n    }\n  }\n}\n```\n\n---\n\n### üé≠ Multiple Provider Configurations (Aliases)\n\n**Use Case:** Deploy to multiple regions or accounts\n\n```hcl\n# Default AWS provider (us-east-1)\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\n# West coast provider\nprovider \"aws\" {\n  alias  = \"west\"\n  region = \"us-west-2\"\n}\n\n# Europe provider\nprovider \"aws\" {\n  alias  = \"europe\"\n  region = \"eu-west-1\"\n}\n\n# Production account provider\nprovider \"aws\" {\n  alias   = \"prod\"\n  region  = \"us-east-1\"\n  profile = \"production\"\n}\n\n# Resources using default provider (us-east-1)\nresource \"aws_s3_bucket\" \"east_bucket\" {\n  bucket = \"my-east-bucket\"\n}\n\n# Resources using west provider\nresource \"aws_s3_bucket\" \"west_bucket\" {\n  provider = aws.west  # Specify alias\n  bucket   = \"my-west-bucket\"\n}\n\n# Resources using europe provider\nresource \"aws_vpc\" \"eu_vpc\" {\n  provider   = aws.europe\n  cidr_block = \"10.0.0.0/16\"\n}\n\n# Resources using production account\nresource \"aws_instance\" \"prod_server\" {\n  provider      = aws.prod\n  ami           = \"ami-12345\"\n  instance_type = \"t3.large\"\n}\n```\n\n**Multi-Region Deployment Example:**\n\n```hcl\n# File: main.tf\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\n# Primary region\nprovider \"aws\" {\n  region = var.primary_region\n}\n\n# Secondary region for DR\nprovider \"aws\" {\n  alias  = \"dr\"\n  region = var.dr_region\n}\n\n# Variables\nvariable \"primary_region\" {\n  default = \"us-east-1\"\n}\n\nvariable \"dr_region\" {\n  default = \"us-west-2\"\n}\n\n# Primary region resources\nresource \"aws_vpc\" \"primary\" {\n  cidr_block = \"10.0.0.0/16\"\n  \n  tags = {\n    Name   = \"primary-vpc\"\n    Region = var.primary_region\n  }\n}\n\nresource \"aws_instance\" \"primary_web\" {\n  count         = 3\n  ami           = \"ami-east-12345\"\n  instance_type = \"t3.medium\"\n  \n  tags = {\n    Name = \"primary-web-${count.index + 1}\"\n  }\n}\n\n# DR region resources\nresource \"aws_vpc\" \"dr\" {\n  provider   = aws.dr\n  cidr_block = \"10.1.0.0/16\"\n  \n  tags = {\n    Name   = \"dr-vpc\"\n    Region = var.dr_region\n  }\n}\n\nresource \"aws_instance\" \"dr_web\" {\n  provider      = aws.dr\n  count         = 3\n  ami           = \"ami-west-12345\"\n  instance_type = \"t3.medium\"\n  \n  tags = {\n    Name = \"dr-web-${count.index + 1}\"\n  }\n}\n\n# Outputs\noutput \"primary_vpc_id\" {\n  value = aws_vpc.primary.id\n}\n\noutput \"dr_vpc_id\" {\n  value = aws_vpc.dr.id\n}\n```\n\n---\n\n### üåê Multi-Cloud Deployment\n\n**Deploy across AWS, Azure, and GCP:**\n\n```hcl\n# File: main.tf\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~> 3.0\"\n    }\n    google = {\n      source  = \"hashicorp/google\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\n# AWS Provider\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\n# Azure Provider\nprovider \"azurerm\" {\n  features {}\n}\n\n# GCP Provider\nprovider \"google\" {\n  project = \"my-project-id\"\n  region  = \"us-central1\"\n}\n\n# AWS Resources\nresource \"aws_s3_bucket\" \"aws_storage\" {\n  bucket = \"my-aws-storage\"\n  \n  tags = {\n    Cloud = \"AWS\"\n  }\n}\n\nresource \"aws_instance\" \"aws_server\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t3.micro\"\n  \n  tags = {\n    Name  = \"AWS-Server\"\n    Cloud = \"AWS\"\n  }\n}\n\n# Azure Resources\nresource \"azurerm_resource_group\" \"azure_rg\" {\n  name     = \"my-resource-group\"\n  location = \"East US\"\n  \n  tags = {\n    Cloud = \"Azure\"\n  }\n}\n\nresource \"azurerm_storage_account\" \"azure_storage\" {\n  name                     = \"myazurestorage\"\n  resource_group_name      = azurerm_resource_group.azure_rg.name\n  location                 = azurerm_resource_group.azure_rg.location\n  account_tier             = \"Standard\"\n  account_replication_type = \"LRS\"\n  \n  tags = {\n    Cloud = \"Azure\"\n  }\n}\n\n# GCP Resources\nresource \"google_storage_bucket\" \"gcp_storage\" {\n  name     = \"my-gcp-storage\"\n  location = \"US\"\n  \n  labels = {\n    cloud = \"gcp\"\n  }\n}\n\nresource \"google_compute_instance\" \"gcp_server\" {\n  name         = \"gcp-server\"\n  machine_type = \"f1-micro\"\n  zone         = \"us-central1-a\"\n  \n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-11\"\n    }\n  }\n  \n  network_interface {\n    network = \"default\"\n    \n    access_config {}\n  }\n  \n  labels = {\n    cloud = \"gcp\"\n  }\n}\n\n# Outputs\noutput \"aws_bucket\" {\n  value = aws_s3_bucket.aws_storage.id\n}\n\noutput \"azure_storage\" {\n  value = azurerm_storage_account.azure_storage.name\n}\n\noutput \"gcp_bucket\" {\n  value = google_storage_bucket.gcp_storage.url\n}\n```\n\n---\n\n### üîê Provider Security Best Practices\n\n#### **1. Never Hardcode Credentials**\n\n```hcl\n# ‚ùå BAD - Credentials in code\nprovider \"aws\" {\n  region     = \"us-east-1\"\n  access_key = \"AKIAIOSFODNN7EXAMPLE\"\n  secret_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\n}\n\n# ‚úÖ GOOD - Use environment variables\nprovider \"aws\" {\n  region = \"us-east-1\"\n  # Credentials from environment or AWS CLI\n}\n\n# ‚úÖ GOOD - Use AWS CLI profile\nprovider \"aws\" {\n  region  = \"us-east-1\"\n  profile = \"terraform\"\n}\n\n# ‚úÖ GOOD - Assume IAM role\nprovider \"aws\" {\n  region = \"us-east-1\"\n  assume_role {\n    role_arn = \"arn:aws:iam::123456789012:role/TerraformRole\"\n  }\n}\n```\n\n#### **2. Use Least Privilege IAM Policies**\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:Describe*\",\n        \"ec2:CreateTags\",\n        \"ec2:DeleteTags\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:RunInstances\",\n        \"ec2:TerminateInstances\",\n        \"ec2:StopInstances\",\n        \"ec2:StartInstances\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"aws:RequestedRegion\": \"us-east-1\"\n        }\n      }\n    }\n  ]\n}\n```\n\n#### **3. Pin Provider Versions**\n\n```hcl\n# ‚úÖ GOOD - Exact version for production\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"5.31.0\"\n    }\n  }\n}\n\n# ‚ùå BAD - No version constraint\nterraform {\n  required_providers {\n    aws = {\n      source = \"hashicorp/aws\"\n    }\n  }\n}\n```\n\n---\n\n### ‚úÖ Day 4 Checklist\n\nBy now you should understand:\n\n- [x] What providers are and how they work\n- [x] How to configure AWS, Azure, and GCP providers\n- [x] Multiple authentication methods\n- [x] Provider aliases for multi-region/multi-account\n- [x] Multi-cloud deployments\n- [x] Provider security best practices\n\n**Next:** Deep dive into Resources!\n\n---\n\n## Day 5: Resources - The Heart of Terraform\n\n### üéØ Learning Objectives\n- Understand resource blocks completely\n- Master resource dependencies\n- Learn meta-arguments\n- Handle resource lifecycle\n- Use provisioners correctly\n\n---\n\n### üèóÔ∏è What is a Resource?\n\nA **resource** is any infrastructure component you want to create/manage:\n- Virtual machines\n- Storage buckets\n- Databases\n- Networks\n- Load balancers\n- DNS records\n- Anything your provider supports!\n\n---\n\n### üìù Resource Block Syntax\n\n```hcl\nresource \"resource_type\" \"resource_name\" {\n  # Configuration arguments\n  argument1 = \"value1\"\n  argument2 = \"value2\"\n  \n  # Nested blocks\n  nested_block {\n    nested_arg = \"value\"\n  }\n  \n  # Meta-arguments (special Terraform arguments)\n  count    = 3\n  depends_on = [other_resource.name]\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n**Breakdown:**\n- `resource` = Keyword\n- `\"resource_type\"` = Provider resource type (e.g., `aws_instance`, `azurerm_virtual_machine`)\n- `\"resource_name\"` = Your local name for this resource\n- Resource ID = `resource_type.resource_name` (e.g., `aws_instance.web`)\n\n---\n\n### üåü Complete Resource Examples\n\n#### **Example 1: AWS EC2 Instance**\n\n```hcl\n# Security Group\nresource \"aws_security_group\" \"web_sg\" {\n  name        = \"web-server-sg\"\n  description = \"Security group for web server\"\n  \n  # Inbound HTTP\n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"Allow HTTP from anywhere\"\n  }\n  \n  # Inbound HTTPS\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"Allow HTTPS from anywhere\"\n  }\n  \n  # Inbound SSH (restricted)\n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"203.0.113.0/24\"]  # Your office IP\n    description = \"Allow SSH from office\"\n  }\n  \n  # Outbound - all traffic\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"Allow all outbound\"\n  }\n  \n  tags = {\n    Name = \"web-server-sg\"\n  }\n}\n\n# EC2 Instance\nresource \"aws_instance\" \"web_server\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"  # Amazon Linux 2\n  instance_type = \"t3.micro\"\n  \n  # Reference security group created above\n  vpc_security_group_ids = [aws_security_group.web_sg.id]\n  \n  # User data script\n  user_data = <<-EOF\n    #!/bin/bash\n    yum update -y\n    yum install -y httpd\n    systemctl start httpd\n    systemctl enable httpd\n    echo \"<h1>Hello from Terraform!</h1>\" > /var/www/html/index.html\n  EOF\n  \n  # Root volume\n  root_block_device {\n    volume_size           = 20\n    volume_type           = \"gp3\"\n    delete_on_termination = true\n    encrypted             = true\n  }\n  \n  # Additional volume\n  ebs_block_device {\n    device_name           = \"/dev/sdf\"\n    volume_size           = 50\n    volume_type           = \"gp3\"\n    delete_on_termination = true\n    encrypted             = true\n  }\n  \n  # Enable detailed monitoring\n  monitoring = true\n  \n  # Instance metadata options (security best practice)\n  metadata_options {\n    http_endpoint               = \"enabled\"\n    http_tokens                 = \"required\"  # IMDSv2\n    http_put_response_hop_limit = 1\n  }\n  \n  tags = {\n    Name        = \"web-server\"\n    Environment = \"production\"\n    ManagedBy   = \"Terraform\"\n  }\n  \n  # Lifecycle rules\n  lifecycle {\n    create_before_destroy = true\n    ignore_changes        = [user_data]\n  }\n}\n\n# Elastic IP\nresource \"aws_eip\" \"web_eip\" {\n  instance = aws_instance.web_server.id\n  domain   = \"vpc\"\n  \n  tags = {\n    Name = \"web-server-eip\"\n  }\n  \n  # Don't create until instance is ready\n  depends_on = [aws_instance.web_server]\n}\n```\n\n---\n\n#### **Example 2: Azure Virtual Machine**\n\n```hcl\n# Resource Group\nresource \"azurerm_resource_group\" \"main\" {\n  name     = \"vm-resources\"\n  location = \"East US\"\n  \n  tags = {\n    Environment = \"Production\"\n  }\n}\n\n# Virtual Network\nresource \"azurerm_virtual_network\" \"main\" {\n  name                = \"vm-network\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n}\n\n# Subnet\nresource \"azurerm_subnet\" \"internal\" {\n  name                 = \"internal\"\n  resource_group_name  = azurerm_resource_group.main.name\n  virtual_network_name = azurerm_virtual_network.main.name\n  address_prefixes     = [\"10.0.2.0/24\"]\n}\n\n# Network Interface\nresource \"azurerm_network_interface\" \"main\" {\n  name                = \"vm-nic\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  \n  ip_configuration {\n    name                          = \"internal\"\n    subnet_id                     = azurerm_subnet.internal.id\n    private_ip_address_allocation = \"Dynamic\"\n    public_ip_address_id          = azurerm_public_ip.main.id\n  }\n}\n\n# Public IP\nresource \"azurerm_public_ip\" \"main\" {\n  name                = \"vm-public-ip\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  allocation_method   = \"Static\"\n  sku                 = \"Standard\"\n}\n\n# Network Security Group\nresource \"azurerm_network_security_group\" \"main\" {\n  name                = \"vm-nsg\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  \n  security_rule {\n    name                       = \"SSH\"\n    priority                   = 1001\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"22\"\n    source_address_prefix      = \"*\"\n    destination_address_prefix = \"*\"\n  }\n}\n\n# Associate NSG with NIC\nresource \"azurerm_network_interface_security_group_association\" \"main\" {\n  network_interface_id      = azurerm_network_interface.main.id\n  network_security_group_id = azurerm_network_security_group.main.id\n}\n\n# Virtual Machine\nresource \"azurerm_linux_virtual_machine\" \"main\" {\n  name                = \"production-vm\"\n  resource_group_name = azurerm_resource_group.main.name\n  location            = azurerm_resource_group.main.location\n  size                = \"Standard_B2s\"\n  admin_username      = \"adminuser\"\n  \n  network_interface_ids = [\n    azurerm_network_interface.main.id,\n  ]\n  \n  admin_ssh_key {\n    username   = \"adminuser\"\n    public_key = file(\"~/.ssh/id_rsa.pub\")\n  }\n  \n  os_disk {\n    caching              = \"ReadWrite\"\n    storage_account_type = \"Premium_LRS\"\n    disk_size_gb         = 30\n  }\n  \n  source_image_reference {\n    publisher = \"Canonical\"\n    offer     = \"0001-com-ubuntu-server-focal\"\n    sku       = \"20_04-lts-gen2\"\n    version   = \"latest\"\n  }\n  \n  tags = {\n    Environment = \"Production\"\n  }\n}\n```\n\n---\n\n### üîó Resource Dependencies\n\nTerraform automatically detects dependencies when you reference other resources:\n\n#### **Implicit Dependencies (Automatic)**\n\n```hcl\n# Security group created first\nresource \"aws_security_group\" \"web\" {\n  name = \"web-sg\"\n  \n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\n# EC2 instance created AFTER security group\n# Terraform detects: aws_instance.web depends on aws_security_group.web\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  # This reference creates implicit dependency\n  vpc_security_group_ids = [aws_security_group.web.id]\n}\n\n# EIP created AFTER instance\n# Terraform detects: aws_eip.web depends on aws_instance.web\nresource \"aws_eip\" \"web\" {\n  instance = aws_instance.web.id\n  domain   = \"vpc\"\n}\n```\n\n**Terraform automatically creates this order:**\n```plaintext\n1. aws_security_group.web\n2. aws_instance.web\n3. aws_eip.web\n```\n\n---\n\n#### **Explicit Dependencies (Manual)**\n\nUse `depends_on` when Terraform can't detect the dependency:\n\n```hcl\n# S3 bucket for storing data\nresource \"aws_s3_bucket\" \"data\" {\n  bucket = \"my-data-bucket\"\n}\n\n# EC2 instance that needs bucket to exist first\n# But doesn't reference it directly in code\nresource \"aws_instance\" \"processor\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  user_data = <<-EOF\n    #!/bin/bash\n    # Script uploads data to S3\n    aws s3 cp data.txt s3://my-data-bucket/\n  EOF\n  \n  # Explicit dependency - create bucket first!\n  depends_on = [aws_s3_bucket.data]\n}\n\n# IAM role policy attachment\nresource \"aws_iam_role_policy_attachment\" \"s3_access\" {\n  role       = aws_iam_role.app_role.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n}\n\n# Instance profile needs policy attached first\nresource \"aws_iam_instance_profile\" \"app_profile\" {\n  name = \"app-profile\"\n  role = aws_iam_role.app_role.name\n  \n  # Wait for policy attachment\n  depends_on = [aws_iam_role_policy_attachment.s3_access]\n}\n```\n\n**When to use `depends_on`:**\n- Resource needs another to exist but doesn't reference it\n- IAM policy attachments before using the role\n- Database initialization before app deployment\n- Network routes before instances\n\n---\n\n### üéõÔ∏è Meta-Arguments\n\nMeta-arguments work with ALL resource types:\n\n#### **1. `count` - Create Multiple Similar Resources**\n\n```hcl\n# Create 3 identical instances\nresource \"aws_instance\" \"web\" {\n  count = 3\n  \n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags = {\n    Name = \"web-server-${count.index}\"\n    # Results: web-server-0, web-server-1, web-server-2\n  }\n}\n\n# Reference specific instance\noutput \"first_instance_ip\" {\n  value = aws_instance.web[0].private_ip\n}\n\noutput \"all_instance_ips\" {\n  value = aws_instance.web[*].private_ip\n}\n\n# Conditional creation\nvariable \"create_database\" {\n  type    = bool\n  default = true\n}\n\nresource \"aws_db_instance\" \"main\" {\n  count = var.create_database ? 1 : 0  # Create only if true\n  \n  engine         = \"mysql\"\n  instance_class = \"db.t3.micro\"\n}\n\n# Create different number per environment\nvariable \"environment\" {\n  default = \"prod\"\n}\n\nresource \"aws_instance\" \"app\" {\n  count = var.environment == \"prod\" ? 5 : (\n          var.environment == \"staging\" ? 3 : 1\n  )\n  \n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n}\n```\n\n---\n\n#### **2. `for_each` - Create Resources from Map/Set**\n\n```hcl\n# From set\nvariable \"users\" {\n  type    = set(string)\n  default = [\"john\", \"jane\", \"bob\"]\n}\n\nresource \"aws_iam_user\" \"users\" {\n  for_each = var.users\n  name     = each.key  # \"john\", \"jane\", \"bob\"\n}\n\n# From map\nvariable \"instances\" {\n  type = map(object({\n    instance_type = string\n    ami           = string\n  }))\n  \n  default = {\n    web = {\n      instance_type = \"t2.micro\"\n      ami           = \"ami-12345\"\n    }\n    api = {\n      instance_type = \"t2.small\"\n      ami           = \"ami-12345\"\n    }\n    worker = {\n      instance_type = \"t2.medium\"\n      ami           = \"ami-67890\"\n    }\n  }\n}\n\nresource \"aws_instance\" \"servers\" {\n  for_each = var.instances\n  \n  ami           = each.value.ami\n  instance_type = each.value.instance_type\n  \n  tags = {\n    Name = \"${each.key}-server\"  # \"web-server\", \"api-server\", \"worker-server\"\n    Type = each.key\n  }\n}\n\n# Reference specific resource\noutput \"web_server_ip\" {\n  value = aws_instance.servers[\"web\"].private_ip\n}\n\n# Reference all resources\noutput \"all_server_ips\" {\n  value = {\n    for key, instance in aws_instance.servers :\n    key => instance.private_ip\n  }\n}\n\n# Complex example: Create subnets\nvariable \"availability_zones\" {\n  type = map(string)\n  default = {\n    \"us-east-1a\" = \"10.0.1.0/24\"\n    \"us-east-1b\" = \"10.0.2.0/24\"\n    \"us-east-1c\" = \"10.0.3.0/24\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  for_each = var.availability_zones\n  \n  vpc_id            = aws_vpc.main.id\n  availability_zone = each.key\n  cidr_block        = each.value\n  \n  tags = {\n    Name = \"public-subnet-${each.key}\"\n  }\n}\n```\n\n**`count` vs `for_each`:**\n\n| Feature | count | for_each |\n|---------|-------|----------|\n| Input | Number | Map or Set |\n| Index | Numeric (0, 1, 2) | String keys |\n| Adding/Removing | Can cause recreation | Stable - no recreation |\n| Use When | Same configuration | Different configurations |\n| Best For | Simple duplication | Named resources |\n\n---\n\n#### **3. `depends_on` - Manual Dependencies**\n\n```hcl\n# Covered above - forces creation order\nresource \"aws_instance\" \"app\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  depends_on = [\n    aws_db_instance.main,\n    aws_s3_bucket.data,\n    aws_iam_role_policy_attachment.app_policy\n  ]\n}\n```\n\n---\n\n#### **4. `provider` - Use Specific Provider**\n\n```hcl\n# Multi-region deployment\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nprovider \"aws\" {\n  alias  = \"west\"\n  region = \"us-west-2\"\n}\n\n# Default provider (us-east-1)\nresource \"aws_instance\" \"east\" {\n  ami           = \"ami-east-12345\"\n  instance_type = \"t2.micro\"\n}\n\n# West provider\nresource \"aws_instance\" \"west\" {\n  provider      = aws.west\n  ami           = \"ami-west-12345\"\n  instance_type = \"t2.micro\"\n}\n```\n\n---\n\n#### **5. `lifecycle` - Control Resource Behavior**\n\n```hcl\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  lifecycle {\n    # Create new resource before destroying old one\n    create_before_destroy = true\n    \n    # Prevent accidental deletion\n    prevent_destroy = true\n    \n    # Ignore changes to specific attributes\n    ignore_changes = [\n      tags,\n      user_data,\n    ]\n    \n    # Ignore all changes (rare use case)\n    # ignore_changes = all\n    \n    # Custom conditions\n    precondition {\n      condition     = var.environment == \"prod\"\n      error_message = \"This resource can only be created in production.\"\n    }\n    \n    postcondition {\n      condition     = self.instance_state == \"running\"\n      error_message = \"Instance must be in running state.\"\n    }\n  }\n}\n```\n\n**Lifecycle options explained:**\n\n**`create_before_destroy`:**\n```hcl\n# Useful for zero-downtime updates\nresource \"aws_launch_configuration\" \"app\" {\n  image_id      = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# When you change AMI:\n# 1. Create new launch configuration\n# 2. Update references to new config\n# 3. Delete old launch configuration\n```\n\n**`prevent_destroy`:**\n```hcl\n# Protect critical resources\nresource \"aws_db_instance\" \"production\" {\n  engine         = \"mysql\"\n  instance_class = \"db.t3.large\"\n  \n  lifecycle {\n    prevent_destroy = true  # terraform destroy will fail\n  }\n}\n```\n\n**`ignore_changes`:**\n```hcl\n# Don't revert external changes\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags = {\n    Name = \"web-server\"\n  }\n  \n  lifecycle {\n    # If someone manually changes tags, Terraform won't revert them\n    ignore_changes = [tags]\n    \n    # Ignore user_data changes (common for auto-updated startup scripts)\n    ignore_changes = [user_data]\n  }\n}\n```\n\n**Conditions (Terraform 1.2+):**\n```hcl\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"instance_type\" {\n  type = string\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-12345\"\n  instance_type = var.instance_type\n  \n  lifecycle {\n    # Check BEFORE creating\n    precondition {\n      condition     = var.environment == \"prod\" ? contains([\"t3.large\", \"t3.xlarge\"], var.instance_type) : true\n      error_message = \"Production instances must be t3.large or larger.\"\n    }\n    \n    # Check AFTER creating\n    postcondition {\n      condition     = self.instance_state == \"running\"\n      error_message = \"Instance failed to start. State: ${self.instance_state}\"\n    }\n  }\n}\n```\n\n---\n\n### üì¶ Resource Addressing\n\n```hcl\n# Single resource\nresource \"aws_instance\" \"web\" {\n  ami = \"ami-12345\"\n}\n# Address: aws_instance.web\n\n# With count\nresource \"aws_instance\" \"app\" {\n  count = 3\n  ami   = \"ami-12345\"\n}\n# Address: aws_instance.app[0], aws_instance.app[1], aws_instance.app[2]\n\n# With for_each\nresource \"aws_instance\" \"server\" {\n  for_each = toset([\"web\", \"api\", \"worker\"])\n  ami      = \"ami-12345\"\n}\n# Address: aws_instance.server[\"web\"], aws_instance.server[\"api\"]\n\n# In modules\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n}\n# Address: module.vpc.aws_vpc.main\n```\n\n---\n\n### üîÑ Resource Behavior\n\n#### **Create:**\n```bash\nterraform apply\n# Creates new resources\n```\n\n#### **Update (In-Place):**\n```hcl\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"  # Change this to t2.small\n  \n  tags = {\n    Name = \"web-server\"  # Change tags\n  }\n}\n```\n```bash\nterraform apply\n# Updates existing resource without recreation\n# ~ indicates in-place update\n```\n\n#### **Replace (Destroy + Create):**\n```hcl\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-12345\"  # Change AMI (requires new instance)\n  instance_type = \"t2.micro\"\n}\n```\n```bash\nterraform apply\n# -/+ indicates destroy and recreate\n```\n\n#### **Delete:**\n```hcl\n# Remove resource from configuration\n# resource \"aws_instance\" \"web\" {\n#   ...\n# }\n```\n```bash\nterraform apply\n# - indicates deletion\n```\n\n---\n\n### ‚úÖ Day 5 Checklist\n\n- [x] Understand resource block syntax\n- [x] Reference resources and attributes\n- [x] Implicit vs explicit dependencies\n- [x] All meta-arguments (count, for_each, depends_on, provider, lifecycle)\n- [x] Resource addressing\n- [x] Resource behavior (create, update, replace, delete)\n\n**Next:** Variables - Making configurations dynamic!\n\n---\n\n## Day 6: Variables - Dynamic Configuration\n\n### üéØ Learning Objectives\n- Master all variable types\n- Set variable values multiple ways\n- Use variable validation\n- Understand variable precedence\n- Create reusable configurations\n\n---\n\n### üì• Input Variables\n\nVariables make your Terraform code reusable and flexible.\n\n#### **Basic Variable Declaration**\n\n```hcl\n# File: variables.tf\n\n# String variable\nvariable \"region\" {\n  type        = string\n  description = \"AWS region to deploy resources\"\n  default     = \"us-east-1\"\n}\n\n# Number variable\nvariable \"instance_count\" {\n  type        = number\n  description = \"Number of EC2 instances to create\"\n  default     = 3\n}\n\n# Boolean variable\nvariable \"enable_monitoring\" {\n  type        = bool\n  description = \"Enable detailed monitoring\"\n  default     = true\n}\n\n# List variable\nvariable \"availability_zones\" {\n  type        = list(string)\n  description = \"List of availability zones\"\n  default     = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n}\n\n# Map variable\nvariable \"instance_types\" {\n  type        = map(string)\n  description = \"Instance types per environment\"\n  default = {\n    dev     = \"t2.micro\"\n    staging = \"t2.small\"\n    prod    = \"t3.large\"\n  }\n}\n\n# Object variable\nvariable \"database_config\" {\n  type = object({\n    engine            = string\n    engine_version    = string\n    instance_class    = string\n    allocated_storage = number\n    multi_az          = bool\n  })\n  \n  description = \"Database configuration\"\n  \n  default = {\n    engine            = \"mysql\"\n    engine_version    = \"8.0.33\"\n    instance_class    = \"db.t3.micro\"\n    allocated_storage = 20\n    multi_az          = false\n  }\n}\n\n# Set variable (unique values only)\nvariable \"allowed_ips\" {\n  type        = set(string)\n  description = \"Allowed IP addresses\"\n  default     = [\"203.0.113.0/24\", \"198.51.100.0/24\"]\n}\n\n# Any type (not recommended for production)\nvariable \"custom_config\" {\n  type        = any\n  description = \"Custom configuration\"\n  default     = {}\n}\n```\n\n---\n\n### üé® Variable Types Reference\n\n```hcl\n# Primitive Types\nvariable \"string_var\" {\n  type = string\n}\n\nvariable \"number_var\" {\n  type = number\n}\n\nvariable \"bool_var\" {\n  type = bool\n}\n\n# Collection Types\nvariable \"list_var\" {\n  type = list(string)  # List of strings\n}\n\nvariable \"list_numbers\" {\n  type = list(number)  # List of numbers\n}\n\nvariable \"map_var\" {\n  type = map(string)  # Map with string values\n}\n\nvariable \"set_var\" {\n  type = set(string)  # Set of unique strings\n}\n\n# Structural Types\nvariable \"object_var\" {\n  type = object({\n    name   = string\n    age    = number\n    active = bool\n  })\n}\n\nvariable \"tuple_var\" {\n  type = tuple([string, number, bool])\n}\n\n# Complex nested types\nvariable \"complex_var\" {\n  type = map(object({\n    instance_type = string\n    tags          = map(string)\n    volumes       = list(object({\n      size = number\n      type = string\n    }))\n  }))\n}\n```\n\n---\n\n### ‚öôÔ∏è Using Variables\n\n```hcl\n# File: main.tf\n\n# Use with var prefix\nresource \"aws_instance\" \"web\" {\n  ami           = var.ami_id\n  instance_type = var.instance_types[var.environment]\n  monitoring    = var.enable_monitoring\n  \n  count = var.instance_count\n  \n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"web-server-${count.index + 1}\"\n    }\n  )\n}\n\n# Use in locals\nlocals {\n  full_name = \"${var.project}-${var.environment}-${var.region}\"\n  \n  is_production = var.environment == \"prod\"\n  \n  instance_type = local.is_production ? \"t3.large\" : \"t2.micro\"\n}\n\n# Use in outputs\noutput \"instance_ips\" {\n  value = aws_instance.web[*].private_ip\n}\n```\n\n---\n\n### üìù Setting Variable Values\n\n#### **Method 1: Default Values (Lowest Priority)**\n\n```hcl\nvariable \"region\" {\n  type    = string\n  default = \"us-east-1\"  # Used if no other value provided\n}\n```\n\n---\n\n#### **Method 2: Command Line**\n\n```bash\n# Single variable\nterraform apply -var=\"region=us-west-2\"\n\n# Multiple variables\nterraform apply \\\n  -var=\"region=us-west-2\" \\\n  -var=\"instance_count=5\" \\\n  -var=\"enable_monitoring=true\"\n\n# List variable\nterraform apply -var='availability_zones=[\"us-west-2a\",\"us-west-2b\"]'\n\n# Map variable\nterraform apply -var='instance_types={dev=\"t2.micro\",prod=\"t3.large\"}'\n```\n\n---\n\n#### **Method 3: Variable Files (.tfvars)**\n\n```hcl\n# File: terraform.tfvars (automatically loaded)\nregion         = \"us-west-2\"\ninstance_count = 5\nenable_monitoring = true\n\navailability_zones = [\n  \"us-west-2a\",\n  \"us-west-2b\",\n  \"us-west-2c\"\n]\n\ninstance_types = {\n  dev     = \"t2.micro\"\n  staging = \"t2.small\"\n  prod    = \"t3.large\"\n}\n\ndatabase_config = {\n  engine            = \"postgresql\"\n  engine_version    = \"14.7\"\n  instance_class    = \"db.t3.small\"\n  allocated_storage = 50\n  multi_az          = true\n}\n\ncommon_tags = {\n  Project     = \"MyApp\"\n  Team        = \"Platform\"\n  ManagedBy   = \"Terraform\"\n}\n```\n\n```hcl\n# File: prod.tfvars (load explicitly)\nenvironment       = \"prod\"\ninstance_count    = 10\nenable_monitoring = true\ninstance_type     = \"t3.large\"\n```\n\n```bash\n# Load specific file\nterraform apply -var-file=\"prod.tfvars\"\n\n# Load multiple files\nterraform apply -var-file=\"common.tfvars\" -var-file=\"prod.tfvars\"\n```\n\n---\n\n#### **Method 4: Environment Variables**\n\n```bash\n# Format: TF_VAR_<variable_name>\n\n# String\nexport TF_VAR_region=\"us-west-2\"\n\n# Number\nexport TF_VAR_instance_count=5\n\n# Boolean\nexport TF_VAR_enable_monitoring=true\n\n# List (JSON)\nexport TF_VAR_availability_zones='[\"us-west-2a\",\"us-west-2b\"]'\n\n# Map (JSON)\nexport TF_VAR_instance_types='{\"dev\":\"t2.micro\",\"prod\":\"t3.large\"}'\n\n# Object (JSON)\nexport TF_VAR_database_config='{\n  \"engine\": \"mysql\",\n  \"engine_version\": \"8.0\",\n  \"instance_class\": \"db.t3.micro\",\n  \"allocated_storage\": 20,\n  \"multi_az\": false\n}'\n\n# Then run\nterraform apply\n```\n\n---\n\n#### **Method 5: Interactive Prompt**\n\n```hcl\n# Variable without default\nvariable \"database_password\" {\n  type        = string\n  description = \"Database admin password\"\n  sensitive   = true\n  # No default - will prompt\n}\n```\n\n```bash\nterraform apply\n# Terraform will prompt:\n# var.database_password\n#   Database admin password\n#\n#   Enter a value: ‚ñà\n```\n\n---\n\n### üìä Variable Precedence (Highest to Lowest)\n\n```plaintext\n1. Command line -var flags         (highest priority)\n2. *.auto.tfvars files (alphabetical order)\n3. terraform.tfvars file\n4. Environment variables (TF_VAR_*)\n5. Default values in variable blocks (lowest priority)\n```\n\n**Example:**\n```hcl\n# variables.tf\nvariable \"region\" {\n  default = \"us-east-1\"  # Priority 5\n}\n```\n\n```bash\n# Environment\nexport TF_VAR_region=\"us-west-1\"  # Priority 4\n\n# terraform.tfvars\nregion = \"us-west-2\"  # Priority 3\n\n# prod.auto.tfvars\nregion = \"eu-west-1\"  # Priority 2\n\n# Command line\nterraform apply -var=\"region=ap-south-1\"  # Priority 1 - WINS!\n# Final value: \"ap-south-1\"\n```\n\n---\n\n### ‚úÖ Variable Validation\n\n```hcl\n# Validate environment name\nvariable \"environment\" {\n  type        = string\n  description = \"Environment name\"\n  \n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n\n# Validate instance count\nvariable \"instance_count\" {\n  type        = number\n  description = \"Number of instances\"\n  \n  validation {\n    condition     = var.instance_count >= 1 && var.instance_count <= 10\n    error_message = \"Instance count must be between 1 and 10.\"\n  }\n}\n\n# Validate CIDR block\nvariable \"vpc_cidr\" {\n  type        = string\n  description = \"VPC CIDR block\"\n  \n  validation {\n    condition     = can(regex(\"^([0-9]{1,3}\\\\.){3}[0-9]{1,3}/[0-9]{1,2}$\", var.vpc_cidr))\n    error_message = \"VPC CIDR must be a valid IPv4 CIDR block.\"\n  }\n}\n\n# Validate region\nvariable \"region\" {\n  type        = string\n  description = \"AWS region\"\n  \n  validation {\n    condition     = can(regex(\"^(us|eu|ap|sa|ca|me|af)-(north|south|east|west|central|northeast|southeast)-[1-3]$\", var.region))\n    error_message = \"Must be a valid AWS region.\"\n  }\n}\n\n# Multiple validations\nvariable \"instance_type\" {\n  type        = string\n  description = \"EC2 instance type\"\n  \n  validation {\n    condition     = can(regex(\"^t[2-3]\\\\.\", var.instance_type))\n    error_message = \"Instance type must be t2 or t3 series.\"\n  }\n  \n  validation {\n    condition     = contains([\"t2.micro\", \"t2.small\", \"t3.micro\", \"t3.small\"], var.instance_type)\n    error_message = \"Instance type must be micro or small.\"\n  }\n}\n\n# Complex validation\nvariable \"database_config\" {\n  type = object({\n    engine            = string\n    allocated_storage = number\n    multi_az          = bool\n  })\n  \n  validation {\n    condition     = contains([\"mysql\", \"postgres\", \"mariadb\"], var.database_config.engine)\n    error_message = \"Database engine must be mysql, postgres, or mariadb.\"\n  }\n  \n  validation {\n    condition     = var.database_config.allocated_storage >= 20\n    error_message = \"Database storage must be at least 20 GB.\"\n  }\n  \n  validation {\n    condition     = var.database_config.engine == \"postgres\" ? var.database_config.allocated_storage >= 50 : true\n    error_message = \"PostgreSQL requires at least 50 GB storage.\"\n  }\n}\n```\n\n---\n\n### üîê Sensitive Variables\n\n```hcl\nvariable \"database_password\" {\n  type        = string\n  description = \"Database admin password\"\n  sensitive   = true  # Won't show in logs/output\n}\n\nvariable \"api_key\" {\n  type      = string\n  sensitive = true\n}\n\n# Using sensitive variables\nresource \"aws_db_instance\" \"main\" {\n  engine         = \"mysql\"\n  username       = \"admin\"\n  password       = var.database_password  # Value hidden in logs\n  instance_class = \"db.t3.micro\"\n}\n\n# Output won't show value\noutput \"db_password\" {\n  value     = var.database_password\n  sensitive = true\n}\n```\n\n---\n\n### üéì Real-World Example: Complete Variable Setup\n\n```hcl\n# ==========================================\n# File: variables.tf\n# ==========================================\n\n# Project Info\nvariable \"project_name\" {\n  type        = string\n  description = \"Project name for resource naming\"\n  \n  validation {\n    condition     = length(var.project_name) > 0 && length(var.project_name) <= 20\n    error_message = \"Project name must be 1-20 characters.\"\n  }\n}\n\nvariable \"environment\" {\n  type        = string\n  description = \"Environment (dev/staging/prod)\"\n  \n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n\n# AWS Configuration\nvariable \"region\" {\n  type        = string\n  description = \"AWS region\"\n  default     = \"us-east-1\"\n}\n\nvariable \"availability_zones\" {\n  type        = list(string)\n  description = \"Availability zones\"\n  default     = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n}\n\n# Networking\nvariable \"vpc_cidr\" {\n  type        = string\n  description = \"VPC CIDR block\"\n  default     = \"10.0.0.0/16\"\n  \n  validation {\n    condition     = can(cidrhost(var.vpc_cidr, 0))\n    error_message = \"Must be a valid CIDR block.\"\n  }\n}\n\nvariable \"public_subnet_cidrs\" {\n  type        = list(string)\n  description = \"Public subnet CIDR blocks\"\n  default     = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n}\n\nvariable \"private_subnet_cidrs\" {\n  type        = list(string)\n  description = \"Private subnet CIDR blocks\"\n  default     = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n}\n\n# Compute\nvariable \"instance_config\" {\n  type = map(object({\n    instance_type = string\n    instance_count = number\n    volume_size    = number\n  }))\n  \n  description = \"Instance configuration per environment\"\n  \n  default = {\n    dev = {\n      instance_type  = \"t2.micro\"\n      instance_count = 1\n      volume_size    = 20\n    }\n    staging = {\n      instance_type  = \"t2.small\"\n      instance_count = 2\n      volume_size    = 30\n    }\n    prod = {\n      instance_type  = \"t3.large\"\n      instance_count = 5\n      volume_size    = 50\n    }\n  }\n}\n\n# Database\nvariable \"create_database\" {\n  type        = bool\n  description = \"Whether to create database\"\n  default     = true\n}\n\nvariable \"database_config\" {\n  type = object({\n    engine            = string\n    engine_version    = string\n    instance_class    = string\n    allocated_storage = number\n    multi_az          = bool\n    backup_retention  = number\n  })\n  \n  description = \"Database configuration\"\n  \n  default = {\n    engine            = \"mysql\"\n    engine_version    = \"8.0.33\"\n    instance_class    = \"db.t3.micro\"\n    allocated_storage = 20\n    multi_az          = false\n    backup_retention  = 7\n  }\n}\n\nvariable \"database_password\" {\n  type        = string\n  description = \"Database admin password\"\n  sensitive   = true\n}\n\n# Tags\nvariable \"common_tags\" {\n  type        = map(string)\n  description = \"Common tags for all resources\"\n  default     = {}\n}\n\n# Feature Flags\nvariable \"enable_monitoring\" {\n  type        = bool\n  description = \"Enable detailed monitoring\"\n  default     = false\n}\n\nvariable \"enable_auto_scaling\" {\n  type        = bool\n  description = \"Enable auto scaling\"\n  default     = false\n}\n\n# ==========================================\n# File: terraform.tfvars\n# ==========================================\n\nproject_name = \"myapp\"\nenvironment  = \"dev\"\nregion       = \"us-east-1\"\n\navailability_zones = [\"us-east-1a\", \"us-east-1b\"]\n\nvpc_cidr = \"10.0.0.0/16\"\n\npublic_subnet_cidrs  = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\nprivate_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\"]\n\ncreate_database = true\n\ncommon_tags = {\n  Project    = \"MyApp\"\n  Team       = \"Platform\"\n  ManagedBy  = \"Terraform\"\n  CostCenter = \"Engineering\"\n}\n\nenable_monitoring    = false\nenable_auto_scaling  = false\n\n# ==========================================\n# File: prod.tfvars\n# ==========================================\n\nenvironment = \"prod\"\nregion      = \"us-east-1\"\n\navailability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n\ndatabase_config = {\n  engine            = \"mysql\"\n  engine_version    = \"8.0.33\"\n  instance_class    = \"db.r5.large\"\n  allocated_storage = 100\n  multi_az          = true\n  backup_retention  = 30\n}\n\nenable_monitoring   = true\nenable_auto_scaling = true\n\ncommon_tags = {\n  Project     = \"MyApp\"\n  Team        = \"Platform\"\n  Environment = \"Production\"\n  ManagedBy   = \"Terraform\"\n  CostCenter  = \"Engineering\"\n  Compliance  = \"Required\"\n}\n\n# ==========================================\n# File: main.tf (using variables)\n# ==========================================\n\nlocals {\n  name_prefix = \"${var.project_name}-${var.environment}\"\n  config      = var.instance_config[var.environment]\n  \n  all_tags = merge(\n    var.common_tags,\n    {\n      Environment = var.environment\n      Region      = var.region\n    }\n  )\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n  \n  tags = merge(\n    local.all_tags,\n    {\n      Name = \"${local.name_prefix}-vpc\"\n    }\n  )\n}\n\nresource \"aws_subnet\" \"public\" {\n  count = length(var.public_subnet_cidrs)\n  \n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = var.availability_zones[count.index]\n  map_public_ip_on_launch = true\n  \n  tags = merge(\n    local.all_tags,\n    {\n      Name = \"${local.name_prefix}-public-${var.availability_zones[count.index]}\"\n      Type = \"public\"\n    }\n  )\n}\n\nresource \"aws_instance\" \"app\" {\n  count = local.config.instance_count\n  \n  ami           = data.aws_ami.amazon_linux_2.id\n  instance_type = local.config.instance_type\n  subnet_id     = aws_subnet.public[count.index % length(aws_subnet.public)].id\n  monitoring    = var.enable_monitoring\n  \n  root_block_device {\n    volume_size = local.config.volume_size\n  }\n  \n  tags = merge(\n    local.all_tags,\n    {\n      Name  = \"${local.name_prefix}-app-${count.index + 1}\"\n      Index = count.index + 1\n    }\n  )\n}\n\nresource \"aws_db_instance\" \"main\" {\n  count = var.create_database ? 1 : 0\n  \n  identifier          = \"${local.name_prefix}-db\"\n  engine              = var.database_config.engine\n  engine_version      = var.database_config.engine_version\n  instance_class      = var.database_config.instance_class\n  allocated_storage   = var.database_config.allocated_storage\n  multi_az            = var.database_config.multi_az\n  backup_retention_period = var.database_config.backup_retention\n  \n  username = \"admin\"\n  password = var.database_password\n  \n  skip_final_snapshot = var.environment != \"prod\"\n  \n  tags = merge(\n    local.all_tags,\n    {\n      Name = \"${local.name_prefix}-db\"\n    }\n  )\n}\n```\n\n**Using this setup:**\n\n```bash\n# Development\nterraform apply\n\n# Staging\nterraform apply -var=\"environment=staging\"\n\n# Production\nterraform apply -var-file=\"prod.tfvars\"\n\n# With password from environment\nexport TF_VAR_database_password=\"super-secret-password\"\nterraform apply -var-file=\"prod.tfvars\"\n```\n\n---\n\n### ‚úÖ Day 6 Checklist\n\n- [x] All variable types\n- [x] Variable declaration syntax\n- [x] All methods to set variable values\n- [x] Variable precedence\n- [x] Variable validation\n- [x] Sensitive variables\n- [x] Real-world variable organization\n\n**Next:** Outputs - Extracting information!\n\n---\n\n## Day 7: Outputs & Data Sources\n\n### üéØ Learning Objectives\n- Extract and display information with outputs\n- Query existing infrastructure with data sources\n- Share data between configurations\n- Use outputs in modules\n\n---\n\n### üì§ Output Values\n\nOutputs extract information from your Terraform configuration to:\n- Display after `terraform apply`\n- Pass to other Terraform configurations\n- Use in automation scripts\n- Share between modules\n\n#### **Basic Output Syntax**\n\n```hcl\noutput \"output_name\" {\n  description = \"What this output represents\"\n  value       = expression_to_output\n  sensitive   = false  # Optional\n  depends_on  = []     # Optional\n}\n```\n\n---\n\n### üé® Output Examples\n\n#### **Simple Outputs**\n\n```hcl\n# File: outputs.tf\n\n# Single value\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\n# Computed attribute\noutput \"instance_public_ip\" {\n  description = \"Public IP address of the instance\"\n  value       = aws_instance.web.public_ip\n}\n\n# Using locals\nlocals {\n  environment = \"production\"\n}\n\noutput \"environment\" {\n  description = \"Current environment\"\n  value       = local.environment\n}\n\n# Conditional output\noutput \"database_endpoint\" {\n  description = \"Database endpoint (if created)\"\n  value       = var.create_database ? aws_db_instance.main[0].endpoint : \"No database\"\n}\n```\n\n---\n\n#### **List Outputs**\n\n```hcl\n# All instance IDs\noutput \"instance_ids\" {\n  description = \"IDs of all instances\"\n  value       = aws_instance.web[*].id\n  # Result: [\"i-1234567890abcdef0\", \"i-0fedcba0987654321\"]\n}\n\n# All private IPs\noutput \"private_ips\" {\n  description = \"Private IP addresses\"\n  value       = aws_instance.web[*].private_ip\n  # Result: [\"10.0.1.10\", \"10.0.1.11\", \"10.0.1.12\"]\n}\n\n# Subnet IDs\noutput \"public_subnet_ids\" {\n  description = \"IDs of public subnets\"\n  value       = aws_subnet.public[*].id\n}\n```\n\n---\n\n#### **Map Outputs**\n\n```hcl\n# With for_each - creates map\nresource \"aws_instance\" \"servers\" {\n  for_each = toset([\"web\", \"api\", \"worker\"])\n  \n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags = {\n    Name = \"${each.key}-server\"\n  }\n}\n\n# Output as map\noutput \"server_ips\" {\n  description = \"Map of server names to IP addresses\"\n  value = {\n    for key, instance in aws_instance.servers :\n    key => instance.private_ip\n  }\n  # Result: {\n  #   web    = \"10.0.1.10\"\n  #   api    = \"10.0.1.11\"\n  #   worker = \"10.0.1.12\"\n  # }\n}\n\n# Specific keys\noutput \"web_server_ip\" {\n  description = \"Web server IP\"\n  value       = aws_instance.servers[\"web\"].private_ip\n}\n```\n\n---\n\n#### **Complex Outputs**\n\n```hcl\n# Object output\noutput \"database_info\" {\n  description = \"Complete database information\"\n  value = {\n    endpoint           = aws_db_instance.main.endpoint\n    port               = aws_db_instance.main.port\n    database_name      = aws_db_instance.main.db_name\n    connection_string  = \"mysql://${aws_db_instance.main.endpoint}/${aws_db_instance.main.db_name}\"\n  }\n}\n\n# Nested output\noutput \"infrastructure_summary\" {\n  description = \"Complete infrastructure summary\"\n  value = {\n    vpc = {\n      id         = aws_vpc.main.id\n      cidr_block = aws_vpc.main.cidr_block\n      region     = var.region\n    }\n    instances = {\n      count      = length(aws_instance.web)\n      ids        = aws_instance.web[*].id\n      public_ips = aws_instance.web[*].public_ip\n    }\n    database = var.create_database ? {\n      endpoint = aws_db_instance.main[0].endpoint\n      port     = aws_db_instance.main[0].port\n    } : null\n  }\n}\n\n# Transformed output\noutput \"instance_details\" {\n  description = \"Detailed instance information\"\n  value = [\n    for i, instance in aws_instance.web : {\n      index      = i + 1\n      id         = instance.id\n      public_ip  = instance.public_ip\n      private_ip = instance.private_ip\n      az         = instance.availability_zone\n      url        = \"http://${instance.public_ip}\"\n    }\n  ]\n}\n```\n\n---\n\n#### **Sensitive Outputs**\n\n```hcl\n# Hide sensitive data\noutput \"database_password\" {\n  description = \"Database admin password\"\n  value       = aws_db_instance.main.password\n  sensitive   = true  # Won't show in console\n}\n\noutput \"api_key\" {\n  description = \"API key for external service\"\n  value       = random_password.api_key.result\n  sensitive   = true\n}\n\n# When you run terraform apply:\n# Outputs:\n#\n# database_password = <sensitive>\n# api_key = <sensitive>\n\n# To see the value:\nterraform output database_password\n# or\nterraform output -json\n```\n\n---\n\n#### **Outputs with Dependencies**\n\n```hcl\n# Explicit dependency\noutput \"instance_ready\" {\n  description = \"Message when instance is ready\"\n  value       = \"Instance ${aws_instance.web.id} is ready\"\n  \n  depends_on = [\n    aws_instance.web,\n    aws_eip.web,\n    aws_security_group.web\n  ]\n}\n```\n\n---\n\n### üì• Using Outputs\n\n#### **1. View Outputs After Apply**\n\n```bash\n# During terraform apply\nterraform apply\n\n# Outputs:\n#\n# instance_ip = \"54.123.45.67\"\n# vpc_id = \"vpc-1234567890abcdef0\"\n```\n\n#### **2. Query Specific Output**\n\n```bash\n# Get specific output\nterraform output instance_ip\n# 54.123.45.67\n\n# Get as JSON\nterraform output -json instance_ip\n# \"54.123.45.67\"\n\n# Get all outputs\nterraform output\n\n# Get all outputs as JSON\nterraform output -json\n```\n\n#### **3. Use in Shell Scripts**\n\n```bash\n#!/bin/bash\n\n# Get output value\nINSTANCE_IP=$(terraform output -raw instance_ip)\n\n# Use it\necho \"Connecting to $INSTANCE_IP\"\nssh ec2-user@$INSTANCE_IP\n\n# Get JSON output\nDATABASE_INFO=$(terraform output -json database_info)\nENDPOINT=$(echo $DATABASE_INFO | jq -r '.endpoint')\n\necho \"Database endpoint: $ENDPOINT\"\n```\n\n#### **4. Pass to Another Terraform Configuration**\n\n```hcl\n# Configuration A: outputs.tf\noutput \"vpc_id\" {\n  value = aws_vpc.main.id\n}\n\noutput \"subnet_ids\" {\n  value = aws_subnet.private[*].id\n}\n```\n\n```hcl\n# Configuration B: data.tf\ndata \"terraform_remote_state\" \"vpc\" {\n  backend = \"s3\"\n  \n  config = {\n    bucket = \"my-terraform-state\"\n    key    = \"vpc/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n\n# Use outputs from Configuration A\nresource \"aws_instance\" \"app\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  subnet_id     = data.terraform_remote_state.vpc.outputs.subnet_ids[0]\n  \n  tags = {\n    VPC = data.terraform_remote_state.vpc.outputs.vpc_id\n  }\n}\n```\n\n---\n\n### üìä Data Sources\n\nData sources **query** existing infrastructure (not managed by Terraform):\n- AWS AMIs\n- Existing VPCs\n- Route53 zones\n- IAM policies\n- Any resource created outside Terraform\n\n#### **Data Source Syntax**\n\n```hcl\ndata \"provider_datasource\" \"name\" {\n  # Filter/query arguments\n  argument1 = \"value1\"\n  argument2 = \"value2\"\n}\n\n# Reference: data.provider_datasource.name.attribute\n```\n\n---\n\n### üîç Common Data Sources\n\n#### **AWS AMI (Latest Amazon Linux)**\n\n```hcl\ndata \"aws_ami\" \"amazon_linux_2\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n  \n  filter {\n    name   = \"name\"\n    values = [\"amzn2-ami-hvm-*-x86_64-gp2\"]\n  }\n  \n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\n# Use in resource\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.amazon_linux_2.id\n  instance_type = \"t2.micro\"\n}\n\n# Output AMI details\noutput \"ami_info\" {\n  value = {\n    id           = data.aws_ami.amazon_linux_2.id\n    name         = data.aws_ami.amazon_linux_2.name\n    architecture = data.aws_ami.amazon_linux_2.architecture\n    creation_date = data.aws_ami.amazon_linux_2.creation_date\n  }\n}\n```\n\n#### **Latest Ubuntu AMI**\n\n```hcl\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n  owners      = [\"099720109477\"]  # Canonical\n  \n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"]\n  }\n}\n\nresource \"aws_instance\" \"ubuntu_server\" {\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = \"t2.micro\"\n}\n```\n\n---\n\n#### **Existing VPC**\n\n```hcl\n# Query VPC by tag\ndata \"aws_vpc\" \"existing\" {\n  tags = {\n    Name = \"production-vpc\"\n  }\n}\n\n# Query default VPC\ndata \"aws_vpc\" \"default\" {\n  default = true\n}\n\n# Use VPC ID\nresource \"aws_subnet\" \"new_subnet\" {\n  vpc_id     = data.aws_vpc.existing.id\n  cidr_block = \"10.0.100.0/24\"\n}\n\noutput \"existing_vpc_info\" {\n  value = {\n    id         = data.aws_vpc.existing.id\n    cidr_block = data.aws_vpc.existing.cidr_block\n  }\n}\n```\n\n---\n\n#### **Availability Zones**\n\n```hcl\n# Get all available AZs in current region\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\n# Use in resources\nresource \"aws_subnet\" \"public\" {\n  count = length(data.aws_availability_zones.available.names)\n  \n  vpc_id            = aws_vpc.main.id\n  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index)\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n}\n\noutput \"available_azs\" {\n  value = data.aws_availability_zones.available.names\n  # [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\", ...]\n}\n```\n\n---\n\n#### **AWS Account Information**\n\n```hcl\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_region\" \"current\" {}\n\noutput \"account_info\" {\n  value = {\n    account_id = data.aws_caller_identity.current.account_id\n    caller_arn = data.aws_caller_identity.current.arn\n    user_id    = data.aws_caller_identity.current.user_id\n    region     = data.aws_region.current.name\n  }\n}\n\n# Use in resource naming\nresource \"aws_s3_bucket\" \"logs\" {\n  bucket = \"logs-${data.aws_caller_identity.current.account_id}-${data.aws_region.current.name}\"\n}\n```\n\n---\n\n#### **IAM Policy Document**\n\n```hcl\n# Create IAM policy using data source\ndata \"aws_iam_policy_document\" \"s3_read_access\" {\n  statement {\n    effect = \"Allow\"\n    \n    actions = [\n      \"s3:GetObject\",\n      \"s3:ListBucket\",\n    ]\n    \n    resources = [\n      \"arn:aws:s3:::my-bucket\",\n      \"arn:aws:s3:::my-bucket/*\",\n    ]\n  }\n  \n  statement {\n    effect = \"Allow\"\n    \n    actions = [\n      \"s3:PutObject\",\n    ]\n    \n    resources = [\n      \"arn:aws:s3:::my-bucket/uploads/*\",\n    ]\n  }\n}\n\n# Use in IAM policy\nresource \"aws_iam_policy\" \"s3_access\" {\n  name   = \"s3-access-policy\"\n  policy = data.aws_iam_policy_document.s3_read_access.json\n}\n\noutput \"policy_json\" {\n  value = data.aws_iam_policy_document.s3_read_access.json\n}\n```\n\n---\n\n#### **Route53 Zone**\n\n```hcl\n# Query hosted zone\ndata \"aws_route53_zone\" \"main\" {\n  name         = \"example.com\"\n  private_zone = false\n}\n\n# Create DNS record\nresource \"aws_route53_record\" \"www\" {\n  zone_id = data.aws_route53_zone.main.zone_id\n  name    = \"www.${data.aws_route53_zone.main.name}\"\n  type    = \"A\"\n  ttl     = 300\n  records = [aws_instance.web.public_ip]\n}\n```\n\n---\n\n#### **Subnet IDs**\n\n```hcl\n# Get subnets by filter\ndata \"aws_subnets\" \"private\" {\n  filter {\n    name   = \"vpc-id\"\n    values = [data.aws_vpc.existing.id]\n  }\n  \n  tags = {\n    Type = \"private\"\n  }\n}\n\n# Use subnet IDs\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"main-db-subnet-group\"\n  subnet_ids = data.aws_subnets.private.ids\n}\n\noutput \"private_subnet_ids\" {\n  value = data.aws_subnets.private.ids\n}\n```\n\n---\n\n#### **Security Group**\n\n```hcl\n# Query existing security group\ndata \"aws_security_group\" \"default\" {\n  vpc_id = data.aws_vpc.default.id\n  \n  filter {\n    name   = \"group-name\"\n    values = [\"default\"]\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.amazon_linux_2.id\n  instance_type = \"t2.micro\"\n  \n  vpc_security_group_ids = [data.aws_security_group.default.id]\n}\n```\n\n---\n\n#### **S3 Bucket**\n\n```hcl\n# Query existing bucket\ndata \"aws_s3_bucket\" \"logs\" {\n  bucket = \"my-logs-bucket\"\n}\n\noutput \"bucket_info\" {\n  value = {\n    arn           = data.aws_s3_bucket.logs.arn\n    region        = data.aws_s3_bucket.logs.region\n    hosted_zone_id = data.aws_s3_bucket.logs.hosted_zone_id\n  }\n}\n```\n\n---\n\n### üéì Real-World Example: Complete Setup\n\n```hcl\n# ==================================================\n# File: data.tf\n# ==================================================\n\n# Get current AWS account and region\ndata \"aws_caller_identity\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n\n# Get all available AZs\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\n# Get latest Amazon Linux 2 AMI\ndata \"aws_ami\" \"amazon_linux_2\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n  \n  filter {\n    name   = \"name\"\n    values = [\"amzn2-ami-hvm-*-x86_64-gp2\"]\n  }\n  \n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\n# Get existing VPC (if using existing)\ndata \"aws_vpc\" \"existing\" {\n  count = var.use_existing_vpc ? 1 : 0\n  \n  tags = {\n    Name = var.existing_vpc_name\n  }\n}\n\n# IAM policy for EC2 to access S3\ndata \"aws_iam_policy_document\" \"ec2_assume_role\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n    \n    principals {\n      type        = \"Service\"\n      identifiers = [\"ec2.amazonaws.com\"]\n    }\n  }\n}\n\ndata \"aws_iam_policy_document\" \"s3_access\" {\n  statement {\n    effect = \"Allow\"\n    \n    actions = [\n      \"s3:GetObject\",\n      \"s3:ListBucket\",\n    ]\n    \n    resources = [\n      \"arn:aws:s3:::${var.s3_bucket_name}\",\n      \"arn:aws:s3:::${var.s3_bucket_name}/*\",\n    ]\n  }\n}\n\n# ==================================================\n# File: main.tf\n# ==================================================\n\nlocals {\n  vpc_id = var.use_existing_vpc ? data.aws_vpc.existing[0].id : aws_vpc.main[0].id\n  \n  az_names = slice(\n    data.aws_availability_zones.available.names,\n    0,\n    min(var.az_count, length(data.aws_availability_zones.available.names))\n  )\n  \n  common_tags = {\n    Project     = var.project_name\n    Environment = var.environment\n    ManagedBy   = \"Terraform\"\n    AccountID   = data.aws_caller_identity.current.account_id\n    Region      = data.aws_region.current.name\n  }\n}\n\n# Create VPC (if not using existing)\nresource \"aws_vpc\" \"main\" {\n  count = var.use_existing_vpc ? 0 : 1\n  \n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-vpc\"\n    }\n  )\n}\n\n# Create subnets in each AZ\nresource \"aws_subnet\" \"public\" {\n  count = length(local.az_names)\n  \n  vpc_id                  = local.vpc_id\n  cidr_block              = cidrsubnet(var.vpc_cidr, 8, count.index)\n  availability_zone       = local.az_names[count.index]\n  map_public_ip_on_launch = true\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-public-${local.az_names[count.index]}\"\n      Type = \"public\"\n    }\n  )\n}\n\n# IAM role for EC2\nresource \"aws_iam_role\" \"ec2_role\" {\n  name               = \"${var.project_name}-ec2-role\"\n  assume_role_policy = data.aws_iam_policy_document.ec2_assume_role.json\n  \n  tags = local.common_tags\n}\n\nresource \"aws_iam_role_policy\" \"s3_access\" {\n  name   = \"s3-access\"\n  role   = aws_iam_role.ec2_role.id\n  policy = data.aws_iam_policy_document.s3_access.json\n}\n\nresource \"aws_iam_instance_profile\" \"ec2_profile\" {\n  name = \"${var.project_name}-ec2-profile\"\n  role = aws_iam_role.ec2_role.name\n  \n  depends_on = [aws_iam_role_policy.s3_access]\n}\n\n# EC2 instances using latest AMI\nresource \"aws_instance\" \"web\" {\n  count = var.instance_count\n  \n  ami                  = data.aws_ami.amazon_linux_2.id\n  instance_type        = var.instance_type\n  subnet_id            = aws_subnet.public[count.index % length(aws_subnet.public)].id\n  iam_instance_profile = aws_iam_instance_profile.ec2_profile.name\n  \n  user_data = <<-EOF\n    #!/bin/bash\n    yum update -y\n    yum install -y httpd\n    systemctl start httpd\n    systemctl enable httpd\n    \n    # Instance info page\n    cat > /var/www/html/index.html <<HTML\n    <h1>Server Info</h1>\n    <ul>\n      <li>Instance ID: $(ec2-metadata --instance-id | cut -d' ' -f2)</li>\n      <li>AZ: $(ec2-metadata --availability-zone | cut -d' ' -f2)</li>\n      <li>Region: ${data.aws_region.current.name}</li>\n      <li>Account: ${data.aws_caller_identity.current.account_id}</li>\n    </ul>\n    HTML\n  EOF\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name  = \"${var.project_name}-web-${count.index + 1}\"\n      Index = count.index + 1\n    }\n  )\n}\n\n# ==================================================\n# File: outputs.tf\n# ==================================================\n\n# Account & Region Info\noutput \"account_id\" {\n  description = \"AWS Account ID\"\n  value       = data.aws_caller_identity.current.account_id\n}\n\noutput \"region\" {\n  description = \"AWS Region\"\n  value       = data.aws_region.current.name\n}\n\noutput \"availability_zones\" {\n  description = \"Available AZs used\"\n  value       = local.az_names\n}\n\n# AMI Info\noutput \"ami_id\" {\n  description = \"AMI ID used for instances\"\n  value       = data.aws_ami.amazon_linux_2.id\n}\n\noutput \"ami_name\" {\n  description = \"AMI name\"\n  value       = data.aws_ami.amazon_linux_2.name\n}\n\n# VPC Info\noutput \"vpc_id\" {\n  description = \"VPC ID\"\n  value       = local.vpc_id\n}\n\noutput \"vpc_cidr\" {\n  description = \"VPC CIDR block\"\n  value       = var.use_existing_vpc ? data.aws_vpc.existing[0].cidr_block : aws_vpc.main[0].cidr_block\n}\n\n# Subnet Info\noutput \"subnet_ids\" {\n  description = \"List of subnet IDs\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"subnet_cidrs\" {\n  description = \"List of subnet CIDR blocks\"\n  value       = aws_subnet.public[*].cidr_block\n}\n\n# Instance Info\noutput \"instance_ids\" {\n  description = \"List of instance IDs\"\n  value       = aws_instance.web[*].id\n}\n\noutput \"instance_public_ips\" {\n  description = \"List of public IP addresses\"\n  value       = aws_instance.web[*].public_ip\n}\n\noutput \"instance_private_ips\" {\n  description = \"List of private IP addresses\"\n  value       = aws_instance.web[*].private_ip\n}\n\n# Detailed instance info\noutput \"instances_detail\" {\n  description = \"Detailed information about all instances\"\n  value = [\n    for i, instance in aws_instance.web : {\n      index      = i + 1\n      id         = instance.id\n      public_ip  = instance.public_ip\n      private_ip = instance.private_ip\n      az         = instance.availability_zone\n      subnet_id  = instance.subnet_id\n      url        = \"http://${instance.public_ip}\"\n    }\n  ]\n}\n\n# IAM Info\noutput \"iam_role_arn\" {\n  description = \"ARN of IAM role\"\n  value       = aws_iam_role.ec2_role.arn\n}\n\n# Summary\noutput \"infrastructure_summary\" {\n  description = \"Complete infrastructure summary\"\n  value = {\n    account = {\n      id     = data.aws_caller_identity.current.account_id\n      region = data.aws_region.current.name\n    }\n    network = {\n      vpc_id       = local.vpc_id\n      vpc_cidr     = var.use_existing_vpc ? data.aws_vpc.existing[0].cidr_block : aws_vpc.main[0].cidr_block\n      subnet_count = length(aws_subnet.public)\n      azs          = local.az_names\n    }\n    compute = {\n      instance_count = length(aws_instance.web)\n      ami_id         = data.aws_ami.amazon_linux_2.id\n      instance_type  = var.instance_type\n    }\n  }\n}\n\n# Connection string for SSH\noutput \"ssh_commands\" {\n  description = \"SSH commands to connect to instances\"\n  value = [\n    for instance in aws_instance.web :\n    \"ssh -i ~/.ssh/your-key.pem ec2-user@${instance.public_ip}\"\n  ]\n}\n\n# URLs to access web servers\noutput \"web_urls\" {\n  description = \"URLs to access web servers\"\n  value = [\n    for instance in aws_instance.web :\n    \"http://${instance.public_ip}\"\n  ]\n}\n```\n\n**Usage:**\n\n```bash\n# Apply configuration\nterraform apply\n\n# View specific output\nterraform output instance_public_ips\n\n# Get as JSON\nterraform output -json infrastructure_summary | jq\n\n# Use in script\nINSTANCE_IP=$(terraform output -raw instance_public_ips | jq -r '.[0]')\ncurl http://$INSTANCE_IP\n\n# SSH to first instance\neval $(terraform output ssh_commands | jq -r '.[0]')\n```\n\n---\n\n### ‚úÖ Day 7 Checklist\n\n- [x] Output syntax and types\n- [x] Simple, list, map, and complex outputs\n- [x] Sensitive outputs\n- [x] Using outputs in automation\n- [x] Data source syntax\n- [x] Common data sources (AMI, VPC, IAM, etc.)\n- [x] Querying existing infrastructure\n- [x] Complete real-world example\n\n**Next:** Advanced features - count, for_each, dynamic blocks!\n\n---\n\n## Day 8-9: Advanced Iteration & Dynamic Blocks\n\n### üéØ Learning Objectives\n- Master count vs for_each\n- Create dynamic resource blocks\n- Use for expressions\n- Implement conditional logic\n- Build flexible configurations\n\n---\n\n### üî¢ Count vs For_Each - Deep Dive\n\n#### **When to Use Count**\n\n‚úÖ **Use count when:**\n- Creating identical resources\n- Simple duplication\n- Resources are interchangeable\n- Order doesn't matter long-term\n\n```hcl\n# Example: Create 5 identical servers\nresource \"aws_instance\" \"web\" {\n  count = 5\n  \n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags = {\n    Name = \"web-server-${count.index + 1}\"\n  }\n}\n\n# Accessing resources\noutput \"first_instance\" {\n  value = aws_instance.web[0].id\n}\n\noutput \"all_instances\" {\n  value = aws_instance.web[*].id\n}\n```\n\n**‚ùå Problem with count:**\n```hcl\n# Initial: 3 instances\nvariable \"servers\" {\n  default = [\"web1\", \"web2\", \"web3\"]\n}\n\nresource \"aws_instance\" \"server\" {\n  count = length(var.servers)\n  \n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags = {\n    Name = var.servers[count.index]\n  }\n}\n\n# Result: \n# [0] = web1\n# [1] = web2\n# [2] = web3\n\n# Now remove web2\nvariable \"servers\" {\n  default = [\"web1\", \"web3\"]  # Removed web2\n}\n\n# Terraform will:\n# [0] = web1 (no change)\n# [1] = web3 (RECREATE! was web2)\n# [2] = DELETE web3\n\n# üò± web3 gets destroyed and recreated!\n```\n\n---\n\n#### **When to Use For_Each**\n\n‚úÖ **Use for_each when:**\n- Resources have unique identifiers\n- Adding/removing resources shouldn't affect others\n- Resources have different configurations\n- Stability is important\n\n```hcl\n# Example: Named servers\nvariable \"servers\" {\n  type = set(string)\n  default = [\"web1\", \"web2\", \"web3\"]\n}\n\nresource \"aws_instance\" \"server\" {\n  for_each = var.servers\n  \n  ami           = \"ami-12345\"\n  instance_type = \"t2.micro\"\n  \n  tags = {\n    Name = each.key\n  }\n}\n\n# Result:\n# server[\"web1\"]\n# server[\"web2\"]\n# server[\"web3\"]\n\n# Now remove web2\nvariable \"servers\" {\n  default = [\"web1\", \"web3\"]\n}\n\n# Terraform will:\n# server[\"web1\"] - no change\n# server[\"web3\"] - no change\n# server[\"web2\"] - DELETE only web2\n# ‚úÖ web3 is untouched!\n```\n\n---\n\n### üé® Advanced For_Each Patterns\n\n#### **1. From Map with Different Configurations**\n\n```hcl\nvariable \"instances\" {\n  type = map(object({\n    instance_type = string\n    ami           = string\n    volume_size   = number\n    monitoring    = bool\n  }))\n  \n  default = {\n    web = {\n      instance_type = \"t3.medium\"\n      ami           = \"ami-12345\"\n      volume_size   = 50\n      monitoring    = true\n    }\n    api = {\n      instance_type = \"t3.small\"\n      ami           = \"ami-12345\"\n      volume_size   = 30\n      monitoring    = true\n    }\n    worker = {\n      instance_type = \"t3.micro\"\n      ami           = \"ami-67890\"\n      volume_size   = 20\n      monitoring    = false\n    }\n  }\n}\n\nresource \"aws_instance\" \"servers\" {\n  for_each = var.instances\n  \n  ami           = each.value.ami\n  instance_type = each.value.instance_type\n  monitoring    = each.value.monitoring\n  \n  root_block_device {\n    volume_size = each.value.volume_size\n  }\n  \n  tags = {\n    Name = \"${each.key}-server\"\n    Role = each.key\n  }\n}\n\n# Access specific server\noutput \"web_server_ip\" {\n  value = aws_instance.servers[\"web\"].private_ip\n}\n\n# Access all servers\noutput \"all_server_ips\" {\n  value = {\n    for key, instance in aws_instance.servers :\n    key => instance.private_ip\n  }\n}\n```\n\n---\n\n#### **2. Create Subnets Across AZs**\n\n```hcl\nvariable \"availability_zones\" {\n  type = map(object({\n    cidr_block = string\n    public     = bool\n  }))\n  \n  default = {\n    \"us-east-1a\" = {\n      cidr_block = \"10.0.1.0/24\"\n      public     = true\n    }\n    \"us-east-1b\" = {\n      cidr_block = \"10.0.2.0/24\"\n      public     = true\n    }\n    \"us-east-1c\" = {\n      cidr_block = \"10.0.11.0/24\"\n      public     = false\n    }\n  }\n}\n\nresource \"aws_subnet\" \"main\" {\n  for_each = var.availability_zones\n  \n  vpc_id                  = aws_vpc.main.id\n  availability_zone       = each.key\n  cidr_block              = each.value.cidr_block\n  map_public_ip_on_launch = each.value.public\n  \n  tags = {\n    Name = \"subnet-${each.key}\"\n    Type = each.value.public ? \"public\" : \"private\"\n  }\n}\n\n# Create route table association for public subnets only\nresource \"aws_route_table_association\" \"public\" {\n  for_each = {\n    for az, config in var.availability_zones :\n    az => config if config.public\n  }\n  \n  subnet_id      = aws_subnet.main[each.key].id\n  route_table_id = aws_route_table.public.id\n}\n```\n\n---\n\n#### **3. IAM Users with Different Policies**\n\n```hcl\nvariable \"users\" {\n  type = map(object({\n    policies = list(string)\n    groups   = list(string)\n  }))\n  \n  default = {\n    \"john.doe\" = {\n      policies = [\"arn:aws:iam::aws:policy/PowerUserAccess\"]\n      groups   = [\"developers\", \"admins\"]\n    }\n    \"jane.smith\" = {\n      policies = [\"arn:aws:iam::aws:policy/ReadOnlyAccess\"]\n      groups   = [\"developers\"]\n    }\n    \"bob.wilson\" = {\n      policies = [\n        \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\",\n        \"arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess\"\n      ]\n      groups = [\"viewers\"]\n    }\n  }\n}\n\n# Create IAM users\nresource \"aws_iam_user\" \"users\" {\n  for_each = var.users\n  name     = each.key\n  \n  tags = {\n    Email = \"${replace(each.key, \".\", \"_\")}@company.com\"\n  }\n}\n\n# Attach policies to users\nresource \"aws_iam_user_policy_attachment\" \"user_policies\" {\n  for_each = merge([\n    for username, user in var.users : {\n      for policy in user.policies :\n      \"${username}-${basename(policy)}\" => {\n        user   = username\n        policy = policy\n      }\n    }\n  ]...)\n  \n  user       = aws_iam_user.users[each.value.user].name\n  policy_arn = each.value.policy\n}\n\n# Add users to groups\nresource \"aws_iam_user_group_membership\" \"users\" {\n  for_each = var.users\n  \n  user   = aws_iam_user.users[each.key].name\n  groups = each.value.groups\n}\n```\n\n---\n\n### üîÑ For Expressions\n\nTransform collections:\n\n#### **List to List**\n\n```hcl\nvariable \"names\" {\n  default = [\"alice\", \"bob\", \"charlie\"]\n}\n\nlocals {\n  # Uppercase names\n  upper_names = [\n    for name in var.names :\n    upper(name)\n  ]\n  # Result: [\"ALICE\", \"BOB\", \"CHARLIE\"]\n  \n  # Add prefix\n  prefixed_names = [\n    for name in var.names :\n    \"user-${name}\"\n  ]\n  # Result: [\"user-alice\", \"user-bob\", \"user-charlie\"]\n  \n  # Conditional filtering\n  long_names = [\n    for name in var.names :\n    name if length(name) > 4\n  ]\n  # Result: [\"alice\", \"charlie\"]\n  \n  # Transform objects\n  name_lengths = [\n    for name in var.names :\n    {\n      name   = name\n      length = length(name)\n    }\n  ]\n  # Result: [\n  #   {name = \"alice\", length = 5},\n  #   {name = \"bob\", length = 3},\n  #   {name = \"charlie\", length = 7}\n  # ]\n}\n```\n\n---\n\n#### **Map to Map**\n\n```hcl\nvariable \"instances\" {\n  default = {\n    web    = \"t3.large\"\n    api    = \"t3.medium\"\n    worker = \"t3.small\"\n  }\n}\n\nlocals {\n  # Transform values\n  instance_costs = {\n    for name, type in var.instances :\n    name => \"${type}-cost-optimized\"\n  }\n  # Result: {\n  #   web    = \"t3.large-cost-optimized\"\n  #   api    = \"t3.medium-cost-optimized\"\n  #   worker = \"t3.small-cost-optimized\"\n  # }\n  \n  # Filter map\n  large_instances = {\n    for name, type in var.instances :\n    name => type if can(regex(\"large\", type))\n  }\n  # Result: {web = \"t3.large\"}\n  \n  # Swap key/value\n  type_to_name = {\n    for name, type in var.instances :\n    type => name\n  }\n  # Result: {\n  #   \"t3.large\"  = \"web\"\n  #   \"t3.medium\" = \"api\"\n  #   \"t3.small\"  = \"worker\"\n  # }\n}\n```\n\n---\n\n#### **List to Map**\n\n```hcl\nvariable \"server_names\" {\n  default = [\"web-1\", \"web-2\", \"api-1\"]\n}\n\nlocals {\n  # Create map with index\n  server_map = {\n    for idx, name in var.server_names :\n    name => idx\n  }\n  # Result: {\n  #   \"web-1\" = 0\n  #   \"web-2\" = 1\n  #   \"api-1\" = 2\n  # }\n  \n  # Create map with derived key\n  server_config = {\n    for name in var.server_names :\n    name => {\n      type = split(\"-\", name)[0]\n      index = split(\"-\", name)[1]\n    }\n  }\n  # Result: {\n  #   \"web-1\" = {type = \"web\", index = \"1\"}\n  #   \"web-2\" = {type = \"web\", index = \"2\"}\n  #   \"api-1\" = {type = \"api\", index = \"1\"}\n  # }\n}\n```\n\n---\n\n#### **Nested For Expressions**\n\n```hcl\nvariable \"vpcs\" {\n  default = {\n    prod = {\n      cidr = \"10.0.0.0/16\"\n      azs  = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n    }\n    dev = {\n      cidr = \"10.1.0.0/16\"\n      azs  = [\"us-east-1a\", \"us-east-1b\"]\n    }\n  }\n}\n\nlocals {\n  # Flatten nested structure\n  all_subnets = flatten([\n    for vpc_name, vpc in var.vpcs : [\n      for idx, az in vpc.azs : {\n        vpc_name = vpc_name\n        az       = az\n        cidr     = cidrsubnet(vpc.cidr, 8, idx)\n      }\n    ]\n  ])\n  # Result: [\n  #   {vpc_name = \"prod\", az = \"us-east-1a\", cidr = \"10.0.0.0/24\"},\n  #   {vpc_name = \"prod\", az = \"us-east-1b\", cidr = \"10.0.1.0/24\"},\n  #   ...\n  # ]\n  \n  # Create subnet map\n  subnets = {\n    for subnet in local.all_subnets :\n    \"${subnet.vpc_name}-${subnet.az}\" => subnet\n  }\n}\n\n# Create all subnets\nresource \"aws_subnet\" \"all\" {\n  for_each = local.subnets\n  \n  vpc_id            = aws_vpc.main[each.value.vpc_name].id\n  availability_zone = each.value.az\n  cidr_block        = each.value.cidr\n  \n  tags = {\n    Name = each.key\n  }\n}\n```\n\n---\n\n### üé≠ Dynamic Blocks\n\nCreate repeating nested blocks dynamically:\n\n#### **Basic Dynamic Block**\n\n```hcl\n# Without dynamic block (repetitive)\nresource \"aws_security_group\" \"web\" {\n  name = \"web-sg\"\n  \n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  \n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  \n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"203.0.113.0/24\"]\n  }\n}\n\n# With dynamic block (clean!)\nvariable \"ingress_rules\" {\n  type = list(object({\n    port        = number\n    protocol    = string\n    cidr_blocks = list(string)\n    description = string\n  }))\n  \n  default = [\n    {\n      port        = 80\n      protocol    = \"tcp\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n      description = \"HTTP\"\n    },\n    {\n      port        = 443\n      protocol    = \"tcp\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n      description = \"HTTPS\"\n    },\n    {\n      port        = 22\n      protocol    = \"tcp\"\n      cidr_blocks = [\"203.0.113.0/24\"]\n      description = \"SSH\"\n    }\n  ]\n}\n\nresource \"aws_security_group\" \"web\" {\n  name = \"web-sg\"\n  \n  dynamic \"ingress\" {\n    for_each = var.ingress_rules\n    \n    content {\n      from_port   = ingress.value.port\n      to_port     = ingress.value.port\n      protocol    = ingress.value.protocol\n      cidr_blocks = ingress.value.cidr_blocks\n      description = ingress.value.description\n    }\n  }\n  \n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n```\n\n**Dynamic block anatomy:**\n```hcl\ndynamic \"BLOCK_NAME\" {\n  for_each = COLLECTION\n  iterator = OPTIONAL_NAME  # defaults to block name\n  \n  content {\n    # Block configuration using:\n    # BLOCK_NAME.value or ITERATOR_NAME.value\n    # BLOCK_NAME.key or ITERATOR_NAME.key\n  }\n}\n```\n\n---\n\n#### **Advanced Dynamic Block Patterns**\n\n**1. Security Groups with Port Ranges**\n\n```hcl\nvariable \"security_rules\" {\n  default = {\n    http = {\n      from_port   = 80\n      to_port     = 80\n      protocol    = \"tcp\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n    }\n    https = {\n      from_port   = 443\n      to_port     = 443\n      protocol    = \"tcp\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n    }\n    ssh = {\n      from_port   = 22\n      to_port     = 22\n      protocol    = \"tcp\"\n      cidr_blocks = [\"10.0.0.0/8\"]\n    }\n    ephemeral = {\n      from_port   = 1024\n      to_port     = 65535\n      protocol    = \"tcp\"\n      cidr_blocks = [\"10.0.0.0/8\"]\n    }\n  }\n}\n\nresource \"aws_security_group\" \"app\" {\n  name = \"app-sg\"\n  \n  dynamic \"ingress\" {\n    for_each = var.security_rules\n    iterator = rule\n    \n    content {\n      description = rule.key\n      from_port   = rule.value.from_port\n      to_port     = rule.value.to_port\n      protocol    = rule.value.protocol\n      cidr_blocks = rule.value.cidr_blocks\n    }\n  }\n}\n```\n\n---\n\n**2. RDS with Optional Features**\n\n```hcl\nvariable \"database_config\" {\n  type = object({\n    engine               = string\n    instance_class       = string\n    allocated_storage    = number\n    backup_retention     = number\n    multi_az             = bool\n    storage_encrypted    = bool\n    performance_insights = optional(bool, false)\n    replicas             = optional(number, 0)\n  })\n}\n\nvariable \"restore_config\" {\n  type = object({\n    enabled         = bool\n    snapshot_id     = optional(string)\n    restore_time    = optional(string)\n  })\n  default = {\n    enabled = false\n  }\n}\n\nresource \"aws_db_instance\" \"main\" {\n  identifier     = \"main-db\"\n  engine         = var.database_config.engine\n  instance_class = var.database_config.instance_class\n  \n  allocated_storage = var.database_config.allocated_storage\n  storage_encrypted = var.database_config.storage_encrypted\n  \n  multi_az                = var.database_config.multi_az\n  backup_retention_period = var.database_config.backup_retention\n  \n  # Dynamic block for performance insights\n  dynamic \"performance_insights\" {\n    for_each = var.database_config.performance_insights ? [1] : []\n    \n    content {\n      enabled          = true\n      retention_period = 7\n    }\n  }\n  \n  # Dynamic restore configuration\n  dynamic \"restore_to_point_in_time\" {\n    for_each = var.restore_config.enabled ? [var.restore_config] : []\n    \n    content {\n      source_db_instance_identifier = restore_to_point_in_time.value.snapshot_id\n      restore_time                  = restore_to_point_in_time.value.restore_time\n    }\n  }\n}\n\n# Read replicas\nresource \"aws_db_instance\" \"replica\" {\n  count = var.database_config.replicas\n  \n  identifier          = \"main-db-replica-${count.index + 1}\"\n  replicate_source_db = aws_db_instance.main.identifier\n  instance_class      = var.database_config.instance_class\n  \n  tags = {\n    Name = \"replica-${count.index + 1}\"\n  }\n}\n```\n\n---\n\n**3. EC2 with Conditional Block Device Mappings**\n\n```hcl\nvariable \"instance_config\" {\n  type = object({\n    instance_type = string\n    root_volume = object({\n      size = number\n      type = string\n    })\n    additional_volumes = list(object({\n      device_name = string\n      size        = number\n      type        = string\n      encrypted   = bool\n    }))\n  })\n  \n  default = {\n    instance_type = \"t3.medium\"\n    root_volume = {\n      size = 30\n      type = \"gp3\"\n    }\n    additional_volumes = [\n      {\n        device_name = \"/dev/sdf\"\n        size        = 100\n        type        = \"gp3\"\n        encrypted   = true\n      },\n      {\n        device_name = \"/dev/sdg\"\n        size        = 200\n        type        = \"io2\"\n        encrypted   = true\n      }\n    ]\n  }\n}\n\nresource \"aws_instance\" \"app\" {\n  ami           = data.aws_ami.amazon_linux_2.id\n  instance_type = var.instance_config.instance_type\n  \n  root_block_device {\n    volume_size = var.instance_config.root_volume.size\n    volume_type = var.instance_config.root_volume.type\n    encrypted   = true\n  }\n  \n  dynamic \"ebs_block_device\" {\n    for_each = var.instance_config.additional_volumes\n    iterator = volume\n    \n    content {\n      device_name           = volume.value.device_name\n      volume_size           = volume.value.size\n      volume_type           = volume.value.type\n      encrypted             = volume.value.encrypted\n      delete_on_termination = true\n    }\n  }\n}\n```\n\n---\n\n**4. Nested Dynamic Blocks**\n\n```hcl\nvariable \"load_balancers\" {\n  type = map(object({\n    internal = bool\n    listeners = list(object({\n      port     = number\n      protocol = string\n      rules = list(object({\n        priority = number\n        path     = string\n        target   = string\n      }))\n    }))\n  }))\n  \n  default = {\n    public = {\n      internal = false\n      listeners = [\n        {\n          port     = 80\n          protocol = \"HTTP\"\n          rules = [\n            {\n              priority = 1\n              path     = \"/api/*\"\n              target   = \"api\"\n            },\n            {\n              priority = 2\n              path     = \"/*\"\n              target   = \"web\"\n            }\n          ]\n        },\n        {\n          port     = 443\n          protocol = \"HTTPS\"\n          rules = [\n            {\n              priority = 1\n              path     = \"/api/*\"\n              target   = \"api\"\n            }\n          ]\n        }\n      ]\n    }\n  }\n}\n\nresource \"aws_lb\" \"main\" {\n  for_each = var.load_balancers\n  \n  name               = \"${each.key}-lb\"\n  internal           = each.value.internal\n  load_balancer_type = \"application\"\n  subnets            = aws_subnet.public[*].id\n}\n\nresource \"aws_lb_listener\" \"main\" {\n  for_each = merge([\n    for lb_name, lb in var.load_balancers : {\n      for listener in lb.listeners :\n      \"${lb_name}-${listener.port}\" => {\n        lb_name  = lb_name\n        port     = listener.port\n        protocol = listener.protocol\n        rules    = listener.rules\n      }\n    }\n  ]...)\n  \n  load_balancer_arn = aws_lb.main[each.value.lb_name].arn\n  port              = each.value.port\n  protocol          = each.value.protocol\n  \n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.main[\"${each.value.lb_name}-web\"].arn\n  }\n}\n\nresource \"aws_lb_listener_rule\" \"main\" {\n  for_each = merge(flatten([\n    for lb_name, lb in var.load_balancers : [\n      for listener in lb.listeners : [\n        for rule in listener.rules : {\n          \"${lb_name}-${listener.port}-${rule.priority}\" = {\n            listener_key = \"${lb_name}-${listener.port}\"\n            priority     = rule.priority\n            path         = rule.path\n            target       = rule.target\n            lb_name      = lb_name\n          }\n        }\n      ]\n    ]\n  ])...)\n  \n  listener_arn = aws_lb_listener.main[each.value.listener_key].arn\n  priority     = each.value.priority\n  \n  action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.main[\"${each.value.lb_name}-${each.value.target}\"].arn\n  }\n  \n  condition {\n    path_pattern {\n      values = [each.value.path]\n    }\n  }\n}\n```\n\n---\n\n### üéì Real-World Complete Example\n\n```hcl\n# ==================================================\n# File: variables.tf\n# ==================================================\n\nvariable \"project_name\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n\nvariable \"vpc_config\" {\n  type = object({\n    cidr_block         = string\n    availability_zones = list(string)\n    public_subnets     = list(string)\n    private_subnets    = list(string)\n  })\n}\n\nvariable \"security_groups\" {\n  type = map(object({\n    description = string\n    ingress_rules = list(object({\n      from_port   = number\n      to_port     = number\n      protocol    = string\n      cidr_blocks = list(string)\n      description = string\n    }))\n  }))\n}\n\nvariable \"instances\" {\n  type = map(object({\n    count         = number\n    instance_type = string\n    security_groups = list(string)\n    user_data     = optional(string, \"\")\n    volumes = optional(list(object({\n      device_name = string\n      size        = number\n      type        = string\n    })), [])\n  }))\n}\n\nvariable \"load_balancer\" {\n  type = object({\n    enabled  = bool\n    internal = bool\n    targets = map(object({\n      port              = number\n      health_check_path = string\n      instances         = list(string)\n    }))\n  })\n}\n\n# ==================================================\n# File: terraform.tfvars\n# ==================================================\n\nproject_name = \"webapp\"\nenvironment  = \"prod\"\n\nvpc_config = {\n  cidr_block         = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  public_subnets     = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n  private_subnets    = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n}\n\nsecurity_groups = {\n  web = {\n    description = \"Security group for web servers\"\n    ingress_rules = [\n      {\n        from_port   = 80\n        to_port     = 80\n        protocol    = \"tcp\"\n        cidr_blocks = [\"0.0.0.0/0\"]\n        description = \"HTTP from anywhere\"\n      },\n      {\n        from_port   = 443\n        to_port     = 443\n        protocol    = \"tcp\"\n        cidr_blocks = [\"0.0.0.0/0\"]\n        description = \"HTTPS from anywhere\"\n      }\n    ]\n  }\n  \n  app = {\n    description = \"Security group for app servers\"\n    ingress_rules = [\n      {\n        from_port   = 8080\n        to_port     = 8080\n        protocol    = \"tcp\"\n        cidr_blocks = [\"10.0.0.0/16\"]\n        description = \"App port from VPC\"\n      }\n    ]\n  }\n  \n  db = {\n    description = \"Security group for database\"\n    ingress_rules = [\n      {\n        from_port   = 3306\n        to_port     = 3306\n        protocol    = \"tcp\"\n        cidr_blocks = [\"10.0.0.0/16\"]\n        description = \"MySQL from VPC\"\n      }\n    ]\n  }\n}\n\ninstances = {\n  web = {\n    count           = 3\n    instance_type   = \"t3.medium\"\n    security_groups = [\"web\"]\n    user_data       = <<-EOF\n      #!/bin/bash\n      yum install -y httpd\n      systemctl start httpd\n    EOF\n    volumes = [\n      {\n        device_name = \"/dev/sdf\"\n        size        = 50\n        type        = \"gp3\"\n      }\n    ]\n  }\n  \n  app = {\n    count           = 2\n    instance_type   = \"t3.large\"\n    security_groups = [\"app\"]\n    volumes = []\n  }\n}\n\nload_balancer = {\n  enabled  = true\n  internal = false\n  targets = {\n    web = {\n      port              = 80\n      health_check_path = \"/health\"\n      instances         = [\"web\"]\n    }\n    app = {\n      port              = 8080\n      health_check_path = \"/api/health\"\n      instances         = [\"app\"]\n    }\n  }\n}\n\n# ==================================================\n# File: main.tf\n# ==================================================\n\n# VPC\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_config.cidr_block\n  enable_dns_hostnames = true\n  \n  tags = {\n    Name = \"${var.project_name}-${var.environment}-vpc\"\n  }\n}\n\n# Public Subnets\nresource \"aws_subnet\" \"public\" {\n  count = length(var.vpc_config.public_subnets)\n  \n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = var.vpc_config.public_subnets[count.index]\n  availability_zone       = var.vpc_config.availability_zones[count.index]\n  map_public_ip_on_launch = true\n  \n  tags = {\n    Name = \"${var.project_name}-public-${var.vpc_config.availability_zones[count.index]}\"\n    Type = \"public\"\n  }\n}\n\n# Private Subnets\nresource \"aws_subnet\" \"private\" {\n  count = length(var.vpc_config.private_subnets)\n  \n  vpc_id            = aws_vpc.main.id\n  cidr_block        = var.vpc_config.private_subnets[count.index]\n  availability_zone = var.vpc_config.availability_zones[count.index]\n  \n  tags = {\n    Name = \"${var.project_name}-private-${var.vpc_config.availability_zones[count.index]}\"\n    Type = \"private\"\n  }\n}\n\n# Security Groups with Dynamic Ingress Rules\nresource \"aws_security_group\" \"main\" {\n  for_each = var.security_groups\n  \n  name        = \"${var.project_name}-${each.key}-sg\"\n  description = each.value.description\n  vpc_id      = aws_vpc.main.id\n  \n  dynamic \"ingress\" {\n    for_each = each.value.ingress_rules\n    \n    content {\n      description = ingress.value.description\n      from_port   = ingress.value.from_port\n      to_port     = ingress.value.to_port\n      protocol    = ingress.value.protocol\n      cidr_blocks = ingress.value.cidr_blocks\n    }\n  }\n  \n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  \n  tags = {\n    Name = \"${var.project_name}-${each.key}-sg\"\n  }\n}\n\n# EC2 Instances with Dynamic Configuration\nlocals {\n  # Flatten instance configuration\n  instances_flat = flatten([\n    for role, config in var.instances : [\n      for i in range(config.count) : {\n        key             = \"${role}-${i}\"\n        role            = role\n        instance_type   = config.instance_type\n        security_groups = [for sg in config.security_groups : aws_security_group.main[sg].id]\n        user_data       = config.user_data\n        volumes         = config.volumes\n        subnet_id       = aws_subnet.public[i % length(aws_subnet.public)].id\n      }\n    ]\n  ])\n  \n  instances_map = {\n    for inst in local.instances_flat :\n    inst.key => inst\n  }\n}\n\nresource \"aws_instance\" \"main\" {\n  for_each = local.instances_map\n  \n  ami                    = data.aws_ami.amazon_linux_2.id\n  instance_type          = each.value.instance_type\n  subnet_id              = each.value.subnet_id\n  vpc_security_group_ids = each.value.security_groups\n  user_data              = each.value.user_data != \"\" ? each.value.user_data : null\n  \n  root_block_device {\n    volume_size = 20\n    volume_type = \"gp3\"\n    encrypted   = true\n  }\n  \n  dynamic \"ebs_block_device\" {\n    for_each = each.value.volumes\n    \n    content {\n      device_name = ebs_block_device.value.device_name\n      volume_size = ebs_block_device.value.size\n      volume_type = ebs_block_device.value.type\n      encrypted   = true\n    }\n  }\n  \n  tags = {\n    Name = \"${var.project_name}-${each.key}\"\n    Role = each.value.role\n  }\n}\n\n# Load Balancer (conditional)\nresource \"aws_lb\" \"main\" {\n  count = var.load_balancer.enabled ? 1 : 0\n  \n  name               = \"${var.project_name}-lb\"\n  internal           = var.load_balancer.internal\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.main[\"web\"].id]\n  subnets            = aws_subnet.public[*].id\n  \n  tags = {\n    Name = \"${var.project_name}-lb\"\n  }\n}\n\n# Target Groups\nresource \"aws_lb_target_group\" \"main\" {\n  for_each = var.load_balancer.enabled ? var.load_balancer.targets : {}\n  \n  name     = \"${var.project_name}-${each.key}-tg\"\n  port     = each.value.port\n  protocol = \"HTTP\"\n  vpc_id   = aws_vpc.main.id\n  \n  health_check {\n    path                = each.value.health_check_path\n    healthy_threshold   = 2\n    unhealthy_threshold = 10\n  }\n  \n  tags = {\n    Name = \"${var.project_name}-${each.key}-tg\"\n  }\n}\n\n# Target Group Attachments\nlocals {\n  lb_attachments = var.load_balancer.enabled ? flatten([\n    for tg_name, tg_config in var.load_balancer.targets : [\n      for role in tg_config.instances : [\n        for instance_key, instance in local.instances_map :\n        {\n          key           = \"${tg_name}-${instance_key}\"\n          tg_name       = tg_name\n          instance_id   = aws_instance.main[instance_key].id\n        } if instance.role == role\n      ]\n    ]\n  ]) : []\n  \n  lb_attachments_map = {\n    for attach in local.lb_attachments :\n    attach.key => attach\n  }\n}\n\nresource \"aws_lb_target_group_attachment\" \"main\" {\n  for_each = local.lb_attachments_map\n  \n  target_group_arn = aws_lb_target_group.main[each.value.tg_name].arn\n  target_id        = each.value.instance_id\n  port             = var.load_balancer.targets[each.value.tg_name].port\n}\n\n# ==================================================\n# File: outputs.tf\n# ==================================================\n\noutput \"vpc_id\" {\n  value = aws_vpc.main.id\n}\n\noutput \"instances\" {\n  value = {\n    for key, instance in aws_instance.main :\n    key => {\n      id         = instance.id\n      private_ip = instance.private_ip\n      public_ip  = instance.public_ip\n    }\n  }\n}\n\noutput \"security_groups\" {\n  value = {\n    for key, sg in aws_security_group.main :\n    key => sg.id\n  }\n}\n\noutput \"load_balancer_dns\" {\n  value = var.load_balancer.enabled ? aws_lb.main[0].dns_name : null\n}\n```\n\n---\n\n### ‚úÖ Day 8-9 Checklist\n\n- [x] Count vs for_each - when to use each\n- [x] Advanced for_each patterns\n- [x] For expressions (list/map transformations)\n- [x] Nested for expressions and flattening\n- [x] Dynamic blocks syntax\n- [x] Multiple dynamic block patterns\n- [x] Nested dynamic blocks\n- [x] Real-world complex example\n\n**Next:** Modules - Reusable infrastructure!\n\n---\n\n## Day 10-11: Terraform Modules\n\n### üéØ Learning Objectives\n- Understand modules and their benefits\n- Create reusable modules\n- Use module inputs and outputs\n- Work with module sources\n- Follow module best practices\n\n---\n\n### üì¶ What are Modules?\n\n**Module** = A container for multiple resources used together.\n\nThink of modules like **functions in programming**:\n- **Input** = Variables\n- **Processing** = Resources\n- **Output** = Output values\n\n**Benefits:**\n- **Reusability** - Write once, use many times\n- **Organization** - Group related resources\n- **Standardization** - Enforce best practices\n- **Collaboration** - Share with team\n\n---\n\n### üèóÔ∏è Module Structure\n\n```\nmy-module/\n‚îú‚îÄ‚îÄ main.tf          # Main resource definitions\n‚îú‚îÄ‚îÄ variables.tf     # Input variables\n‚îú‚îÄ‚îÄ outputs.tf       # Output values\n‚îú‚îÄ‚îÄ README.md        # Documentation\n‚îú‚îÄ‚îÄ versions.tf      # Provider requirements (optional)\n‚îî‚îÄ‚îÄ examples/        # Usage examples (optional)\n    ‚îî‚îÄ‚îÄ complete/\n        ‚îú‚îÄ‚îÄ main.tf\n        ‚îî‚îÄ‚îÄ variables.tf\n```\n\n---\n\n### üé® Creating Your First Module\n\n#### **Module: VPC**\n\n```hcl\n# ==================================================\n# File: modules/vpc/variables.tf\n# ==================================================\n\nvariable \"project_name\" {\n  description = \"Project name for resource naming\"\n  type        = string\n}\n\nvariable \"environment\" {\n  description = \"Environment (dev/staging/prod)\"\n  type        = string\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"availability_zones\" {\n  description = \"List of availability zones\"\n  type        = list(string)\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"CIDR blocks for public subnets\"\n  type        = list(string)\n}\n\nvariable \"private_subnet_cidrs\" {\n  description = \"CIDR blocks for private subnets\"\n  type        = list(string)\n}\n\nvariable \"enable_nat_gateway\" {\n  description = \"Enable NAT Gateway for private subnets\"\n  type        = bool\n  default     = true\n}\n\nvariable \"single_nat_gateway\" {\n  description = \"Use single NAT Gateway for all private subnets\"\n  type        = bool\n  default     = false\n}\n\nvariable \"tags\" {\n  description = \"Additional tags\"\n  type        = map(string)\n  default     = {}\n}\n\n# ==================================================\n# File: modules/vpc/main.tf\n# ==================================================\n\nlocals {\n  common_tags = merge(\n    var.tags,\n    {\n      Project     = var.project_name\n      Environment = var.environment\n      ManagedBy   = \"Terraform\"\n      Module      = \"VPC\"\n    }\n  )\n}\n\n# VPC\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-vpc\"\n    }\n  )\n}\n\n# Internet Gateway\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-igw\"\n    }\n  )\n}\n\n# Public Subnets\nresource \"aws_subnet\" \"public\" {\n  count = length(var.public_subnet_cidrs)\n  \n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = var.availability_zones[count.index]\n  map_public_ip_on_launch = true\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-public-${var.availability_zones[count.index]}\"\n      Type = \"public\"\n    }\n  )\n}\n\n# Private Subnets\nresource \"aws_subnet\" \"private\" {\n  count = length(var.private_subnet_cidrs)\n  \n  vpc_id            = aws_vpc.main.id\n  cidr_block        = var.private_subnet_cidrs[count.index]\n  availability_zone = var.availability_zones[count.index]\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-private-${var.availability_zones[count.index]}\"\n      Type = \"private\"\n    }\n  )\n}\n\n# Elastic IPs for NAT Gateways\nresource \"aws_eip\" \"nat\" {\n  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : length(var.private_subnet_cidrs)) : 0\n  \n  domain = \"vpc\"\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-nat-eip-${count.index + 1}\"\n    }\n  )\n  \n  depends_on = [aws_internet_gateway.main]\n}\n\n# NAT Gateways\nresource \"aws_nat_gateway\" \"main\" {\n  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : length(var.private_subnet_cidrs)) : 0\n  \n  allocation_id = aws_eip.nat[count.index].id\n  subnet_id     = aws_subnet.public[count.index].id\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-nat-${count.index + 1}\"\n    }\n  )\n  \n  depends_on = [aws_internet_gateway.main]\n}\n\n# Public Route Table\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n  \n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.main.id\n  }\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-public-rt\"\n    }\n  )\n}\n\n# Public Route Table Associations\nresource \"aws_route_table_association\" \"public\" {\n  count = length(var.public_subnet_cidrs)\n  \n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public.id\n}\n\n# Private Route Tables\nresource \"aws_route_table\" \"private\" {\n  count = var.enable_nat_gateway ? length(var.private_subnet_cidrs) : 1\n  \n  vpc_id = aws_vpc.main.id\n  \n  dynamic \"route\" {\n    for_each = var.enable_nat_gateway ? [1] : []\n    \n    content {\n      cidr_block     = \"0.0.0.0/0\"\n      nat_gateway_id = var.single_nat_gateway ? aws_nat_gateway.main[0].id : aws_nat_gateway.main[count.index].id\n    }\n  }\n  \n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project_name}-${var.environment}-private-rt-${count.index + 1}\"\n    }\n  )\n}\n\n# Private Route Table Associations\nresource \"aws_route_table_association\" \"private\" {\n  count = length(var.private_subnet_cidrs)\n  \n  subnet_id      = aws_subnet.private[count.index].id\n  route_table_id = var.enable_nat_gateway ? aws_route_table.private[var.single_nat_gateway ? 0 : count.index].id : aws_route_table.private[0].id\n}\n\n# ==================================================\n# File: modules/vpc/outputs.tf\n# ==================================================\n\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"vpc_cidr\" {\n  description = \"CIDR block of the VPC\"\n  value       = aws_vpc.main.cidr_block\n}\n\noutput \"public_subnet_ids\" {\n  description = \"IDs of public subnets\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"private_subnet_ids\" {\n  description = \"IDs of private subnets\"\n  value       = aws_subnet.private[*].id\n}\n\noutput \"public_subnet_cidrs\" {\n  description = \"CIDR blocks of public subnets\"\n  value       = aws_subnet.public[*].cidr_block\n}\n\noutput \"private_subnet_cidrs\" {\n  description = \"CIDR blocks of private subnets\"\n  value       = aws_subnet.private[*].cidr_block\n}\n\noutput \"internet_gateway_id\" {\n  description = \"ID of the Internet Gateway\"\n  value       = aws_internet_gateway.main.id\n}\n\noutput \"nat_gateway_ids\" {\n  description = \"IDs of NAT Gateways\"\n  value       = aws_nat_gateway.main[*].id\n}\n\noutput \"nat_eip_public_ips\" {\n  description = \"Public IPs of NAT Gateway Elastic IPs\"\n  value       = aws_eip.nat[*].public_ip\n}\n\n# ==================================================\n# File: modules/vpc/README.md\n# ==================================================\n\n# VPC Module\n\nCreates a complete VPC with public and private subnets, Internet Gateway, and NAT Gateway.\n\n## Features\n\n- VPC with customizable CIDR\n- Public subnets with Internet Gateway\n- Private subnets with NAT Gateway\n- Single or multiple NAT Gateways\n- Automatic route table configuration\n\n## Usage\n\n```hcl\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  project_name = \"myapp\"\n  environment  = \"prod\"\n  \n  vpc_cidr = \"10.0.0.0/16\"\n  \n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  \n  public_subnet_cidrs  = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n  private_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n  \n  enable_nat_gateway  = true\n  single_nat_gateway  = false\n  \n  tags = {\n    Team = \"Platform\"\n  }\n}\n```\n\n## Inputs\n\n| Name | Description | Type | Default | Required |\n|------|-------------|------|---------|----------|\n| project_name | Project name | string | - | yes |\n| environment | Environment | string | - | yes |\n| vpc_cidr | VPC CIDR block | string | \"10.0.0.0/16\" | no |\n| availability_zones | List of AZs | list(string) | - | yes |\n| public_subnet_cidrs | Public subnet CIDRs | list(string) | - | yes |\n| private_subnet_cidrs | Private subnet CIDRs | list(string) | - | yes |\n| enable_nat_gateway | Enable NAT Gateway | bool | true | no |\n| single_nat_gateway | Use single NAT Gateway | bool | false | no |\n| tags | Additional tags | map(string) | {} | no |\n\n## Outputs\n\n| Name | Description |\n|------|-------------|\n| vpc_id | VPC ID |\n| public_subnet_ids | Public subnet IDs |\n| private_subnet_ids | Private subnet IDs |\n| nat_gateway_ids | NAT Gateway IDs |\n```\n\n---\n\n### üéØ Using the Module\n\n```hcl\n# ==================================================\n# File: main.tf (root configuration)\n# ==================================================\n\nterraform {\n  required_version = \">= 1.0\"\n  \n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.region\n}\n\n# Use the VPC module\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  project_name = var.project_name\n  environment  = var.environment\n  \n  vpc_cidr = \"10.0.0.0/16\"\n  \n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  \n  public_subnet_cidrs  = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n  private_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n  \n  enable_nat_gateway = true\n  single_nat_gateway = false\n  \n  tags = {\n    Team = \"Platform\"\n  }\n}\n\n# Use module outputs\nresource \"aws_instance\" \"web\" {\n  count = 3\n  \n  ami           = data.aws_ami.amazon_linux_2.id\n  instance_type = \"t3.micro\"\n  \n  # Reference module output\n  subnet_id = module.vpc.public_subnet_ids[count.index]\n  \n  tags = {\n    Name = \"web-${count.index + 1}\"\n  }\n}\n\n# Output module values\noutput \"vpc_id\" {\n  value = module.vpc.vpc_id\n}\n\noutput \"public_subnets\" {\n  value = module.vpc.public_subnet_ids\n}\n```\n\n---\n\n### üìö Module Sources\n\n#### **1. Local Path**\n\n```hcl\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n}\n\nmodule \"networking\" {\n  source = \"../shared-modules/networking\"\n}\n```\n\n#### **2. GitHub**\n\n```hcl\n# Public repo\nmodule \"vpc\" {\n  source = \"github.com/terraform-aws-modules/terraform-aws-vpc\"\n}\n\n# With branch/tag\nmodule \"vpc\" {\n  source = \"github.com/terraform-aws-modules/terraform-aws-vpc?ref=v5.1.2\"\n}\n\n# Private repo with SSH\nmodule \"vpc\" {\n  source = \"git@github.com:mycompany/terraform-modules.git//vpc\"\n}\n\n# Subdirectory\nmodule \"vpc\" {\n  source = \"github.com/mycompany/terraform-modules//aws/vpc?ref=v1.0.0\"\n}\n```\n\n#### **3. Terraform Registry**\n\n```hcl\n# Official modules\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"5.1.2\"\n}\n\nmodule \"rds\" {\n  source  = \"terraform-aws-modules/rds/aws\"\n  version = \"6.1.1\"\n}\n\n# Always pin version!\n```\n\n#### **4. S3 Bucket**\n\n```hcl\nmodule \"vpc\" {\n  source = \"s3::https://s3.amazonaws.com/my-bucket/terraform-modules/vpc.zip\"\n}\n```\n\n#### **5. HTTP URL**\n\n```hcl\nmodule \"vpc\" {\n  source = \"https://example.com/terraform-modules/vpc.zip\"\n}\n```\n\n---\n\n### üîÑ Module Composition\n\nBuild complex modules from simpler ones:\n\n```hcl\n# ==================================================\n# Module: application (composite module)\n# ==================================================\n\n# File: modules/application/main.tf\n\nmodule \"vpc\" {\n  source = \"../vpc\"\n  \n  project_name = var.project_name\n  environment  = var.environment\n  \n  vpc_cidr             = var.vpc_cidr\n  availability_zones   = var.availability_zones\n  public_subnet_cidrs  = var.public_subnet_cidrs\n  private_subnet_cidrs = var.private_subnet_cidrs\n}\n\nmodule \"security_groups\" {\n  source = \"../security-groups\"\n  \n  vpc_id       = module.vpc.vpc_id\n  project_name = var.project_name\n  environment  = var.environment\n}\n\nmodule \"alb\" {\n  source = \"../alb\"\n  \n  project_name = var.project_name\n  environment  = var.environment\n  \n  vpc_id         = module.vpc.vpc_id\n  subnet_ids     = module.vpc.public_subnet_ids\n  security_group = module.security_groups.alb_sg_id\n}\n\nmodule \"asg\" {\n  source = \"../asg\"\n  \n  project_name = var.project_name\n  environment  = var.environment\n  \n  vpc_id             = module.vpc.vpc_id\n  subnet_ids         = module.vpc.private_subnet_ids\n  security_group     = module.security_groups.app_sg_id\n  target_group_arns  = [module.alb.target_group_arn]\n  \n  min_size     = var.min_instances\n  max_size     = var.max_instances\n  desired_size = var.desired_instances\n}\n\nmodule \"rds\" {\n  source = \"../rds\"\n  \n  project_name = var.project_name\n  environment  = var.environment\n  \n  vpc_id         = module.vpc.vpc_id\n  subnet_ids     = module.vpc.private_subnet_ids\n  security_group = module.security_groups.db_sg_id\n  \n  engine         = \"mysql\"\n  engine_version = \"8.0.33\"\n  instance_class = var.db_instance_class\n  multi_az       = var.db_multi_az\n}\n\n# File: modules/application/outputs.tf\n\noutput \"vpc_id\" {\n  value = module.vpc.vpc_id\n}\n\noutput \"alb_dns_name\" {\n  value = module.alb.dns_name\n}\n\noutput \"database_endpoint\" {\n  value = module.rds.endpoint\n}\n```\n\n**Use the composite module:**\n\n```hcl\n# Root main.tf\n\nmodule \"production_app\" {\n  source = \"./modules/application\"\n  \n  project_name = \"myapp\"\n  environment  = \"prod\"\n  \n  vpc_cidr = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  public_subnet_cidrs  = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n  private_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n  \n  min_instances     = 3\n  max_instances     = 10\n  desired_instances = 5\n  \n  db_instance_class = \"db.r5.large\"\n  db_multi_az       = true\n}\n\noutput \"app_url\" {\n  value = \"http://${module.production_app.alb_dns_name}\"\n}\n```\n\n---\n\n### üéì Module Best Practices\n\n#### **1. Use Clear Variable Names**\n\n```hcl\n# ‚ùå BAD\nvariable \"c\" {\n  type = string\n}\n\nvariable \"n\" {\n  type = number\n}\n\n# ‚úÖ GOOD\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n  \n  validation {\n    condition     = can(cidrhost(var.vpc_cidr, 0))\n    error_message = \"Must be a valid CIDR block.\"\n  }\n}\n\nvariable \"instance_count\" {\n  description = \"Number of instances to create\"\n  type        = number\n  \n  validation {\n    condition     = var.instance_count >= 1 && var.instance_count <= 100\n    error_message = \"Instance count must be between 1 and 100.\"\n  }\n}\n```\n\n---\n\n#### **2. Provide Sensible Defaults**\n\n```hcl\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t3.micro\"  # Safe default for dev/test\n}\n\nvariable \"enable_monitoring\" {\n  description = \"Enable detailed monitoring\"\n  type        = bool\n  default     = false  # Opt-in for cost savings\n}\n\nvariable \"backup_retention_days\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7  # Reasonable default\n}\n```\n\n---\n\n#### **3. Use Output Descriptions**\n\n```hcl\noutput \"vpc_id\" {\n  description = \"ID of the VPC created by this module\"\n  value       = aws_vpc.main.id\n}\n\noutput \"public_subnet_ids\" {\n  description = \"List of IDs of public subnets, ordered by availability zone\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"nat_gateway_public_ips\" {\n  description = \"Public IP addresses of NAT Gateways for whitelisting\"\n  value       = aws_eip.nat[*].public_ip\n}\n```\n\n---\n\n#### **4. Version Your Modules**\n\n```hcl\n# Use Git tags\nmodule \"vpc\" {\n  source = \"git::https://github.com/myorg/terraform-modules.git//vpc?ref=v1.2.0\"\n}\n\n# Follow semantic versioning\n# v1.2.0 = MAJOR.MINOR.PATCH\n# MAJOR = breaking changes\n# MINOR = new features (backwards compatible)\n# PATCH = bug fixes\n```\n\n---\n\n#### **5. Write Good Documentation**\n\n```markdown\n# VPC Module\n\n## Description\nCreates a production-ready VPC with public and private subnets across multiple availability zones.\n\n## Features\n- [x] Multi-AZ deployment\n- [x] NAT Gateway (optional single/multi)\n- [x] Internet Gateway for public subnets\n- [x] Automatic route table configuration\n- [x] Customizable CIDR blocks\n\n## Requirements\n- Terraform >= 1.0\n- AWS Provider >= 5.0\n\n## Usage\n\n### Basic Example\n```hcl\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  project_name = \"myapp\"\n  environment  = \"prod\"\n  \n  availability_zones = [\"us-east-1a\", \"us-east-1b\"]\n  public_subnet_cidrs  = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n  private_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\"]\n}\n```\n\n### Production Example\n```hcl\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  project_name = \"myapp\"\n  environment  = \"prod\"\n  \n  vpc_cidr = \"10.0.0.0/16\"\n  \n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  public_subnet_cidrs  = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n  private_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n  \n  enable_nat_gateway = true\n  single_nat_gateway = false  # HA setup\n  \n  tags = {\n    Team       = \"Platform\"\n    CostCenter = \"Engineering\"\n  }\n}\n```\n\n## Inputs\n\n(Table of all inputs with descriptions)\n\n## Outputs\n\n(Table of all outputs with descriptions)\n\n## Cost Estimation\n\n- VPC: Free\n- Internet Gateway: Free\n- NAT Gateway: ~$32/month per AZ\n- Elastic IPs: Free (when attached to NAT Gateway)\n\n**Total (3 AZs with NAT Gateway in each): ~$96/month**\n\n## Known Issues\n\n- NAT Gateway can take 5-10 minutes to provision\n- Changing AZ count requires careful planning to avoid downtime\n\n## Contributing\n\nPlease see CONTRIBUTING.md\n\n## License\n\nMIT\n```\n\n---\n\n#### **6. Organize Module Files**\n\n```\nmodules/\n‚îú‚îÄ‚îÄ vpc/\n‚îÇ   ‚îú‚îÄ‚îÄ main.tf\n‚îÇ   ‚îú‚îÄ‚îÄ variables.tf\n‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf\n‚îÇ   ‚îú‚îÄ‚îÄ versions.tf\n‚îÇ   ‚îú‚îÄ‚îÄ README.md\n‚îÇ   ‚îî‚îÄ‚îÄ examples/\n‚îÇ       ‚îú‚îÄ‚îÄ basic/\n‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ main.tf\n‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ README.md\n‚îÇ       ‚îî‚îÄ‚îÄ complete/\n‚îÇ           ‚îú‚îÄ‚îÄ main.tf\n‚îÇ           ‚îî‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ security-groups/\n‚îÇ   ‚îú‚îÄ‚îÄ main.tf\n‚îÇ   ‚îú‚îÄ‚îÄ variables.tf\n‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf\n‚îÇ   ‚îî‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ ec2-instance/\n    ‚îú‚îÄ‚îÄ main.tf\n    ‚îú‚îÄ‚îÄ variables.tf\n    ‚îú‚îÄ‚îÄ outputs.tf\n    ‚îî‚îÄ‚îÄ README.md\n```\n\n---\n\n### ‚úÖ Day 10-11 Checklist\n\n- [x] Module concepts and benefits\n- [x] Module structure\n- [x] Creating modules (VPC example)\n- [x] Using modules\n- [x] Module sources (local, GitHub, registry, etc.)\n- [x] Module composition\n- [x] Module best practices\n- [x] Documentation\n\n**Next:** Workspaces, Remote State, and Production Practices!\n\n---\n\n## üìä Progress Summary\n\n### ‚úÖ **COMPLETED (Days 1-11)**\n\n**PART 1: FOUNDATIONS (Days 1-2)** ‚úÖ\n- Day 1: What is Terraform, Installation & Setup\n- Day 2: First Project, Terraform Workflow\n\n**PART 2: CORE CONCEPTS (Days 3-7)** ‚úÖ  \n- Day 3: HCL Language Basics (syntax, data types, functions)\n- Day 4: Providers Deep Dive (AWS, Azure, GCP)\n- Day 5: Resources (meta-arguments, lifecycle, dependencies)\n- Day 6: Variables (all types, validation, precedence)\n- Day 7: Outputs & Data Sources\n\n**PART 3: ADVANCED FEATURES (Days 8-11)** ‚úÖ\n- Days 8-9: Advanced Iteration (count, for_each, dynamic blocks, for expressions)\n- Days 10-11: Modules (creation, usage, composition, best practices)\n\n---\n\n### üìù **REMAINING CONTENT**\n\nDue to response length constraints, the following sections will be added next:\n\n**PART 4: PRODUCTION READY (Days 12-18)**\n- Day 12: Workspaces (managing multiple environments)\n- Day 13: Remote State (S3, Azure Blob, Terraform Cloud)\n- Day 14: State Locking (DynamoDB, preventing conflicts)\n- Day 15: Import & Migration (bringing existing infrastructure)\n- Day 16: Provisioners (local-exec, remote-exec, file)\n- Day 17: Lifecycle Rules & Conditions (advanced resource management)\n- Day 18: Terraform Cloud & Enterprise\n\n**PART 5: BEST PRACTICES (Days 19-22)**\n- Day 19: Project Structure & Organization\n- Day 20: Security Best Practices (secrets, policies, compliance)\n- Day 21: Testing Strategies (terraform validate, tflint, terratest)\n- Day 22: CI/CD Integration (GitHub Actions, GitLab CI, Jenkins)\n\n**PART 6: REAL-WORLD PROJECTS (5 Complete Projects)**\n- Project 1: Simple Web Server (EC2 + Security Group + EIP)\n- Project 2: Complete VPC & Networking (Multi-AZ, NAT Gateway, Bastion)\n- Project 3: Multi-Tier Application (ALB, ASG, RDS, ElastiCache)\n- Project 4: EKS Kubernetes Cluster (Production-ready Kubernetes)\n- Project 5: Multi-Cloud Deployment (AWS + Azure + GCP together)\n\n**BONUS SECTIONS**\n- Advanced State Management\n- Terraform Graph & Visualization\n- Performance Optimization\n- Troubleshooting Guide\n- Certification Preparation (Terraform Associate)\n- Cheat Sheets & Quick Reference\n\n---\n\n### üìà **Current Statistics**\n\n- **Total Lines**: ~7,450+\n- **Sections Completed**: 11 days of comprehensive content\n- **Code Examples**: 100+ real-world examples\n- **Remaining Sections**: 11 days + 5 projects + bonus content\n\n---\n\n## üéØ What You've Learned So Far\n\nAt this point, you have mastered:\n\n1. ‚úÖ **Terraform Fundamentals** - Core concepts, workflow, HCL syntax\n2. ‚úÖ **Provider Configuration** - AWS, Azure, GCP setup and authentication\n3. ‚úÖ **Resource Management** - Creating, updating, and managing infrastructure\n4. ‚úÖ **Variables & Outputs** - Dynamic, reusable configurations\n5. ‚úÖ **Data Sources** - Querying existing infrastructure\n6. ‚úÖ **Advanced Iteration** - count, for_each, dynamic blocks, complex transformations\n7. ‚úÖ **Modules** - Creating reusable, composable infrastructure components\n\n**You can now:**\n- ‚úÖ Write production-quality Terraform code\n- ‚úÖ Create reusable modules\n- ‚úÖ Deploy multi-tier applications\n- ‚úÖ Use advanced HCL features\n- ‚úÖ Follow Terraform best practices\n\n**Next steps will cover:**\n- üîú Production deployment patterns\n- üîú State management & collaboration\n- üîú Security & compliance\n- üîú Testing & CI/CD\n- üîú Complete real-world projects\n\n---\n\n## üöÄ Continue Learning\n\nThe remaining content (Days 12-22 + 5 Projects + Bonus) will be added to complete this comprehensive guide. Would you like me to:\n\n1. ‚úÖ Continue with Days 12-18 (Production Ready)\n2. ‚úÖ Continue with Days 19-22 (Best Practices)\n3. ‚úÖ Add all 5 Real-World Projects\n4. ‚úÖ Add Bonus Sections\n\n**Let me know and I'll continue building the complete guide!** üéì\n\n---"}