{"id":"kubernetes-guide","title":"â˜¸ï¸ Kubernetes Zero to Hero","content":"# â˜¸ï¸ Kubernetes Zero to Hero - Complete Course\n\nA comprehensive course covering Kubernetes from basics to advanced topics with concise concepts and practical examples.\n\n---\n\n## ğŸ“š Table of Contents\n\n1. [Introduction and Core Concepts](#part-1-introduction-and-core-concepts)\n2. [Architecture Deep Dive](#part-2-architecture-deep-dive)\n3. [kubectl Mastery](#part-3-kubectl-mastery)\n4. [Pods In Depth](#part-4-pods-in-depth)\n5. [Controllers and Deployments](#part-5-controllers-and-deployments)\n6. [StatefulSets and DaemonSets](#part-6-statefulsets-and-daemonsets)\n7. [Services and Networking](#part-7-services-and-networking)\n8. [Storage](#part-8-storage)\n9. [ConfigMaps and Secrets](#part-9-configmaps-and-secrets)\n10. [Ingress](#part-10-ingress)\n11. [Helm](#part-11-helm)\n12. [Security](#part-12-security)\n13. [Advanced Topics](#part-13-advanced-topics)\n\n---\n\n## ğŸ¯ Learning Path\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        BEGINNER                                      â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚\nâ”‚  â”‚ 01. Intro    â”‚â”€â”€â”€â–¶â”‚ 02. Arch     â”‚â”€â”€â”€â–¶â”‚ 03. kubectl  â”‚          â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                â”‚\n                                â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                      INTERMEDIATE                                    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚\nâ”‚  â”‚ 04. Pods     â”‚â”€â”€â”€â–¶â”‚ 05. Deploy   â”‚â”€â”€â”€â–¶â”‚ 06. State    â”‚          â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚\nâ”‚                                                  â”‚                   â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚\nâ”‚  â”‚ 07. Network  â”‚â—€â”€â”€â”€â”‚ 08. Storage  â”‚â—€â”€â”€â”€â”‚ 09. Config   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                â”‚\n                                â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        ADVANCED                                      â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚\nâ”‚  â”‚ 10. Ingress  â”‚â”€â”€â”€â–¶â”‚ 11. Helm     â”‚â”€â”€â”€â–¶â”‚ 12. Security â”‚          â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚\nâ”‚                                                  â”‚                   â”‚\nâ”‚                                                  â–¼                   â”‚\nâ”‚                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\nâ”‚                                          â”‚ 13. Advanced â”‚           â”‚\nâ”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n# Part 1: Introduction and Core Concepts\n\n## What is Kubernetes?\n\nKubernetes (K8s) is an open-source container orchestration platform that automates deployment, scaling, and management of containerized applications. Originally developed by Google, it's now maintained by the Cloud Native Computing Foundation (CNCF).\n\n## Why Kubernetes?\n\nKubernetes solves the challenge of running containerized applications at scale by providing automatic healing, scaling, load balancing, and deployment capabilities. It abstracts infrastructure complexity, letting you focus on your applications.\n\n### Key Benefits\n\n| Feature | Description |\n|---------|-------------|\n| **Self-healing** | Automatically restarts failed containers |\n| **Horizontal scaling** | Scale apps up/down based on demand |\n| **Service discovery** | Built-in DNS and load balancing |\n| **Rolling updates** | Zero-downtime deployments |\n| **Secret management** | Secure handling of sensitive data |\n| **Declarative config** | Define desired state, K8s maintains it |\n\n## Core Concepts Overview\n\n### Cluster Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         KUBERNETES CLUSTER                          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚                      CONTROL PLANE                             â”‚ â”‚\nâ”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚\nâ”‚  â”‚  â”‚ API     â”‚  â”‚ Controller   â”‚  â”‚Scheduler â”‚  â”‚   etcd     â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ Server  â”‚  â”‚ Manager      â”‚  â”‚          â”‚  â”‚            â”‚ â”‚ â”‚\nâ”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ”‚                                                                     â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚                       WORKER NODES                             â”‚ â”‚\nâ”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚\nâ”‚  â”‚  â”‚     Node 1      â”‚  â”‚     Node 2      â”‚  â”‚    Node 3      â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ â”‚   kubelet   â”‚ â”‚  â”‚ â”‚   kubelet   â”‚ â”‚  â”‚ â”‚  kubelet   â”‚ â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ â”‚ kube-proxy  â”‚ â”‚  â”‚ â”‚ kube-proxy  â”‚ â”‚  â”‚ â”‚ kube-proxy â”‚ â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ â”‚  Container  â”‚ â”‚  â”‚ â”‚  Container  â”‚ â”‚  â”‚ â”‚ Container  â”‚ â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ â”‚   Runtime   â”‚ â”‚  â”‚ â”‚   Runtime   â”‚ â”‚  â”‚ â”‚  Runtime   â”‚ â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚\nâ”‚  â”‚  â”‚ [Pod][Pod][Pod] â”‚  â”‚ [Pod][Pod][Pod] â”‚  â”‚ [Pod][Pod]     â”‚ â”‚ â”‚\nâ”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Kubernetes Objects\n\n| Object | Purpose |\n|--------|---------|\n| **Pod** | Smallest deployable unit, contains one or more containers |\n| **Service** | Stable network endpoint to access Pods |\n| **Deployment** | Manages ReplicaSets for stateless apps |\n| **ConfigMap** | Store non-sensitive configuration |\n| **Secret** | Store sensitive data (passwords, tokens) |\n| **Namespace** | Virtual cluster for resource isolation |\n\n## Setting Up Kubernetes\n\n### Local Development Options\n\n| Tool | Best For | Resources |\n|------|----------|-----------|\n| **Minikube** | Learning, single-node | Moderate |\n| **kind** | CI/CD, testing | Low |\n| **k3d** | Lightweight local dev | Very Low |\n| **Docker Desktop** | Mac/Windows users | Integrated |\n\n### Quick Start with Minikube\n\n```bash\n# Install minikube\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n\n# Start cluster\nminikube start\n\n# Verify installation\nkubectl cluster-info\nkubectl get nodes\n```\n\n---\n\n# Part 2: Architecture Deep Dive\n\n## Control Plane Components\n\nThe control plane makes global decisions about the cluster and detects/responds to cluster events.\n\n### API Server\n\n```\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚      API Server     â”‚\n                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n   kubectl â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚ Authenticationâ”‚  â”‚\n   Dashboard â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚ Authorization â”‚  â”‚â—€â”€â”€â”€â”€ kubelet\n   Controllers â”€â”€â”€â”€â–¶â”‚  â”‚  Admission    â”‚  â”‚â—€â”€â”€â”€â”€ Scheduler\n                    â”‚  â”‚  Validation   â”‚  â”‚\n                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                               â”‚\n                               â–¼\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚        etcd         â”‚\n                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### etcd\n\netcd is a distributed key-value store that holds all cluster data.\n\n```bash\n# Check etcd cluster health\nkubectl -n kube-system exec etcd-master -- etcdctl endpoint health\n```\n\n### Scheduler\n\nThe scheduler watches for newly created Pods and assigns them to nodes.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚              SCHEDULER DECISION FLOW               â”‚\nâ”‚                                                    â”‚\nâ”‚   New Pod â”€â”€â–¶ Filter Nodes â”€â”€â–¶ Score Nodes â”€â”€â–¶    â”‚\nâ”‚                    â”‚               â”‚               â”‚\nâ”‚              â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”        â”‚\nâ”‚              â”‚ Feasible  â”‚   â”‚  Ranked   â”‚        â”‚\nâ”‚              â”‚  Nodes    â”‚   â”‚   Nodes   â”‚        â”‚\nâ”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\nâ”‚                                   â”‚               â”‚\nâ”‚                                   â–¼               â”‚\nâ”‚                            Best Node Selected     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Controller Manager\n\nControllers are control loops that watch the state of your cluster and make changes.\n\n| Controller | Responsibility |\n|------------|---------------|\n| Node Controller | Responds to node failures |\n| Replication Controller | Maintains correct number of pods |\n| Endpoints Controller | Populates Endpoints objects |\n| Service Account Controller | Creates default accounts for namespaces |\n\n## Worker Node Components\n\n### kubelet\n\nThe kubelet runs on each node and ensures containers are running in Pods.\n\n### kube-proxy\n\nkube-proxy maintains network rules on nodes for Service communication.\n\n### Container Runtime\n\nContainer runtimes execute containers (containerd, CRI-O, Docker).\n\n---\n\n# Part 3: kubectl Mastery\n\n## kubectl Basics\n\nkubectl is the command-line tool for interacting with Kubernetes clusters.\n\n```bash\n# Syntax\nkubectl [command] [TYPE] [NAME] [flags]\n\n# Examples\nkubectl get pods\nkubectl describe pod nginx\nkubectl create -f deployment.yaml\n```\n\n## Essential Commands\n\n### Cluster Information\n\n```bash\nkubectl cluster-info\nkubectl get nodes\nkubectl get namespaces\nkubectl config view\n```\n\n### Working with Pods\n\n```bash\nkubectl get pods\nkubectl get pods -o wide\nkubectl get pods --all-namespaces\nkubectl describe pod <pod-name>\nkubectl logs <pod-name>\nkubectl logs <pod-name> -c <container>\nkubectl exec -it <pod-name> -- /bin/sh\nkubectl delete pod <pod-name>\n```\n\n### Working with Deployments\n\n```bash\nkubectl get deployments\nkubectl describe deployment <name>\nkubectl scale deployment <name> --replicas=3\nkubectl rollout status deployment/<name>\nkubectl rollout history deployment/<name>\nkubectl rollout undo deployment/<name>\n```\n\n### Working with Services\n\n```bash\nkubectl get services\nkubectl describe service <name>\nkubectl expose deployment <name> --port=80 --type=LoadBalancer\n```\n\n## Output Formatting\n\n```bash\nkubectl get pods -o yaml\nkubectl get pods -o json\nkubectl get pods -o wide\nkubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase\n```\n\n## Context and Configuration\n\n```bash\nkubectl config current-context\nkubectl config get-contexts\nkubectl config use-context <context-name>\nkubectl config set-context --current --namespace=<namespace>\n```\n\n---\n\n# Part 4: Pods In Depth\n\n## What is a Pod?\n\nA Pod is the smallest deployable unit in Kubernetes, representing a single instance of a running process. Pods can contain one or more containers that share storage and network.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                      POD                            â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚                Shared Network               â”‚   â”‚\nâ”‚  â”‚              (localhost:port)               â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                     â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚ Container 1 â”‚  â”‚ Container 2 â”‚  â”‚ Container â”‚  â”‚\nâ”‚  â”‚   (app)     â”‚  â”‚  (sidecar)  â”‚  â”‚   (init)  â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ”‚         â”‚                â”‚                         â”‚\nâ”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚                                                 â”‚  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚              Shared Storage                 â”‚  â”‚\nâ”‚  â”‚              (volumes)                      â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Pod Specification\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.21\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n```\n\n## Pod Lifecycle\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Pending  â”‚â”€â”€â”€â–¶â”‚ Running  â”‚â”€â”€â”€â–¶â”‚Succeeded â”‚    â”‚  Failed  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n     â”‚                â”‚                               â–²\n     â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n     â”‚                         (error)\n     â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Unknown  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n| Phase | Description |\n|-------|-------------|\n| **Pending** | Pod accepted but containers not ready |\n| **Running** | At least one container is running |\n| **Succeeded** | All containers completed successfully |\n| **Failed** | All containers terminated, at least one failed |\n| **Unknown** | Pod state cannot be determined |\n\n## Multi-Container Pods\n\n### Sidecar Pattern\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: web-with-logging\nspec:\n  containers:\n  - name: web\n    image: nginx\n    volumeMounts:\n    - name: logs\n      mountPath: /var/log/nginx\n  - name: log-shipper\n    image: fluentd\n    volumeMounts:\n    - name: logs\n      mountPath: /logs\n  volumes:\n  - name: logs\n    emptyDir: {}\n```\n\n## Init Containers\n\nInit containers run before the main containers start.\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app-with-init\nspec:\n  initContainers:\n  - name: wait-for-db\n    image: busybox\n    command: ['sh', '-c', 'until nc -z db-service 5432; do sleep 2; done']\n  containers:\n  - name: app\n    image: myapp:1.0\n```\n\n---\n\n# Part 5: Controllers and Deployments\n\n## What are Controllers?\n\nControllers are control loops that watch the state of your cluster and make or request changes to move the current state toward the desired state.\n\n## Deployments\n\nDeployments manage ReplicaSets and provide declarative updates for Pods.\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n        ports:\n        - containerPort: 80\n```\n\n### Deployment Strategies\n\n```yaml\nspec:\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n```\n\n| Strategy | Description |\n|----------|-------------|\n| **RollingUpdate** | Gradually replace pods (default) |\n| **Recreate** | Kill all pods, then create new ones |\n\n### Rolling Updates\n\n```bash\n# Update image\nkubectl set image deployment/nginx nginx=nginx:1.22\n\n# Check rollout status\nkubectl rollout status deployment/nginx\n\n# View history\nkubectl rollout history deployment/nginx\n\n# Rollback\nkubectl rollout undo deployment/nginx\nkubectl rollout undo deployment/nginx --to-revision=2\n```\n\n## ReplicaSets\n\nReplicaSets ensure a specified number of pod replicas are running.\n\n```yaml\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: nginx-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n```\n\n## Jobs and CronJobs\n\n### Job\n\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: backup-job\nspec:\n  completions: 1\n  parallelism: 1\n  backoffLimit: 3\n  template:\n    spec:\n      containers:\n      - name: backup\n        image: backup-tool:1.0\n        command: [\"/backup.sh\"]\n      restartPolicy: Never\n```\n\n### CronJob\n\n```yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: backup-cron\nspec:\n  schedule: \"0 2 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: backup\n            image: backup-tool:1.0\n          restartPolicy: OnFailure\n```\n\n---\n\n# Part 6: StatefulSets and DaemonSets\n\n## StatefulSets\n\nStatefulSets manage stateful applications with stable network identities and persistent storage.\n\n```yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres\nspec:\n  serviceName: postgres\n  replicas: 3\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:14\n        ports:\n        - containerPort: 5432\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/postgresql/data\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 10Gi\n```\n\n### StatefulSet Features\n\n| Feature | Description |\n|---------|-------------|\n| **Stable Network ID** | Predictable pod names (app-0, app-1) |\n| **Stable Storage** | Each pod gets its own PVC |\n| **Ordered Operations** | Pods created/deleted in order |\n| **Headless Service** | Direct pod-to-pod communication |\n\n## DaemonSets\n\nDaemonSets ensure all (or some) nodes run a copy of a Pod.\n\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd\nspec:\n  selector:\n    matchLabels:\n      name: fluentd\n  template:\n    metadata:\n      labels:\n        name: fluentd\n    spec:\n      containers:\n      - name: fluentd\n        image: fluentd:latest\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n```\n\n### DaemonSet Use Cases\n\n- Log collection (Fluentd, Filebeat)\n- Node monitoring (Prometheus Node Exporter)\n- Network plugins (Calico, Weave)\n- Storage daemons\n\n---\n\n# Part 7: Services and Networking\n\n## What are Services?\n\nServices provide stable network endpoints to access a set of Pods, enabling loose coupling.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                       SERVICE                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚              Stable IP: 10.96.0.100             â”‚   â”‚\nâ”‚  â”‚              DNS: my-service.default.svc        â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                         â”‚                               â”‚\nâ”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚\nâ”‚         â”‚               â”‚               â”‚              â”‚\nâ”‚         â–¼               â–¼               â–¼              â”‚\nâ”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\nâ”‚    â”‚  Pod 1  â”‚    â”‚  Pod 2  â”‚    â”‚  Pod 3  â”‚         â”‚\nâ”‚    â”‚10.0.0.1 â”‚    â”‚10.0.0.2 â”‚    â”‚10.0.0.3 â”‚         â”‚\nâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Service Types\n\n### ClusterIP (Default)\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  type: ClusterIP\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n```\n\n### NodePort\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  type: NodePort\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n    nodePort: 30080\n```\n\n### LoadBalancer\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  type: LoadBalancer\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n```\n\n## Service Type Comparison\n\n| Type | Scope | Use Case |\n|------|-------|----------|\n| **ClusterIP** | Internal only | Inter-service communication |\n| **NodePort** | External via node port | Development, testing |\n| **LoadBalancer** | External via cloud LB | Production traffic |\n| **ExternalName** | DNS CNAME | External service proxy |\n\n## DNS in Kubernetes\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    DNS Resolution                       â”‚\nâ”‚                                                         â”‚\nâ”‚  my-service                 â†’ ClusterIP (same namespace)â”‚\nâ”‚  my-service.default         â†’ ClusterIP                 â”‚\nâ”‚  my-service.default.svc     â†’ ClusterIP                 â”‚\nâ”‚  my-service.default.svc.cluster.local â†’ ClusterIP      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Network Policies\n\nNetwork Policies control traffic flow between Pods.\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: api-allow\nspec:\n  podSelector:\n    matchLabels:\n      app: api\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: frontend\n    ports:\n    - protocol: TCP\n      port: 8080\n```\n\n---\n\n# Part 8: Storage\n\n## Kubernetes Storage Model\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    STORAGE HIERARCHY                            â”‚\nâ”‚                                                                 â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚   â”‚   Pod        â”‚    â”‚   Pod        â”‚    â”‚   Pod        â”‚    â”‚\nâ”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚\nâ”‚   â”‚ â”‚ Containerâ”‚ â”‚    â”‚ â”‚ Containerâ”‚ â”‚    â”‚ â”‚ Containerâ”‚ â”‚    â”‚\nâ”‚   â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚    â”‚\nâ”‚   â”‚      â”‚       â”‚    â”‚      â”‚       â”‚    â”‚      â”‚       â”‚    â”‚\nâ”‚   â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”‚    â”‚\nâ”‚   â”‚ â”‚ Volume   â”‚ â”‚    â”‚ â”‚ Volume   â”‚ â”‚    â”‚ â”‚ Volume   â”‚ â”‚    â”‚\nâ”‚   â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚    â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚          â”‚                   â”‚                   â”‚            â”‚\nâ”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\nâ”‚                              â”‚                                 â”‚\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\nâ”‚                    â”‚      PVC          â”‚                      â”‚\nâ”‚                    â”‚ (Claim)           â”‚                      â”‚\nâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚\nâ”‚                              â”‚                                 â”‚\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\nâ”‚                    â”‚      PV           â”‚                      â”‚\nâ”‚                    â”‚ (Physical Storage)â”‚                      â”‚\nâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚\nâ”‚                              â”‚                                 â”‚\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\nâ”‚                    â”‚  Storage Backend  â”‚                      â”‚\nâ”‚                    â”‚  (AWS EBS, GCE PD)â”‚                      â”‚\nâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Volumes\n\n### emptyDir\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: shared-volume\nspec:\n  containers:\n  - name: writer\n    image: busybox\n    volumeMounts:\n    - name: shared\n      mountPath: /data\n  - name: reader\n    image: busybox\n    volumeMounts:\n    - name: shared\n      mountPath: /data\n  volumes:\n  - name: shared\n    emptyDir: {}\n```\n\n### hostPath\n\n```yaml\nvolumes:\n- name: host-data\n  hostPath:\n    path: /data/app\n    type: DirectoryOrCreate\n```\n\n## Persistent Volumes (PV) and Claims (PVC)\n\n### PersistentVolume\n\n```yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: my-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: standard\n  hostPath:\n    path: /data/pv\n```\n\n### PersistentVolumeClaim\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: standard\n```\n\n### Using PVC in Pod\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    image: myapp\n    volumeMounts:\n    - name: data\n      mountPath: /app/data\n  volumes:\n  - name: data\n    persistentVolumeClaim:\n      claimName: my-pvc\n```\n\n## Storage Classes\n\n```yaml\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp3\n  iopsPerGB: \"10\"\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\n```\n\n---\n\n# Part 9: ConfigMaps and Secrets\n\n## ConfigMaps\n\nConfigMaps store non-sensitive configuration data as key-value pairs.\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  DATABASE_HOST: \"db.example.com\"\n  DATABASE_PORT: \"5432\"\n  app.properties: |\n    server.port=8080\n    logging.level=INFO\n```\n\n### Using ConfigMaps\n\n```yaml\n# As environment variables\nspec:\n  containers:\n  - name: app\n    envFrom:\n    - configMapRef:\n        name: app-config\n        \n# As volume\nspec:\n  containers:\n  - name: app\n    volumeMounts:\n    - name: config\n      mountPath: /etc/config\n  volumes:\n  - name: config\n    configMap:\n      name: app-config\n```\n\n## Secrets\n\nSecrets store sensitive data like passwords and API keys (base64 encoded).\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: db-secret\ntype: Opaque\ndata:\n  username: YWRtaW4=      # base64 encoded\n  password: cGFzc3dvcmQ=  # base64 encoded\n```\n\n### Creating Secrets\n\n```bash\n# From literal\nkubectl create secret generic db-secret \\\n  --from-literal=username=admin \\\n  --from-literal=password=secret\n\n# From file\nkubectl create secret generic tls-secret \\\n  --from-file=tls.crt \\\n  --from-file=tls.key\n```\n\n### Using Secrets\n\n```yaml\n# As environment variables\nspec:\n  containers:\n  - name: app\n    env:\n    - name: DB_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: db-secret\n          key: password\n\n# As volume\nspec:\n  containers:\n  - name: app\n    volumeMounts:\n    - name: secrets\n      mountPath: /etc/secrets\n      readOnly: true\n  volumes:\n  - name: secrets\n    secret:\n      secretName: db-secret\n```\n\n---\n\n# Part 10: Ingress\n\n## What is Ingress?\n\nIngress manages external HTTP/HTTPS access to services, providing load balancing, SSL termination, and name-based virtual hosting.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                                                                     â”‚\nâ”‚   Internet                                                          â”‚\nâ”‚       â”‚                                                             â”‚\nâ”‚       â–¼                                                             â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\nâ”‚   â”‚        INGRESS CONTROLLER             â”‚                        â”‚\nâ”‚   â”‚  (nginx, traefik, haproxy, etc.)      â”‚                        â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚                       â”‚                                             â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\nâ”‚   â”‚           INGRESS RESOURCE            â”‚                        â”‚\nâ”‚   â”‚  - Routing rules                      â”‚                        â”‚\nâ”‚   â”‚  - TLS configuration                  â”‚                        â”‚\nâ”‚   â”‚  - Path-based routing                 â”‚                        â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚                       â”‚                                             â”‚\nâ”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚\nâ”‚         â–¼             â–¼             â–¼                              â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\nâ”‚   â”‚ Service  â”‚  â”‚ Service  â”‚  â”‚ Service  â”‚                        â”‚\nâ”‚   â”‚   api    â”‚  â”‚  webapp  â”‚  â”‚  admin   â”‚                        â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚                                                                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Ingress Resource\n\n### Path-Based Routing\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: app.example.com\n    http:\n      paths:\n      - path: /api\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 80\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service\n            port:\n              number: 80\n```\n\n### TLS Configuration\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: tls-ingress\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - app.example.com\n    secretName: tls-secret\n  rules:\n  - host: app.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service\n            port:\n              number: 80\n```\n\n## Installing Ingress Controller\n\n```bash\n# NGINX Ingress Controller\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.0/deploy/static/provider/cloud/deploy.yaml\n\n# Verify installation\nkubectl get pods -n ingress-nginx\nkubectl get svc -n ingress-nginx\n```\n\n---\n\n# Part 11: Helm\n\n## What is Helm?\n\nHelm is the package manager for Kubernetes. It uses charts to define, install, and upgrade applications.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         HELM ARCHITECTURE                           â”‚\nâ”‚                                                                     â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚\nâ”‚   â”‚   Helm Client    â”‚                                             â”‚\nâ”‚   â”‚   (helm CLI)     â”‚                                             â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚\nâ”‚            â”‚                                                        â”‚\nâ”‚            â–¼                                                        â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\nâ”‚   â”‚   Chart Repo     â”‚       â”‚    K8s Cluster   â”‚                  â”‚\nâ”‚   â”‚  (charts.yaml)   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚                  â”‚                  â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                  â”‚\nâ”‚                              â”‚  â”‚  Release   â”‚  â”‚                  â”‚\nâ”‚                              â”‚  â”‚  Objects   â”‚  â”‚                  â”‚\nâ”‚                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚\nâ”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Installing Helm\n\n```bash\n# macOS\nbrew install helm\n\n# Linux\ncurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n\n# Verify installation\nhelm version\n```\n\n## Basic Commands\n\n```bash\n# Add repository\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\n\n# Search charts\nhelm search repo nginx\nhelm search hub wordpress\n\n# Install chart\nhelm install my-release bitnami/nginx\n\n# List releases\nhelm list\n\n# Upgrade release\nhelm upgrade my-release bitnami/nginx --set service.type=LoadBalancer\n\n# Uninstall\nhelm uninstall my-release\n```\n\n## Chart Structure\n\n```\nmychart/\nâ”œâ”€â”€ Chart.yaml          # Chart metadata\nâ”œâ”€â”€ values.yaml         # Default configuration\nâ”œâ”€â”€ charts/             # Dependencies\nâ”œâ”€â”€ templates/          # Kubernetes manifests\nâ”‚   â”œâ”€â”€ deployment.yaml\nâ”‚   â”œâ”€â”€ service.yaml\nâ”‚   â”œâ”€â”€ ingress.yaml\nâ”‚   â”œâ”€â”€ _helpers.tpl    # Template helpers\nâ”‚   â””â”€â”€ NOTES.txt       # Post-install notes\nâ””â”€â”€ README.md\n```\n\n## Creating Charts\n\n```bash\n# Create new chart\nhelm create mychart\n\n# Validate chart\nhelm lint mychart\n\n# Template locally\nhelm template mychart\n\n# Package chart\nhelm package mychart\n\n# Install local chart\nhelm install myrelease ./mychart\n```\n\n---\n\n# Part 12: Security\n\n## RBAC (Role-Based Access Control)\n\nRBAC regulates access to Kubernetes resources based on roles.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                          RBAC MODEL                                 â”‚\nâ”‚                                                                     â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\nâ”‚   â”‚    User/     â”‚         â”‚    Role/     â”‚                        â”‚\nâ”‚   â”‚ServiceAccountâ”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ ClusterRole  â”‚                        â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚          â”‚                        â”‚                                 â”‚\nâ”‚          â”‚    Binding             â”‚ Defines                        â”‚\nâ”‚          â”‚                        â”‚ Permissions                    â”‚\nâ”‚          â–¼                        â–¼                                 â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\nâ”‚   â”‚ RoleBinding/ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Resources   â”‚                        â”‚\nâ”‚   â”‚ClusterRole   â”‚         â”‚  (pods,      â”‚                        â”‚\nâ”‚   â”‚   Binding    â”‚         â”‚  services)   â”‚                        â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚                                                                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Role and RoleBinding\n\n```yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: default\n  name: pod-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: read-pods\n  namespace: default\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\n```\n\n### ClusterRole and ClusterRoleBinding\n\n```yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: secret-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: read-secrets-global\nsubjects:\n- kind: Group\n  name: managers\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: secret-reader\n  apiGroup: rbac.authorization.k8s.io\n```\n\n## Service Accounts\n\nService accounts provide identities for processes running in pods.\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: app-sa\n  namespace: default\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp\nspec:\n  serviceAccountName: app-sa\n  containers:\n  - name: app\n    image: myapp:1.0\n```\n\n## Security Contexts\n\nSecurity contexts define privilege and access control settings.\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: secure-pod\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 2000\n  containers:\n  - name: app\n    image: myapp\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n          - ALL\n```\n\n## Pod Security Standards\n\n| Level | Description |\n|-------|-------------|\n| **Privileged** | Unrestricted, allows known privilege escalations |\n| **Baseline** | Minimally restrictive, prevents known escalations |\n| **Restricted** | Heavily restricted, security best practices |\n\n```yaml\n# Apply to namespace\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: secure-ns\n  labels:\n    pod-security.kubernetes.io/enforce: restricted\n    pod-security.kubernetes.io/audit: restricted\n    pod-security.kubernetes.io/warn: restricted\n```\n\n---\n\n# Part 13: Advanced Topics\n\n## Health Probes\n\n### Liveness Probe\n\n```yaml\nspec:\n  containers:\n  - name: app\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n      initialDelaySeconds: 15\n      periodSeconds: 10\n      failureThreshold: 3\n```\n\n### Readiness Probe\n\n```yaml\nspec:\n  containers:\n  - name: app\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 5\n      periodSeconds: 5\n```\n\n### Startup Probe\n\n```yaml\nspec:\n  containers:\n  - name: app\n    startupProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n      failureThreshold: 30\n      periodSeconds: 10\n```\n\n## Horizontal Pod Autoscaler (HPA)\n\n```yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n```\n\n## Node Affinity and Taints\n\n### Node Affinity\n\n```yaml\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: disktype\n            operator: In\n            values:\n            - ssd\n```\n\n### Taints and Tolerations\n\n```bash\n# Add taint to node\nkubectl taint nodes node1 special=true:NoSchedule\n```\n\n```yaml\nspec:\n  tolerations:\n  - key: \"special\"\n    operator: \"Equal\"\n    value: \"true\"\n    effect: \"NoSchedule\"\n```\n\n## Resource Management\n\n```yaml\nspec:\n  containers:\n  - name: app\n    resources:\n      requests:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n      limits:\n        cpu: \"500m\"\n        memory: \"256Mi\"\n```\n\n## Troubleshooting\n\n### Common Commands\n\n```bash\n# Pod status\nkubectl describe pod <pod-name>\nkubectl logs <pod-name> --previous\nkubectl logs <pod-name> -c <container>\n\n# Events\nkubectl get events --sort-by='.lastTimestamp'\n\n# Debug pod\nkubectl exec -it <pod-name> -- /bin/sh\n\n# Resource usage\nkubectl top pods\nkubectl top nodes\n```\n\n### Common Issues\n\n| Problem | Check | Solution |\n|---------|-------|----------|\n| Pod Pending | `kubectl describe pod` | Check resources, node availability |\n| CrashLoopBackOff | `kubectl logs` | Fix application errors |\n| ImagePullBackOff | Image name/registry | Verify image exists, check secrets |\n| OOMKilled | Memory limits | Increase memory limits |\n\n---\n\n## ğŸ‰ Congratulations!\n\nYou've completed the Kubernetes Zero to Hero course! You now have the knowledge to:\n\n- âœ… Understand Kubernetes architecture\n- âœ… Deploy and manage applications\n- âœ… Configure networking and storage\n- âœ… Secure your cluster with RBAC\n- âœ… Use Helm for package management\n- âœ… Implement health checks and autoscaling\n- âœ… Troubleshoot common issues\n\n---\n\n## ğŸ“š Additional Resources\n\n- [Official Kubernetes Documentation](https://kubernetes.io/docs/)\n- [Kubernetes GitHub](https://github.com/kubernetes/kubernetes)\n- [CNCF Landscape](https://landscape.cncf.io/)\n- [Helm Documentation](https://helm.sh/docs/)\n\n---\n\n# Part 14: Real-World Production Patterns\n\n## Complete Microservices Application Deployment\n\n### E-Commerce Platform Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Production K8s Cluster                        â”‚\nâ”‚                                                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\nâ”‚  â”‚  Ingress   â”‚â”€â”€â”€â”€â–¶â”‚   Frontend â”‚â”€â”€â”€â”€â–¶â”‚   Backend  â”‚         â”‚\nâ”‚  â”‚  (NGINX)   â”‚     â”‚   (React)  â”‚     â”‚   (Node.js)â”‚         â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\nâ”‚        â”‚                                      â”‚                 â”‚\nâ”‚        â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                 â”‚\nâ”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Static   â”‚           â”‚                 â”‚\nâ”‚                     â”‚   Assets   â”‚           â”‚                 â”‚\nâ”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                 â”‚\nâ”‚                                              â–¼                 â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\nâ”‚  â”‚  Auth      â”‚â—€â”€â”€â”€â”€â”‚   API      â”‚â”€â”€â”€â”€â–¶â”‚  Payment   â”‚        â”‚\nâ”‚  â”‚  Service   â”‚     â”‚  Gateway   â”‚     â”‚  Service   â”‚        â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\nâ”‚        â”‚                  â”‚                   â”‚                â”‚\nâ”‚        â–¼                  â–¼                   â–¼                â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\nâ”‚  â”‚PostgreSQL  â”‚     â”‚   MongoDB  â”‚     â”‚   Redis    â”‚        â”‚\nâ”‚  â”‚(StatefulSetâ”‚     â”‚(StatefulSetâ”‚     â”‚(Deployment)â”‚        â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\nâ”‚                                                                â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\nâ”‚  â”‚  Monitoring Stack (Prometheus + Grafana)          â”‚       â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### 1. Namespace Organization\n\n```yaml\n# namespaces.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: production\n  labels:\n    environment: production\n    team: platform\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: staging\n  labels:\n    environment: staging\n    team: platform\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: monitoring\n  labels:\n    purpose: observability\n```\n\n### 2. Complete Frontend Deployment (React SPA)\n\n```yaml\n# frontend-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: production\n  labels:\n    app: frontend\n    tier: presentation\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n        version: v1.2.0\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - frontend\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: frontend\n        image: myregistry.io/frontend:v1.2.0\n        ports:\n        - containerPort: 80\n          name: http\n        env:\n        - name: REACT_APP_API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: frontend-config\n              key: api.url\n        - name: REACT_APP_ENV\n          value: \"production\"\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: nginx-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      volumes:\n      - name: nginx-config\n        configMap:\n          name: nginx-config\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\n  namespace: production\nspec:\n  selector:\n    app: frontend\n  ports:\n  - port: 80\n    targetPort: 80\n    name: http\n  type: ClusterIP\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: frontend-config\n  namespace: production\ndata:\n  api.url: \"https://api.myapp.com\"\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-config\n  namespace: production\ndata:\n  nginx.conf: |\n    events {\n        worker_connections 1024;\n    }\n    http {\n        include mime.types;\n        default_type application/octet-stream;\n        \n        gzip on;\n        gzip_types text/plain text/css application/json application/javascript;\n        \n        server {\n            listen 80;\n            server_name _;\n            root /usr/share/nginx/html;\n            index index.html;\n            \n            location / {\n                try_files $uri $uri/ /index.html;\n            }\n            \n            location /health {\n                return 200 'healthy';\n                add_header Content-Type text/plain;\n            }\n            \n            location /ready {\n                return 200 'ready';\n                add_header Content-Type text/plain;\n            }\n        }\n    }\n```\n\n### 3. Backend API Service (Node.js + Express)\n\n```yaml\n# backend-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend-api\n  namespace: production\n  labels:\n    app: backend-api\n    tier: application\nspec:\n  replicas: 5\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 2\n      maxUnavailable: 1\n  selector:\n    matchLabels:\n      app: backend-api\n  template:\n    metadata:\n      labels:\n        app: backend-api\n        version: v2.1.0\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"3000\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      serviceAccountName: backend-api-sa\n      initContainers:\n      - name: wait-for-db\n        image: busybox:1.28\n        command: ['sh', '-c', 'until nc -z postgres-service 5432; do echo waiting for postgres; sleep 2; done;']\n      containers:\n      - name: backend-api\n        image: myregistry.io/backend-api:v2.1.0\n        ports:\n        - containerPort: 3000\n          name: http\n        - containerPort: 9090\n          name: metrics\n        env:\n        - name: NODE_ENV\n          value: \"production\"\n        - name: PORT\n          value: \"3000\"\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: backend-secrets\n              key: database-url\n        - name: REDIS_URL\n          valueFrom:\n            configMapKeyRef:\n              name: backend-config\n              key: redis.url\n        - name: JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: backend-secrets\n              key: jwt-secret\n        - name: API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: backend-secrets\n              key: api-key\n        resources:\n          requests:\n            cpu: \"200m\"\n            memory: \"256Mi\"\n          limits:\n            cpu: \"1000m\"\n            memory: \"1Gi\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 3000\n          initialDelaySeconds: 10\n          periodSeconds: 5\n          timeoutSeconds: 3\n          successThreshold: 1\n        lifecycle:\n          preStop:\n            exec:\n              command: [\"/bin/sh\", \"-c\", \"sleep 15\"]\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 1000\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: backend-api\n  namespace: production\n  labels:\n    app: backend-api\nspec:\n  selector:\n    app: backend-api\n  ports:\n  - port: 80\n    targetPort: 3000\n    name: http\n  - port: 9090\n    targetPort: 9090\n    name: metrics\n  type: ClusterIP\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 10800\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: backend-api-sa\n  namespace: production\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: backend-secrets\n  namespace: production\ntype: Opaque\nstringData:\n  database-url: \"postgresql://user:password@postgres-service:5432/myapp\"\n  jwt-secret: \"your-super-secret-jwt-key-change-in-production\"\n  api-key: \"your-api-key-for-third-party-services\"\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: backend-config\n  namespace: production\ndata:\n  redis.url: \"redis://redis-service:6379\"\n  log.level: \"info\"\n  rate.limit: \"100\"\n```\n\n### 4. PostgreSQL StatefulSet (Production-Ready)\n\n```yaml\n# postgres-statefulset.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: postgres-config\n  namespace: production\ndata:\n  POSTGRES_DB: \"myapp\"\n  POSTGRES_USER: \"appuser\"\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: postgres-secret\n  namespace: production\ntype: Opaque\nstringData:\n  POSTGRES_PASSWORD: \"change-me-in-production\"\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres\n  namespace: production\nspec:\n  serviceName: postgres-service\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:15-alpine\n        ports:\n        - containerPort: 5432\n          name: postgres\n        envFrom:\n        - configMapRef:\n            name: postgres-config\n        - secretRef:\n            name: postgres-secret\n        volumeMounts:\n        - name: postgres-storage\n          mountPath: /var/lib/postgresql/data\n          subPath: postgres\n        - name: postgres-init\n          mountPath: /docker-entrypoint-initdb.d\n        resources:\n          requests:\n            cpu: \"500m\"\n            memory: \"1Gi\"\n          limits:\n            cpu: \"2000m\"\n            memory: \"4Gi\"\n        livenessProbe:\n          exec:\n            command:\n            - pg_isready\n            - -U\n            - appuser\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - pg_isready\n            - -U\n            - appuser\n          initialDelaySeconds: 5\n          periodSeconds: 5\n      volumes:\n      - name: postgres-init\n        configMap:\n          name: postgres-init-script\n  volumeClaimTemplates:\n  - metadata:\n      name: postgres-storage\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      storageClassName: fast-ssd\n      resources:\n        requests:\n          storage: 50Gi\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-service\n  namespace: production\nspec:\n  selector:\n    app: postgres\n  ports:\n  - port: 5432\n    targetPort: 5432\n  clusterIP: None\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: postgres-init-script\n  namespace: production\ndata:\n  init.sql: |\n    CREATE TABLE IF NOT EXISTS users (\n      id SERIAL PRIMARY KEY,\n      email VARCHAR(255) UNIQUE NOT NULL,\n      password_hash VARCHAR(255) NOT NULL,\n      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n    );\n    \n    CREATE TABLE IF NOT EXISTS products (\n      id SERIAL PRIMARY KEY,\n      name VARCHAR(255) NOT NULL,\n      price DECIMAL(10,2) NOT NULL,\n      stock INTEGER DEFAULT 0,\n      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n    );\n    \n    CREATE TABLE IF NOT EXISTS orders (\n      id SERIAL PRIMARY KEY,\n      user_id INTEGER REFERENCES users(id),\n      total_amount DECIMAL(10,2) NOT NULL,\n      status VARCHAR(50) DEFAULT 'pending',\n      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n    );\n    \n    CREATE INDEX idx_orders_user_id ON orders(user_id);\n    CREATE INDEX idx_orders_status ON orders(status);\n```\n\n### 5. Redis Cache Deployment\n\n```yaml\n# redis-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  namespace: production\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:7-alpine\n        ports:\n        - containerPort: 6379\n          name: redis\n        command:\n        - redis-server\n        - --appendonly\n        - \"yes\"\n        - --requirepass\n        - \"$(REDIS_PASSWORD)\"\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: password\n        volumeMounts:\n        - name: redis-storage\n          mountPath: /data\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"256Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"1Gi\"\n        livenessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 5\n          periodSeconds: 5\n      volumes:\n      - name: redis-storage\n        persistentVolumeClaim:\n          claimName: redis-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-service\n  namespace: production\nspec:\n  selector:\n    app: redis\n  ports:\n  - port: 6379\n    targetPort: 6379\n  type: ClusterIP\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: redis-secret\n  namespace: production\ntype: Opaque\nstringData:\n  password: \"redis-strong-password-change-me\"\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-pvc\n  namespace: production\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: fast-ssd\n```\n\n### 6. Production-Grade Ingress with TLS\n\n```yaml\n# ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: main-ingress\n  namespace: production\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rate-limit: \"100\"\n    nginx.ingress.kubernetes.io/limit-rps: \"10\"\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-methods: \"GET, POST, PUT, DELETE, OPTIONS\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: \"https://myapp.com\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - myapp.com\n    - www.myapp.com\n    - api.myapp.com\n    secretName: myapp-tls\n  rules:\n  - host: myapp.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: frontend\n            port:\n              number: 80\n  - host: www.myapp.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: frontend\n            port:\n              number: 80\n  - host: api.myapp.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: backend-api\n            port:\n              number: 80\n```\n\n### 7. Horizontal Pod Autoscaler\n\n```yaml\n# hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: backend-api-hpa\n  namespace: production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: backend-api\n  minReplicas: 3\n  maxReplicas: 20\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 50\n        periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 0\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 30\n      - type: Pods\n        value: 4\n        periodSeconds: 30\n      selectPolicy: Max\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: frontend-hpa\n  namespace: production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: frontend\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 60\n```\n\n### 8. Network Policies (Security)\n\n```yaml\n# network-policies.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: backend-api-policy\n  namespace: production\nspec:\n  podSelector:\n    matchLabels:\n      app: backend-api\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  # Allow from frontend\n  - from:\n    - podSelector:\n        matchLabels:\n          app: frontend\n    ports:\n    - protocol: TCP\n      port: 3000\n  # Allow from ingress controller\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    ports:\n    - protocol: TCP\n      port: 3000\n  egress:\n  # Allow to PostgreSQL\n  - to:\n    - podSelector:\n        matchLabels:\n          app: postgres\n    ports:\n    - protocol: TCP\n      port: 5432\n  # Allow to Redis\n  - to:\n    - podSelector:\n        matchLabels:\n          app: redis\n    ports:\n    - protocol: TCP\n      port: 6379\n  # Allow DNS\n  - to:\n    - namespaceSelector: {}\n    ports:\n    - protocol: UDP\n      port: 53\n  # Allow HTTPS to external APIs\n  - to:\n    - namespaceSelector: {}\n    ports:\n    - protocol: TCP\n      port: 443\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: postgres-policy\n  namespace: production\nspec:\n  podSelector:\n    matchLabels:\n      app: postgres\n  policyTypes:\n  - Ingress\n  ingress:\n  # Only allow from backend-api\n  - from:\n    - podSelector:\n        matchLabels:\n          app: backend-api\n    ports:\n    - protocol: TCP\n      port: 5432\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: redis-policy\n  namespace: production\nspec:\n  podSelector:\n    matchLabels:\n      app: redis\n  policyTypes:\n  - Ingress\n  ingress:\n  # Only allow from backend-api\n  - from:\n    - podSelector:\n        matchLabels:\n          app: backend-api\n    ports:\n    - protocol: TCP\n      port: 6379\n```\n\n### 9. Pod Disruption Budget\n\n```yaml\n# pdb.yaml\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: backend-api-pdb\n  namespace: production\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: backend-api\n---\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: frontend-pdb\n  namespace: production\nspec:\n  minAvailable: 1\n  selector:\n    matchLabels:\n      app: frontend\n```\n\n### 10. Resource Quotas and Limit Ranges\n\n```yaml\n# resource-limits.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: production-quota\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"50\"\n    requests.memory: \"100Gi\"\n    limits.cpu: \"100\"\n    limits.memory: \"200Gi\"\n    persistentvolumeclaims: \"20\"\n    services.loadbalancers: \"3\"\n---\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: production-limitrange\n  namespace: production\nspec:\n  limits:\n  - max:\n      cpu: \"4\"\n      memory: \"8Gi\"\n    min:\n      cpu: \"50m\"\n      memory: \"64Mi\"\n    default:\n      cpu: \"500m\"\n      memory: \"512Mi\"\n    defaultRequest:\n      cpu: \"100m\"\n      memory: \"256Mi\"\n    type: Container\n  - max:\n      cpu: \"8\"\n      memory: \"16Gi\"\n    min:\n      cpu: \"100m\"\n      memory: \"128Mi\"\n    type: Pod\n```\n\n---\n\n# Part 15: Monitoring and Observability\n\n## Complete Monitoring Stack\n\n### 1. Prometheus Setup\n\n```yaml\n# prometheus-deployment.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: monitoring\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      evaluation_interval: 15s\n    \n    scrape_configs:\n    - job_name: 'kubernetes-apiservers'\n      kubernetes_sd_configs:\n      - role: endpoints\n      scheme: https\n      tls_config:\n        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n      relabel_configs:\n      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n        action: keep\n        regex: default;kubernetes;https\n    \n    - job_name: 'kubernetes-nodes'\n      kubernetes_sd_configs:\n      - role: node\n      relabel_configs:\n      - action: labelmap\n        regex: __meta_kubernetes_node_label_(.+)\n    \n    - job_name: 'kubernetes-pods'\n      kubernetes_sd_configs:\n      - role: pod\n      relabel_configs:\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n        action: keep\n        regex: true\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n        action: replace\n        target_label: __metrics_path__\n        regex: (.+)\n      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n        action: replace\n        regex: ([^:]+)(?::\\d+)?;(\\d+)\n        replacement: $1:$2\n        target_label: __address__\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prometheus\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prometheus\n  template:\n    metadata:\n      labels:\n        app: prometheus\n    spec:\n      serviceAccountName: prometheus\n      containers:\n      - name: prometheus\n        image: prom/prometheus:v2.45.0\n        args:\n        - '--config.file=/etc/prometheus/prometheus.yml'\n        - '--storage.tsdb.path=/prometheus'\n        - '--storage.tsdb.retention.time=30d'\n        ports:\n        - containerPort: 9090\n          name: http\n        volumeMounts:\n        - name: prometheus-config\n          mountPath: /etc/prometheus\n        - name: prometheus-storage\n          mountPath: /prometheus\n        resources:\n          requests:\n            cpu: \"500m\"\n            memory: \"2Gi\"\n          limits:\n            cpu: \"2000m\"\n            memory: \"8Gi\"\n      volumes:\n      - name: prometheus-config\n        configMap:\n          name: prometheus-config\n      - name: prometheus-storage\n        persistentVolumeClaim:\n          claimName: prometheus-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: prometheus\n  namespace: monitoring\nspec:\n  selector:\n    app: prometheus\n  ports:\n  - port: 9090\n    targetPort: 9090\n  type: ClusterIP\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: prometheus\n  namespace: monitoring\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: prometheus\nrules:\n- apiGroups: [\"\"]\n  resources:\n  - nodes\n  - nodes/proxy\n  - services\n  - endpoints\n  - pods\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups:\n  - extensions\n  resources:\n  - ingresses\n  verbs: [\"get\", \"list\", \"watch\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: prometheus\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: prometheus\nsubjects:\n- kind: ServiceAccount\n  name: prometheus\n  namespace: monitoring\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: prometheus-pvc\n  namespace: monitoring\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n  storageClassName: fast-ssd\n```\n\n### 2. Grafana Dashboards\n\n```yaml\n# grafana-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      labels:\n        app: grafana\n    spec:\n      containers:\n      - name: grafana\n        image: grafana/grafana:10.0.0\n        ports:\n        - containerPort: 3000\n          name: http\n        env:\n        - name: GF_SECURITY_ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: grafana-secret\n              key: admin-password\n        - name: GF_SERVER_ROOT_URL\n          value: \"https://grafana.myapp.com\"\n        volumeMounts:\n        - name: grafana-storage\n          mountPath: /var/lib/grafana\n        - name: grafana-datasources\n          mountPath: /etc/grafana/provisioning/datasources\n        - name: grafana-dashboards\n          mountPath: /etc/grafana/provisioning/dashboards\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"256Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"1Gi\"\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: grafana-pvc\n      - name: grafana-datasources\n        configMap:\n          name: grafana-datasources\n      - name: grafana-dashboards\n        configMap:\n          name: grafana-dashboards\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: grafana\n  namespace: monitoring\nspec:\n  selector:\n    app: grafana\n  ports:\n  - port: 80\n    targetPort: 3000\n  type: ClusterIP\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: grafana-secret\n  namespace: monitoring\ntype: Opaque\nstringData:\n  admin-password: \"change-me-in-production\"\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: grafana-pvc\n  namespace: monitoring\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: standard\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: grafana-datasources\n  namespace: monitoring\ndata:\n  prometheus.yaml: |\n    apiVersion: 1\n    datasources:\n    - name: Prometheus\n      type: prometheus\n      access: proxy\n      url: http://prometheus:9090\n      isDefault: true\n      editable: false\n```\n\n### 3. Logging with Fluentd\n\n```yaml\n# fluentd-daemonset.yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd\n  namespace: monitoring\n  labels:\n    app: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: fluentd\n  template:\n    metadata:\n      labels:\n        app: fluentd\n    spec:\n      serviceAccountName: fluentd\n      containers:\n      - name: fluentd\n        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch\n        env:\n        - name: FLUENT_ELASTICSEARCH_HOST\n          value: \"elasticsearch.monitoring.svc.cluster.local\"\n        - name: FLUENT_ELASTICSEARCH_PORT\n          value: \"9200\"\n        - name: FLUENT_ELASTICSEARCH_SCHEME\n          value: \"http\"\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"256Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: fluentd\n  namespace: monitoring\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: fluentd\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  - namespaces\n  verbs:\n  - get\n  - list\n  - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: fluentd\nroleRef:\n  kind: ClusterRole\n  name: fluentd\n  apiGroup: rbac.authorization.k8s.io\nsubjects:\n- kind: ServiceAccount\n  name: fluentd\n  namespace: monitoring\n```\n\n---\n\n# Part 16: CI/CD Integration\n\n## GitOps with ArgoCD\n\n### 1. ArgoCD Installation\n\n```yaml\n# argocd-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: argocd\n```\n\n```bash\n# Install ArgoCD\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Get initial admin password\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n\n# Port forward to access UI\nkubectl port-forward svc/argocd-server -n argocd 8080:443\n```\n\n### 2. Application Definition\n\n```yaml\n# application.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: myapp-production\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/mycompany/myapp-k8s.git\n    targetRevision: main\n    path: production\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: production\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n    syncOptions:\n    - CreateNamespace=true\n  revisionHistoryLimit: 10\n```\n\n### 3. CI/CD Pipeline (GitHub Actions)\n\n```yaml\n# .github/workflows/deploy.yml\nname: Build and Deploy\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ github.actor }}\n        password: ${{ secrets.GITHUB_TOKEN }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=semver,pattern={{version}}\n          type=semver,pattern={{major}}.{{minor}}\n          type=sha\n\n    - name: Build and push Docker image\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n    - name: Checkout k8s repo\n      uses: actions/checkout@v3\n      with:\n        repository: mycompany/myapp-k8s\n        token: ${{ secrets.GIT_TOKEN }}\n\n    - name: Update image tag\n      run: |\n        cd production\n        sed -i \"s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${GITHUB_SHA::7}|\" deployment.yaml\n\n    - name: Commit and push\n      run: |\n        git config user.name \"GitHub Actions\"\n        git config user.email \"actions@github.com\"\n        git add .\n        git commit -m \"Update image to sha-${GITHUB_SHA::7}\"\n        git push\n```\n\n---\n\n# Part 17: Disaster Recovery & Backup\n\n## Backup Strategies\n\n### 1. Velero Setup (Cluster Backup)\n\n```bash\n# Install Velero CLI\nwget https://github.com/vmware-tanzu/velero/releases/download/v1.11.0/velero-v1.11.0-linux-amd64.tar.gz\ntar -xvf velero-v1.11.0-linux-amd64.tar.gz\nsudo mv velero-v1.11.0-linux-amd64/velero /usr/local/bin/\n\n# Install Velero in cluster (AWS example)\nvelero install \\\n  --provider aws \\\n  --plugins velero/velero-plugin-for-aws:v1.7.0 \\\n  --bucket my-backup-bucket \\\n  --backup-location-config region=us-east-1 \\\n  --snapshot-location-config region=us-east-1 \\\n  --secret-file ./credentials-velero\n\n# Create backup schedule\nvelero schedule create daily-backup \\\n  --schedule=\"0 2 * * *\" \\\n  --include-namespaces production,staging\n\n# Backup specific namespace\nvelero backup create production-backup --include-namespaces production\n\n# Restore from backup\nvelero restore create --from-backup production-backup\n```\n\n### 2. Database Backup CronJob\n\n```yaml\n# postgres-backup-cronjob.yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: postgres-backup\n  namespace: production\nspec:\n  schedule: \"0 2 * * *\"  # Daily at 2 AM\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: backup\n            image: postgres:15-alpine\n            command:\n            - /bin/sh\n            - -c\n            - |\n              TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n              pg_dump -h postgres-service -U appuser -d myapp > /backup/backup_${TIMESTAMP}.sql\n              # Upload to S3\n              aws s3 cp /backup/backup_${TIMESTAMP}.sql s3://my-backups/postgres/\n              # Keep only last 30 days\n              find /backup -name \"backup_*.sql\" -mtime +30 -delete\n            env:\n            - name: PGPASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secret\n                  key: POSTGRES_PASSWORD\n            volumeMounts:\n            - name: backup-volume\n              mountPath: /backup\n          restartPolicy: OnFailure\n          volumes:\n          - name: backup-volume\n            persistentVolumeClaim:\n              claimName: postgres-backup-pvc\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: postgres-backup-pvc\n  namespace: production\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n  storageClassName: standard\n```\n\n---\n\n# Part 18: Cost Optimization\n\n## Resource Optimization Strategies\n\n### 1. Vertical Pod Autoscaler\n\n```yaml\n# vpa.yaml\napiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: backend-api-vpa\n  namespace: production\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: backend-api\n  updatePolicy:\n    updateMode: \"Auto\"\n  resourcePolicy:\n    containerPolicies:\n    - containerName: backend-api\n      minAllowed:\n        cpu: 100m\n        memory: 128Mi\n      maxAllowed:\n        cpu: 2\n        memory: 2Gi\n```\n\n### 2. Cluster Autoscaler Configuration\n\n```yaml\n# cluster-autoscaler.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cluster-autoscaler\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cluster-autoscaler\n  template:\n    metadata:\n      labels:\n        app: cluster-autoscaler\n    spec:\n      serviceAccountName: cluster-autoscaler\n      containers:\n      - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.27.0\n        name: cluster-autoscaler\n        command:\n        - ./cluster-autoscaler\n        - --v=4\n        - --stderrthreshold=info\n        - --cloud-provider=aws\n        - --skip-nodes-with-local-storage=false\n        - --expander=least-waste\n        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/my-cluster\n        - --balance-similar-node-groups\n        - --skip-nodes-with-system-pods=false\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 300Mi\n```\n\n### 3. Pod Priority Classes\n\n```yaml\n# priority-classes.yaml\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: high-priority\nvalue: 1000000\nglobalDefault: false\ndescription: \"High priority for critical services\"\n---\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: medium-priority\nvalue: 100000\nglobalDefault: false\ndescription: \"Medium priority for regular services\"\n---\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: low-priority\nvalue: 10000\nglobalDefault: true\ndescription: \"Low priority for batch jobs\"\n```\n\nApply to deployments:\n\n```yaml\nspec:\n  template:\n    spec:\n      priorityClassName: high-priority\n      containers:\n      - name: backend-api\n        image: myapp:latest\n```\n\n---\n\n# Part 19: Multi-Cluster Management\n\n## Federation and Multi-Cluster Strategies\n\n### 1. Kubefed (Kubernetes Federation)\n\n```bash\n# Install kubefedctl\ncurl -LO https://github.com/kubernetes-sigs/kubefed/releases/download/v0.10.0/kubefedctl-0.10.0-linux-amd64.tgz\ntar -xzf kubefedctl-0.10.0-linux-amd64.tgz\nsudo mv kubefedctl /usr/local/bin/\n\n# Initialize federation\nkubefedctl join cluster1 --cluster-context cluster1 \\\n  --host-cluster-context host-cluster\n\nkubefedctl join cluster2 --cluster-context cluster2 \\\n  --host-cluster-context host-cluster\n```\n\n### 2. Federated Deployment\n\n```yaml\n# federated-deployment.yaml\napiVersion: types.kubefed.io/v1beta1\nkind: FederatedDeployment\nmetadata:\n  name: myapp\n  namespace: default\nspec:\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      replicas: 3\n      selector:\n        matchLabels:\n          app: myapp\n      template:\n        metadata:\n          labels:\n            app: myapp\n        spec:\n          containers:\n          - name: myapp\n            image: myregistry.io/myapp:latest\n  placement:\n    clusters:\n    - name: cluster1\n    - name: cluster2\n  overrides:\n  - clusterName: cluster1\n    clusterOverrides:\n    - path: \"/spec/replicas\"\n      value: 5\n  - clusterName: cluster2\n    clusterOverrides:\n    - path: \"/spec/replicas\"\n      value: 3\n```\n\n---\n\n# Part 20: Troubleshooting Deep Dive\n\n## Advanced Debugging Techniques\n\n### 1. Debug Pod\n\n```yaml\n# debug-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: debug-pod\n  namespace: production\nspec:\n  containers:\n  - name: debug\n    image: nicolaka/netshoot\n    command: [\"/bin/bash\"]\n    args: [\"-c\", \"while true; do sleep 30; done\"]\n    securityContext:\n      capabilities:\n        add: [\"NET_ADMIN\", \"SYS_ADMIN\"]\n```\n\n```bash\n# Execute into debug pod\nkubectl exec -it debug-pod -n production -- /bin/bash\n\n# Inside debug pod\n# Test DNS\nnslookup backend-api.production.svc.cluster.local\n\n# Test connectivity\ncurl http://backend-api.production.svc.cluster.local\n\n# Check network\ntcpdump -i any port 3000\n\n# Test postgres connectivity\nnc -zv postgres-service 5432\n```\n\n### 2. Common Issues and Solutions\n\n```bash\n# 1. Pod stuck in Pending\nkubectl describe pod <pod-name> -n production\n# Check: Node resources, PVC binding, node affinity\n\n# 2. Pod stuck in CrashLoopBackOff\nkubectl logs <pod-name> -n production --previous\nkubectl describe pod <pod-name> -n production\n# Check: Application logs, liveness probes, resource limits\n\n# 3. Service not accessible\nkubectl get endpoints <service-name> -n production\nkubectl port-forward svc/<service-name> 8080:80 -n production\n# Check: Selector labels, pod readiness, network policies\n\n# 4. High memory usage\nkubectl top pods -n production --sort-by=memory\nkubectl exec <pod-name> -n production -- cat /proc/meminfo\n# Check: Memory leaks, increase limits, add HPA\n\n# 5. DNS resolution failures\nkubectl run -it --rm debug --image=busybox --restart=Never -- nslookup kubernetes.default\n# Check: CoreDNS pods, DNS policies\n\n# 6. PV/PVC issues\nkubectl get pv\nkubectl get pvc -n production\nkubectl describe pvc <pvc-name> -n production\n# Check: StorageClass, access modes, node affinity\n\n# 7. Image pull errors\nkubectl describe pod <pod-name> -n production | grep -A 10 Events\n# Check: Image name, registry credentials, network\n\n# 8. Node issues\nkubectl describe node <node-name>\nkubectl get node <node-name> -o yaml\n# Check: Disk pressure, memory pressure, network\n\n# 9. Resource quotas exceeded\nkubectl describe quota -n production\n# Check: Resource requests/limits\n\n# 10. RBAC permission denied\nkubectl auth can-i get pods --as=system:serviceaccount:production:backend-api-sa -n production\nkubectl get rolebindings,clusterrolebindings -n production\n# Check: ServiceAccount, Role, RoleBinding\n```\n\n### 3. Performance Profiling\n\n```bash\n# CPU profiling\nkubectl top nodes\nkubectl top pods -n production --containers\n\n# Get resource metrics\nkubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes\nkubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/production/pods\n\n# API server metrics\nkubectl get --raw /metrics\n\n# Etcd metrics\nkubectl exec -it etcd-master -n kube-system -- etcdctl endpoint status\n\n# Check pod events timeline\nkubectl get events -n production --sort-by='.lastTimestamp'\n```\n\n---\n\n## ğŸ‰ Final Summary\n\nYou've completed the **comprehensive Kubernetes Zero to Hero course** covering:\n\n### âœ… **Core Concepts** (Parts 1-13)\n- Architecture, Pods, Deployments, Services\n- Storage, ConfigMaps, Secrets\n- Ingress, Helm, Security, Advanced Topics\n\n### âœ… **Production Patterns** (Part 14)\n- Complete microservices application\n- Frontend, Backend, Databases\n- Security, Autoscaling, Network Policies\n\n### âœ… **Observability** (Part 15)\n- Prometheus monitoring\n- Grafana dashboards\n- Fluentd logging\n\n### âœ… **CI/CD** (Part 16)\n- ArgoCD GitOps\n- GitHub Actions pipelines\n\n### âœ… **Operations** (Parts 17-20)\n- Disaster recovery with Velero\n- Cost optimization\n- Multi-cluster management\n- Advanced troubleshooting\n\n---\n\n## ğŸš€ Next Steps\n\n1. **Practice**: Deploy the example applications in your cluster\n2. **Experiment**: Modify configurations and observe behavior\n3. **Production**: Apply these patterns to real workloads\n4. **Certify**: Consider CKA, CKAD, or CKS certifications\n5. **Contribute**: Join the Kubernetes community\n\n---\n\n## ğŸ“š Additional Resources\n\n- [Official Kubernetes Documentation](https://kubernetes.io/docs/)\n- [Kubernetes GitHub](https://github.com/kubernetes/kubernetes)\n- [CNCF Landscape](https://landscape.cncf.io/)\n- [Helm Documentation](https://helm.sh/docs/)\n- [ArgoCD Documentation](https://argo-cd.readthedocs.io/)\n- [Prometheus Documentation](https://prometheus.io/docs/)\n- [Kubernetes Patterns Book](https://k8spatterns.io/)\n\n---\n\n**Total Content: 5,500+ lines of production-ready Kubernetes knowledge!**\n\n**Happy Orchestrating! â˜¸ï¸**\n\n"}