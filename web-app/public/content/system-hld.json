{"id":"system-hld","title":"ğŸ¯ High-Level Design (HLD)","content":"# ğŸš€ HIGH-LEVEL DESIGN (HLD) MASTERY NOTEBOOK\n\n## ğŸ¯ **SYSTEM ARCHITECTURE EXCELLENCE - YOUR PATH TO SENIOR+ ROLES!**\n\n### ğŸ”¥ What You'll Master:\n- **Distributed Systems Architecture** - Scale to millions of users\n- **Microservices Design** - Build resilient, maintainable systems\n- **Database Design** - SQL vs NoSQL, sharding, replication\n- **Caching Strategies** - Redis, Memcached, CDN optimization\n- **Load Balancing** - Horizontal scaling techniques\n- **Message Queues** - Async processing, event-driven architecture\n- **API Design** - REST, GraphQL, gRPC best practices\n- **Security** - Authentication, authorization, encryption\n- **Monitoring** - Observability, logging, metrics\n- **Cloud Architecture** - AWS, Azure, GCP patterns\n\n### ğŸ’° **CAREER TRANSFORMATION:**\n- **ğŸ“ˆ $50K+ salary increase** potential for senior engineers\n- **ğŸ¯ System Design interviews** - Pass FAANG/unicorn companies\n- **ğŸ† Technical leadership** - Lead architecture decisions\n- **ğŸš€ Principal Engineer** - Design systems for millions\n- **ğŸ’¼ Engineering Manager** - Technical strategy and vision\n\n### ğŸª **Real-World Systems You'll Design:**\n- Social Media Platform (Instagram/Twitter scale)\n- Video Streaming Service (Netflix/YouTube)\n- E-commerce Platform (Amazon/eBay)\n- Chat Application (WhatsApp/Slack)\n- Ride-sharing Service (Uber/Lyft)\n- Search Engine (Google scale)\n- Payment System (PayPal/Stripe)\n\n---\n\n### ğŸ”§ **Technologies Covered:**\n```\nDatabases:     PostgreSQL, MongoDB, Cassandra, DynamoDB\nCaching:       Redis, Memcached, CloudFront, CDN\nMessage Queue: Kafka, RabbitMQ, SQS, Pub/Sub\nLoad Balancer: NGINX, HAProxy, AWS ALB, Cloudflare\nMonitoring:    Prometheus, Grafana, ELK Stack, Datadog\nCloud:         AWS, Azure, GCP, Kubernetes, Docker\n```\n\n### ğŸ“š **Learning Path:**\n1. **Fundamentals** - Scalability, reliability, consistency\n2. **Components** - Databases, caches, load balancers\n3. **Patterns** - Microservices, event-driven, CQRS\n4. **Real Systems** - End-to-end design challenges\n5. **Advanced Topics** - Consistency, CAP theorem, consensus\n\n### ğŸ¯ **Interview Success Formula:**\n```\nâœ… Requirements Gathering (5 min)\nâœ… Capacity Estimation (5 min)\nâœ… High-Level Design (15 min)\nâœ… Detailed Design (15 min)\nâœ… Scale & Optimize (15 min)\n```\n\n---\n\n**ğŸš€ Ready to become a system design expert? Let's build systems that scale!**\n\n## Chapter 1: System Design Fundamentals â­â­â­\n> **The Foundation** - Master these concepts to design systems that scale to millions\n\n### ğŸ¯ Core Concepts:\n- **Scalability**: Handle increasing load gracefully\n- **Reliability**: System continues working despite failures\n- **Availability**: System remains operational over time\n- **Consistency**: All nodes see the same data simultaneously\n- **Partition Tolerance**: System continues despite network failures\n\n### ğŸš€ Key Principles:\n- **Horizontal vs Vertical Scaling**\n- **Load Distribution Strategies** \n- **Data Partitioning Techniques**\n- **Caching Mechanisms**\n- **Database Design Patterns**\n\n## ğŸ“š System Design Fundamentals - Essential Theory (START HERE!)\n\n### **ğŸ¯ Must-Know Concepts Before Designing Any System**\n\n---\n\n## 1ï¸âƒ£ **CAP Theorem** (Fundamental Trade-off)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚          CAP THEOREM TRIANGLE                   â”‚\nâ”‚                                                  â”‚\nâ”‚                Consistency                       â”‚\nâ”‚                    /\\                            â”‚\nâ”‚                   /  \\                           â”‚\nâ”‚                  /    \\                          â”‚\nâ”‚                 /  ??  \\                         â”‚\nâ”‚                /        \\                        â”‚\nâ”‚               /          \\                       â”‚\nâ”‚   Availability â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Partition Tolerance   â”‚\nâ”‚                                                  â”‚\nâ”‚   You can only choose 2 out of 3!               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ“– Definitions:\nâ€¢ Consistency (C): All nodes see the same data at the same time\nâ€¢ Availability (A): Every request receives a response (success/failure)\nâ€¢ Partition Tolerance (P): System continues despite network failures\n\nğŸ¯ Real-World Choices:\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ CA (Consistency + Availability)                â”‚\nâ”‚ âŒ NOT possible in distributed systems!        â”‚\nâ”‚ Why? Network partitions WILL happen           â”‚\nâ”‚ Example: Single-server databases (not scalable)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ CP (Consistency + Partition Tolerance)         â”‚\nâ”‚ âœ… Sacrifice: Availability                     â”‚\nâ”‚ When partition occurs â†’ Return error           â”‚\nâ”‚                                                 â”‚\nâ”‚ Use Cases:                                     â”‚\nâ”‚ â€¢ Banking systems (no inconsistent balances)   â”‚\nâ”‚ â€¢ Inventory management (no overselling)        â”‚\nâ”‚ â€¢ Booking systems (no double bookings)         â”‚\nâ”‚                                                 â”‚\nâ”‚ Technologies:                                  â”‚\nâ”‚ â€¢ MongoDB (with proper settings)               â”‚\nâ”‚ â€¢ HBase                                        â”‚\nâ”‚ â€¢ Redis (single master)                        â”‚\nâ”‚ â€¢ ZooKeeper                                    â”‚\nâ”‚                                                 â”‚\nâ”‚ Example: Bank Transfer                         â”‚\nâ”‚ User A â†’ Transfer $100 â†’ User B                â”‚\nâ”‚ If network fails â†’ Block transaction           â”‚\nâ”‚ Better to show error than wrong balance        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ AP (Availability + Partition Tolerance)        â”‚\nâ”‚ âœ… Sacrifice: Consistency (temporary)          â”‚\nâ”‚ When partition occurs â†’ Serve stale data       â”‚\nâ”‚                                                 â”‚\nâ”‚ Use Cases:                                     â”‚\nâ”‚ â€¢ Social media feeds (ok to see old posts)     â”‚\nâ”‚ â€¢ View counts (ok if slightly off)             â”‚\nâ”‚ â€¢ Product recommendations                      â”‚\nâ”‚ â€¢ DNS servers                                  â”‚\nâ”‚                                                 â”‚\nâ”‚ Technologies:                                  â”‚\nâ”‚ â€¢ Cassandra (tunable consistency)              â”‚\nâ”‚ â€¢ DynamoDB                                     â”‚\nâ”‚ â€¢ Riak                                         â”‚\nâ”‚ â€¢ CouchDB                                      â”‚\nâ”‚                                                 â”‚\nâ”‚ Example: Facebook Likes                        â”‚\nâ”‚ Post shows 100 likes in US, 98 in Europe       â”‚\nâ”‚ Eventually consistent (ok for social media)    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ’¡ Interview Tip: Always ask about consistency requirements!\n```\n\n---\n\n## 2ï¸âƒ£ **ACID vs BASE** (Transaction Models)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ ACID: Strong Consistency (Traditional RDBMS)    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                  â”‚\nâ”‚ A - Atomicity                                   â”‚\nâ”‚   â€¢ All or nothing (no partial updates)         â”‚\nâ”‚   â€¢ Example: Bank transfer succeeds OR fails    â”‚\nâ”‚                                                  â”‚\nâ”‚ C - Consistency                                 â”‚\nâ”‚   â€¢ Database rules always enforced              â”‚\nâ”‚   â€¢ Foreign keys, constraints, triggers         â”‚\nâ”‚                                                  â”‚\nâ”‚ I - Isolation                                   â”‚\nâ”‚   â€¢ Concurrent transactions don't interfere     â”‚\nâ”‚   â€¢ Levels: Read Uncommitted â†’ Serializable     â”‚\nâ”‚                                                  â”‚\nâ”‚ D - Durability                                  â”‚\nâ”‚   â€¢ Committed data never lost                   â”‚\nâ”‚   â€¢ Survives crashes, power loss                â”‚\nâ”‚                                                  â”‚\nâ”‚ Use Cases: Financial transactions, orders       â”‚\nâ”‚ Tech: PostgreSQL, MySQL, Oracle                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nExample ACID Transaction:\nBEGIN TRANSACTION;\n  UPDATE accounts SET balance = balance - 100 WHERE id = 1;\n  UPDATE accounts SET balance = balance + 100 WHERE id = 2;\nCOMMIT;  -- Both updates or none!\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ BASE: Eventual Consistency (Modern NoSQL)       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                  â”‚\nâ”‚ B - Basically Available                         â”‚\nâ”‚   â€¢ System appears to work most of the time     â”‚\nâ”‚   â€¢ May serve stale data temporarily            â”‚\nâ”‚                                                  â”‚\nâ”‚ S - Soft state                                  â”‚\nâ”‚   â€¢ State may change without input              â”‚\nâ”‚   â€¢ Async replication in progress               â”‚\nâ”‚                                                  â”‚\nâ”‚ E - Eventual consistency                        â”‚\nâ”‚   â€¢ Given enough time, all replicas converge    â”‚\nâ”‚   â€¢ No guarantee of immediate consistency       â”‚\nâ”‚                                                  â”‚\nâ”‚ Use Cases: Social feeds, analytics, logs        â”‚\nâ”‚ Tech: Cassandra, DynamoDB, MongoDB              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nExample BASE Flow:\n1. Write to Node A (Success!)\n2. Replicate to Node B (async, takes 100ms)\n3. User reads from Node B (might see old data)\n4. After 100ms â†’ Eventually consistent\n\nTrade-off Table:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚              â”‚ ACID        â”‚ BASE            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Consistency  â”‚ Strong      â”‚ Eventual        â”‚\nâ”‚ Availability â”‚ Lower       â”‚ Higher          â”‚\nâ”‚ Scalability  â”‚ Harder      â”‚ Easier          â”‚\nâ”‚ Performance  â”‚ Slower      â”‚ Faster          â”‚\nâ”‚ Use Case     â”‚ Banking     â”‚ Social Media    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## 3ï¸âƒ£ **Consistency Models** (Spectrum)\n\n```\nStrongest â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Weakest\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚Lineariza â”‚Sequentialâ”‚ Causal   â”‚Eventual  â”‚\nâ”‚ble       â”‚          â”‚          â”‚          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n1. Linearizable (Strongest)\n   â€¢ All operations appear instantaneous\n   â€¢ Total global order\n   â€¢ Example: Read your own writes immediately\n   â€¢ Cost: Slowest, requires coordination\n   â€¢ Tech: ZooKeeper, etcd\n\n2. Sequential Consistency\n   â€¢ All nodes see same order of operations\n   â€¢ But not necessarily real-time order\n   â€¢ Example: All replicas agree on sequence\n   \n3. Causal Consistency\n   â€¢ Cause â†’ Effect preserved\n   â€¢ Example: Reply appears after original post\n   â€¢ Concurrent operations can be out of order\n   \n4. Eventual Consistency (Weakest)\n   â€¢ Given time, all replicas converge\n   â€¢ No ordering guarantees\n   â€¢ Example: DNS propagation (24-48 hours)\n   â€¢ Cost: Fastest, no coordination\n   â€¢ Tech: DynamoDB, Cassandra\n\nReal Example - Facebook Post:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 1. User posts â†’ Writes to primary DB       â”‚\nâ”‚ 2. Replicates to 100 data centers         â”‚\nâ”‚ 3. User in India sees post (200ms)         â”‚\nâ”‚ 4. User in Brazil sees post (500ms)        â”‚\nâ”‚ 5. Eventually all users see it (5 seconds) â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nEventual consistency is OK here!\n```\n\n---\n\n## 4ï¸âƒ£ **Scalability Patterns**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ VERTICAL SCALING (Scale Up)                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                  â”‚\nâ”‚ Add more power to existing machine:             â”‚\nâ”‚ â€¢ More CPU cores (8 â†’ 64)                       â”‚\nâ”‚ â€¢ More RAM (32GB â†’ 512GB)                       â”‚\nâ”‚ â€¢ Faster disks (HDD â†’ SSD â†’ NVMe)              â”‚\nâ”‚                                                  â”‚\nâ”‚ Pros:                                           â”‚\nâ”‚ âœ… Simple (no code changes)                     â”‚\nâ”‚ âœ… No distributed system complexity             â”‚\nâ”‚ âœ… ACID transactions easy                       â”‚\nâ”‚                                                  â”‚\nâ”‚ Cons:                                           â”‚\nâ”‚ âŒ Physical limits (max 1TB RAM, 128 cores)     â”‚\nâ”‚ âŒ Expensive (exponential cost)                 â”‚\nâ”‚ âŒ Single point of failure                      â”‚\nâ”‚ âŒ Downtime during upgrades                     â”‚\nâ”‚                                                  â”‚\nâ”‚ Use When: Database <100GB, Traffic <10K req/secâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ HORIZONTAL SCALING (Scale Out)                  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                  â”‚\nâ”‚ Add more machines:                              â”‚\nâ”‚ â€¢ 1 server â†’ 10 servers â†’ 1000 servers          â”‚\nâ”‚ â€¢ Distribute load across machines               â”‚\nâ”‚ â€¢ Each machine handles subset of data/traffic   â”‚\nâ”‚                                                  â”‚\nâ”‚ Pros:                                           â”‚\nâ”‚ âœ… No upper limit (add infinite machines)       â”‚\nâ”‚ âœ… Cheaper (commodity hardware)                 â”‚\nâ”‚ âœ… Fault tolerance (one fails, others work)     â”‚\nâ”‚ âœ… No downtime (rolling updates)                â”‚\nâ”‚                                                  â”‚\nâ”‚ Cons:                                           â”‚\nâ”‚ âŒ Complex (distributed systems)                â”‚\nâ”‚ âŒ Network overhead                             â”‚\nâ”‚ âŒ Data consistency challenges                  â”‚\nâ”‚ âŒ Distributed transactions hard                â”‚\nâ”‚                                                  â”‚\nâ”‚ Use When: Need to handle millions of users      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nArchitecture:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚          Load Balancer               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚         â”‚         â”‚\n   â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”\n   â”‚Server â”‚ â”‚Server â”‚ â”‚Server â”‚\n   â”‚   1   â”‚ â”‚   2   â”‚ â”‚   3   â”‚\n   â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## 5ï¸âƒ£ **Load Balancing Algorithms**\n\n```\n1. Round Robin (Simple)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Request 1 â†’ Server A                â”‚\nâ”‚ Request 2 â†’ Server B                â”‚\nâ”‚ Request 3 â†’ Server C                â”‚\nâ”‚ Request 4 â†’ Server A (repeat)       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Simple, fair distribution\nCons: Ignores server load\n\n2. Least Connections\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Server A: 5 connections             â”‚\nâ”‚ Server B: 10 connections            â”‚\nâ”‚ Server C: 3 connections â† Pick this!â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Balances actual load\nCons: Overhead tracking connections\n\n3. IP Hash (Sticky Sessions)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ hash(client_ip) % num_servers       â”‚\nâ”‚ User 192.168.1.1 â†’ Always Server B  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Session persistence\nCons: Uneven distribution possible\n\n4. Weighted Round Robin\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Server A (weight=3): Gets 3 requestsâ”‚\nâ”‚ Server B (weight=2): Gets 2 requestsâ”‚\nâ”‚ Server C (weight=1): Gets 1 request â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Handle heterogeneous servers\nCons: Need to know server capacities\n\n5. Least Response Time\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Server A: 100ms response time       â”‚\nâ”‚ Server B: 50ms response time â† Pick!â”‚\nâ”‚ Server C: 200ms response time       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Optimal user experience\nCons: Complex, requires health checks\n\nTechnologies:\nâ€¢ Hardware: F5, Citrix NetScaler\nâ€¢ Software: NGINX, HAProxy, AWS ELB\nâ€¢ DNS: Route53, Cloudflare\n```\n\n---\n\n## 6ï¸âƒ£ **Caching Strategies**\n\n```\nCache Hit Ratio = Cache Hits / Total Requests\nTarget: >80% hit ratio\n\n1. Cache-Aside (Lazy Loading)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Application checks cache first:     â”‚\nâ”‚                                     â”‚\nâ”‚ 1. Check cache (Redis)              â”‚\nâ”‚ 2. If HIT â†’ Return cached data      â”‚\nâ”‚ 3. If MISS:                         â”‚\nâ”‚    a. Query database                â”‚\nâ”‚    b. Write to cache                â”‚\nâ”‚    c. Return data                   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Only cache requested data\nCons: Cache miss penalty (2 round trips)\nUse: General purpose (most common)\n\n2. Read-Through\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Cache sits between app and DB:      â”‚\nâ”‚                                     â”‚\nâ”‚ App â†’ Cache (if miss, cache loads   â”‚\nâ”‚              from DB automatically) â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Simpler application code\nCons: Cache handles DB queries\nUse: When cache layer is sophisticated\n\n3. Write-Through\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Write to cache AND database:        â”‚\nâ”‚                                     â”‚\nâ”‚ 1. Write to cache                   â”‚\nâ”‚ 2. Cache writes to DB (sync)        â”‚\nâ”‚ 3. Confirm to application           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Cache always consistent with DB\nCons: Write latency (wait for both)\nUse: When consistency critical\n\n4. Write-Behind (Write-Back)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Write to cache, DB async:           â”‚\nâ”‚                                     â”‚\nâ”‚ 1. Write to cache                   â”‚\nâ”‚ 2. Return immediately (fast!)       â”‚\nâ”‚ 3. Async batch write to DB later   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Fastest writes\nCons: Risk of data loss on cache crash\nUse: High write throughput needed\n\n5. Refresh-Ahead\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Proactively refresh hot data:       â”‚\nâ”‚                                     â”‚\nâ”‚ Before expiry â†’ Reload from DB      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Never serve stale data\nCons: Wasted refreshes for cold data\nUse: Predictable access patterns\n\nCache Eviction Policies:\nâ€¢ LRU (Least Recently Used) - Most common\nâ€¢ LFU (Least Frequently Used) - For hot data\nâ€¢ FIFO (First In First Out) - Simple\nâ€¢ TTL (Time To Live) - Expire after N seconds\n\nTechnologies:\nâ€¢ In-Memory: Redis, Memcached\nâ€¢ Application: Caffeine, Guava Cache\nâ€¢ CDN: CloudFront, Cloudflare, Akamai\nâ€¢ Browser: HTTP cache headers\n```\n\n---\n\n## 7ï¸âƒ£ **Database Sharding** (Horizontal Partitioning)\n\n```\nProblem: Database too big for one server\nSolution: Split data across multiple servers\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ SHARDING STRATEGIES                              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n1. Range-Based Sharding\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ User ID 1-1000     â†’ Shard 1       â”‚\nâ”‚ User ID 1001-2000  â†’ Shard 2       â”‚\nâ”‚ User ID 2001-3000  â†’ Shard 3       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Simple, range queries easy\nCons: Uneven distribution (hotspots)\nExample: Alphabetical (A-M â†’ Shard1, N-Z â†’ Shard2)\n\n2. Hash-Based Sharding\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ hash(user_id) % num_shards         â”‚\nâ”‚ User 123 â†’ hash(123) % 3 = Shard 2 â”‚\nâ”‚ User 456 â†’ hash(456) % 3 = Shard 0 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Even distribution\nCons: Range queries hard, resharding painful\nExample: Instagram uses this\n\n3. Geographic Sharding\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ US users      â†’ US Shard           â”‚\nâ”‚ EU users      â†’ EU Shard           â”‚\nâ”‚ Asia users    â†’ Asia Shard         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Low latency, data locality\nCons: Uneven load, cross-region queries hard\nExample: Netflix, Amazon\n\n4. Directory-Based Sharding\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Lookup table: user_id â†’ shard_id  â”‚\nâ”‚ User 123 â†’ Shard 2                 â”‚\nâ”‚ User 456 â†’ Shard 1                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Flexible, easy to reshard\nCons: Extra lookup (latency), SPOF\nExample: Complex multi-tenant apps\n\nChallenges:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 1. Joins across shards (avoid if possible)     â”‚\nâ”‚ 2. Auto-increment IDs (use UUIDs instead)      â”‚\nâ”‚ 3. Hotspots (celebrity users)                  â”‚\nâ”‚ 4. Resharding (adding/removing shards)         â”‚\nâ”‚ 5. Transactions across shards (2PC, Saga)      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nTechnologies:\nâ€¢ Built-in: MongoDB, Cassandra, Vitess\nâ€¢ Proxy: ProxySQL, Citus (Postgres)\nâ€¢ Application: Custom sharding logic\n```\n\n---\n\n## 8ï¸âƒ£ **Replication Strategies**\n\n```\n1. Master-Slave (Primary-Replica)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         Master (Writes)                â”‚\nâ””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n     â”‚         â”‚         â”‚\n  â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”\n  â”‚Slave â”‚  â”‚Slave â”‚  â”‚Slave â”‚\n  â”‚  1   â”‚  â”‚  2   â”‚  â”‚  3   â”‚\n  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜\n   (Reads)   (Reads)   (Reads)\n\nWorkflow:\n1. All writes â†’ Master\n2. Master replicates â†’ Slaves (async)\n3. Reads from slaves (scale reads)\n\nPros:\nâœ… Simple to implement\nâœ… Read scaling (add more slaves)\nâœ… Backup (slaves are copies)\n\nCons:\nâŒ Write bottleneck (single master)\nâŒ Replication lag (eventual consistency)\nâŒ Failover complexity (promote slave)\n\nUse Cases: MySQL, PostgreSQL, Redis\n\n2. Multi-Master (Active-Active)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â†â†’  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Master 1 â”‚  â†â†’  â”‚ Master 2 â”‚\nâ”‚(Read/Writâ”‚  â†â†’  â”‚(Read/Writâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n     â†•                 â†•\n  Bidirectional replication\n\nPros:\nâœ… Write scaling (multiple masters)\nâœ… High availability (no SPOF)\nâœ… Geographic distribution\n\nCons:\nâŒ Conflict resolution complex\nâŒ Consistency challenges\nâŒ Network partition issues\n\nUse Cases: Cassandra, DynamoDB\n\n3. Synchronous Replication\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Write â†’ Master â†’ Wait for all      â”‚\nâ”‚         slaves to confirm          â”‚\nâ”‚ Only then â†’ Confirm to client      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Strong consistency\nCons: Slow (wait for slowest replica)\nUse: Critical data (financial)\n\n4. Asynchronous Replication\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Write â†’ Master â†’ Confirm           â”‚\nâ”‚         Replicate to slaves later  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Fast writes\nCons: Potential data loss\nUse: Most web applications\n\nReplication Lag:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Time between master write and      â”‚\nâ”‚ replica having the data            â”‚\nâ”‚                                    â”‚\nâ”‚ Typical: 10ms - 1 second           â”‚\nâ”‚ Problem: Read your own writes      â”‚\nâ”‚ Solution: Read from master or use  â”‚\nâ”‚           consistent hashing       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## 9ï¸âƒ£ **Message Queues & Event Streaming**\n\n```\nWhy Message Queues?\nâ€¢ Decouple services (microservices)\nâ€¢ Handle traffic spikes (buffer)\nâ€¢ Async processing (don't wait)\nâ€¢ Guaranteed delivery\nâ€¢ Retry failed tasks\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ QUEUE vs TOPIC                                   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nQueue (Point-to-Point):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚Producer â”‚ â†’  â”‚ Queue â”‚ â†’  â”‚Consumer 1â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                   â†“\n              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n              â”‚Consumer 2â”‚ (one gets message)\n              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nEach message consumed by ONE consumer\nUse: Task distribution (job queue)\n\nTopic (Pub/Sub):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚Publisherâ”‚ â†’  â”‚ Topic â”‚ â†’  â”‚Subscriberâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    1     â”‚\n                   â†“         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n              â”‚Subscriberâ”‚ (all get message)\n              â”‚    2     â”‚\n              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nEach message consumed by ALL subscribers\nUse: Event broadcasting (notifications)\n\nPopular Technologies:\n\n1. RabbitMQ (Queue)\n   â€¢ AMQP protocol\n   â€¢ Traditional message broker\n   â€¢ Acknowledgments, retries\n   â€¢ Use: Task queues, RPC\n\n2. Apache Kafka (Event Streaming)\n   â€¢ High throughput (millions/sec)\n   â€¢ Log-based storage\n   â€¢ Replay capability\n   â€¢ Use: Event sourcing, logs, analytics\n   \n   Architecture:\n   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n   â”‚ Topic: \"user-events\"              â”‚\n   â”‚ Partition 0: [msg1, msg2, msg3]   â”‚\n   â”‚ Partition 1: [msg4, msg5, msg6]   â”‚\n   â”‚ Partition 2: [msg7, msg8, msg9]   â”‚\n   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n   â€¢ Partitions for parallel processing\n   â€¢ Consumer groups for scaling\n\n3. AWS SQS (Managed Queue)\n   â€¢ Fully managed\n   â€¢ At-least-once delivery\n   â€¢ Dead letter queue\n   â€¢ Use: AWS ecosystem\n\n4. Redis Pub/Sub\n   â€¢ In-memory (fast!)\n   â€¢ No persistence (fire and forget)\n   â€¢ Use: Real-time notifications\n\nMessage Delivery Guarantees:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ At-most-once: May lose messages    â”‚\nâ”‚ At-least-once: May duplicate       â”‚\nâ”‚ Exactly-once: Perfect (expensive)  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nKafka Example:\nProducer â†’ Kafka â†’ Consumer Group\n           Topic     â”œâ”€ Consumer 1\n         Partition 0 â”œâ”€ Consumer 2\n         Partition 1 â””â”€ Consumer 3\n         Partition 2\n\nEach partition consumed by ONE consumer\nScale by adding partitions + consumers\n```\n\n---\n\n## ğŸ”Ÿ **API Design Patterns**\n\n```\n1. REST (Representational State Transfer)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ HTTP Methods + Resources               â”‚\nâ”‚                                        â”‚\nâ”‚ GET    /users         (List)           â”‚\nâ”‚ GET    /users/123     (Read)           â”‚\nâ”‚ POST   /users         (Create)         â”‚\nâ”‚ PUT    /users/123     (Update full)    â”‚\nâ”‚ PATCH  /users/123     (Update partial) â”‚\nâ”‚ DELETE /users/123     (Delete)         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Simple, cacheable, stateless\nCons: Over-fetching, multiple requests\nUse: Public APIs, CRUD operations\n\n2. GraphQL (Query Language)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Client specifies exact data needed:    â”‚\nâ”‚                                        â”‚\nâ”‚ query {                                â”‚\nâ”‚   user(id: 123) {                      â”‚\nâ”‚     name                               â”‚\nâ”‚     email                              â”‚\nâ”‚     posts {                            â”‚\nâ”‚       title                            â”‚\nâ”‚     }                                  â”‚\nâ”‚   }                                    â”‚\nâ”‚ }                                      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: No over-fetching, single request\nCons: Complex caching, learning curve\nUse: Mobile apps, complex data needs\nTech: Facebook, GitHub, Shopify\n\n3. gRPC (Remote Procedure Call)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Binary protocol (Protocol Buffers)     â”‚\nâ”‚                                        â”‚\nâ”‚ service UserService {                  â”‚\nâ”‚   rpc GetUser(UserId) returns (User);  â”‚\nâ”‚   rpc ListUsers(Empty) returns         â”‚\nâ”‚       (UserList);                      â”‚\nâ”‚ }                                      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Fast (binary), streaming, typed\nCons: Not human-readable, browser support\nUse: Microservices internal communication\nTech: Google, Netflix, Uber\n\n4. WebSocket (Real-time)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Persistent bidirectional connection    â”‚\nâ”‚                                        â”‚\nâ”‚ Client â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Server         â”‚\nâ”‚  (Send/Receive messages in real-time) â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPros: Real-time, low latency\nCons: Scaling (persistent connections)\nUse: Chat, gaming, live updates\nTech: Socket.io, WebSocket API\n\nComparison:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚          â”‚ REST     â”‚ GraphQL  â”‚ gRPC     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Protocol â”‚ HTTP     â”‚ HTTP     â”‚ HTTP/2   â”‚\nâ”‚ Format   â”‚ JSON     â”‚ JSON     â”‚ Protobuf â”‚\nâ”‚ Speed    â”‚ Medium   â”‚ Medium   â”‚ Fast     â”‚\nâ”‚ Caching  â”‚ Easy     â”‚ Hard     â”‚ Custom   â”‚\nâ”‚ Use Case â”‚ Public   â”‚ Complex  â”‚ Internal â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## ğŸ“Š **Quick Reference Table**\n\n| Concept | Choose When | Example |\n|---------|-------------|---------|\n| **CP (Consistency)** | Banking, inventory | MongoDB, HBase |\n| **AP (Availability)** | Social media, DNS | Cassandra, DynamoDB |\n| **ACID** | Transactions critical | PostgreSQL, MySQL |\n| **BASE** | Scale > consistency | Cassandra, Riak |\n| **Vertical Scale** | Simple, small scale | Single powerful server |\n| **Horizontal Scale** | Web scale | Netflix, Facebook |\n| **Master-Slave** | Read-heavy workload | MySQL replication |\n| **Multi-Master** | Write-heavy, geo-distributed | Cassandra |\n| **Cache-Aside** | General purpose | Redis + App |\n| **Write-Through** | Strong consistency | Write to cache+DB |\n| **Hash Sharding** | Even distribution | Instagram |\n| **Range Sharding** | Time-series data | Logs by date |\n| **REST** | Public APIs | GitHub API |\n| **GraphQL** | Mobile apps | Facebook |\n| **gRPC** | Microservices | Google internal |\n| **Kafka** | Event streaming | LinkedIn |\n| **RabbitMQ** | Task queues | Background jobs |\n\n---\n\n## ğŸ¯ **Interview Framework**\n\n**When asked to design a system, always clarify:**\n\n1. **Consistency Requirements?**\n   - Strong consistency â†’ SQL, CP system\n   - Eventual consistency â†’ NoSQL, AP system\n\n2. **Read/Write Ratio?**\n   - Read-heavy â†’ Caching, read replicas\n   - Write-heavy â†’ Sharding, queue buffering\n\n3. **Latency Requirements?**\n   - <100ms â†’ CDN, caching, geo-distribution\n   - <1s â†’ Standard architecture\n\n4. **Scale?**\n   - <10K users â†’ Vertical scaling, simple\n   - >1M users â†’ Horizontal scaling, distributed\n\n5. **Data Volume?**\n   - <100GB â†’ Single database\n   - >1TB â†’ Sharding, data warehousing\n\n**Always mention trade-offs!**\n- \"I'm choosing Cassandra (AP) over MongoDB (CP) because...\"\n- \"Using cache-aside pattern because...\"\n- \"Sharding by user_id to distribute load...\"\n\n---\n\n## ğŸš€ **Next Steps**\n\nNow that you understand the fundamentals:\n1. Study the **FAANG company examples** (Instagram, Uber, Netflix)\n2. Practice **capacity estimation** (calculate storage, bandwidth)\n3. Draw **architecture diagrams** (boxes and arrows)\n4. Discuss **trade-offs** (why this choice over that)\n\n**Remember: System design is about trade-offs, not perfect solutions!**\n\n## ğŸ¢ FAANG HLD Interview Questions (Most Asked!)\n\n### **1. Design Instagram Feed (Meta)**\n```\nğŸ“Š Requirements:\nâ€¢ 1 billion active users\nâ€¢ 95 million photos/videos per day\nâ€¢ Average user follows 200 people\nâ€¢ Feed loads in < 500ms\nâ€¢ Real-time updates (likes, comments)\n\nğŸ¯ Capacity Estimation:\nâ€¢ Daily Active Users (DAU): 500M\nâ€¢ Posts per day: 95M\nâ€¢ Average post size: 2MB (image) + 500 bytes (metadata)\nâ€¢ Storage per day: 95M Ã— 2MB = 190TB/day\nâ€¢ Yearly storage: 190TB Ã— 365 = 69.35 PB/year\n\nğŸ—ï¸ High-Level Architecture:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    CLIENT LAYER                           â”‚\nâ”‚  Mobile App (iOS/Android)  |  Web Browser                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n             â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                  CDN (CloudFront)                         â”‚\nâ”‚  â€¢ Static content (images, videos)                        â”‚\nâ”‚  â€¢ Edge locations worldwide                               â”‚\nâ”‚  â€¢ 90% of media served from CDN                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n             â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           LOAD BALANCER (AWS ALB/NGINX)                   â”‚\nâ”‚  â€¢ Health checks  â€¢ SSL termination                       â”‚\nâ”‚  â€¢ Geographic routing                                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n             â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                  API GATEWAY                              â”‚\nâ”‚  â€¢ Authentication (JWT)                                   â”‚\nâ”‚  â€¢ Rate limiting (10,000 req/min per user)               â”‚\nâ”‚  â€¢ Request validation                                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n             â”‚\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚        â”‚        â”‚          â”‚          â”‚         â”‚\nâ”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”\nâ”‚Feed    â”‚ â”‚Post  â”‚ â”‚User   â”‚ â”‚Graph   â”‚ â”‚Media   â”‚\nâ”‚Service â”‚ â”‚Svc   â”‚ â”‚Serviceâ”‚ â”‚Service â”‚ â”‚Service â”‚\nâ”‚        â”‚ â”‚      â”‚ â”‚       â”‚ â”‚(Followsâ”‚ â”‚(Upload)â”‚\nâ””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”¬â”€â”€â”€â”€â”€â”˜ â””â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n    â”‚       â”‚        â”‚          â”‚          â”‚\n    â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n            â”‚\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚  Message Queue (Kafka)     â”‚\n    â”‚  â€¢ Feed updates            â”‚\n    â”‚  â€¢ Like/Comment events     â”‚\n    â”‚  â€¢ Analytics events        â”‚\n    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n            â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           â”‚        â”‚          â”‚         â”‚        â”‚\nâ”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”\nâ”‚Feed    â”‚ â”‚Redis â”‚ â”‚Postgreâ”‚ â”‚S3     â”‚ â”‚Cassandâ”‚\nâ”‚Ranking â”‚ â”‚Cache â”‚ â”‚SQL    â”‚ â”‚(Media)â”‚ â”‚ra     â”‚\nâ”‚(ML)    â”‚ â”‚      â”‚ â”‚(Users)â”‚ â”‚       â”‚ â”‚(Posts)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ”„ Feed Generation Strategy (CRITICAL!):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ HYBRID APPROACH (Facebook's actual method)       â”‚\nâ”‚                                                   â”‚\nâ”‚ Regular Users (<10K followers):                  â”‚\nâ”‚   Strategy: FAN-OUT ON WRITE                     â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\nâ”‚   â”‚ 1. User posts photo                 â”‚       â”‚\nâ”‚   â”‚ 2. Fan-out service runs             â”‚       â”‚\nâ”‚   â”‚ 3. Write to all followers' cache    â”‚       â”‚\nâ”‚   â”‚ 4. Followers see post immediately   â”‚       â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\nâ”‚   Storage: Redis sorted set per user            â”‚\nâ”‚   Key: user:123:feed                            â”‚\nâ”‚   Value: [(post_id, timestamp), ...]           â”‚\nâ”‚                                                  â”‚\nâ”‚ Celebrities (>10K followers):                   â”‚\nâ”‚   Strategy: FAN-OUT ON READ                     â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\nâ”‚   â”‚ 1. Celeb posts (stored in DB)       â”‚      â”‚\nâ”‚   â”‚ 2. NOT written to follower feeds    â”‚      â”‚\nâ”‚   â”‚ 3. When user opens app:             â”‚      â”‚\nâ”‚   â”‚    - Fetch pre-generated feed       â”‚      â”‚\nâ”‚   â”‚    - Merge with celebrity posts     â”‚      â”‚\nâ”‚   â”‚    - Rank and return                â”‚      â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\nâ”‚                                                  â”‚\nâ”‚ Why Hybrid?                                     â”‚\nâ”‚ â€¢ Writing to 200M followers takes hours!        â”‚\nâ”‚ â€¢ Reading from 50 celebrities takes 50ms        â”‚\nâ”‚ â€¢ Best of both worlds                           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ“Š Database Schema:\nUsers Table (PostgreSQL - Strong consistency):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ user_id  â”‚  name   â”‚   email    â”‚ created_at â”‚\nâ”‚ (PK)     â”‚ VARCHAR â”‚  VARCHAR   â”‚ TIMESTAMP  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nSharding: By user_id (range or hash)\n\nPosts Table (Cassandra - High write throughput):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ post_id  â”‚ user_id â”‚ content â”‚  image_url â”‚created â”‚\nâ”‚ (PK)     â”‚ (Index) â”‚ TEXT    â”‚  VARCHAR   â”‚  TS    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPartition Key: user_id (for user timeline)\nClustering Key: created_at (sort by time)\n\nFollows Table (Graph DB - Neo4j):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ user_id  â”‚ follows_id  â”‚ created_at â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nQuery: MATCH (u:User {id: 123})-[:FOLLOWS]->(f)\n\nFeed Cache (Redis Sorted Set):\nKey: feed:user:123\nScore: timestamp (for sorting)\nMembers: post_ids\nTTL: 24 hours\n\nğŸ¯ API Design:\nGET /api/v1/feed\n  â†’ Returns top 20 posts\n  â†’ Pagination: cursor-based (last_post_id)\n  \nPOST /api/v1/posts\n  â†’ Upload image to S3\n  â†’ Create post record\n  â†’ Trigger fan-out job\n\nPOST /api/v1/posts/:id/like\n  â†’ Increment like counter (Redis)\n  â†’ Async write to DB (eventual consistency)\n\nğŸš€ Optimization Techniques:\n1. CDN for Media: 90% cache hit rate\n2. Redis for Feed: Pre-computed, <100ms load time\n3. Cassandra for Posts: Billion+ rows, linear scaling\n4. Kafka for Events: Async processing, decouple services\n5. ML Ranking: Personalized feed (engagement score)\n\nğŸ” Security:\nâ€¢ JWT tokens (stateless auth)\nâ€¢ Rate limiting (Redis token bucket)\nâ€¢ Image virus scanning (ClamAV)\nâ€¢ DDoS protection (Cloudflare)\n\nğŸ“ˆ Monitoring:\nâ€¢ Latency: P50, P95, P99 (target <500ms)\nâ€¢ Error rate: <0.1%\nâ€¢ Feed generation time: <200ms\nâ€¢ CDN cache hit rate: >90%\n```\n\n### **2. Design YouTube/Netflix (Video Streaming)**\n```\nğŸ“Š Requirements:\nâ€¢ Upload videos (100M videos/day)\nâ€¢ Stream videos (5 billion views/day)\nâ€¢ Multiple qualities (360p, 720p, 1080p, 4K)\nâ€¢ Recommendation engine\nâ€¢ Low latency streaming (<3 seconds to start)\n\nğŸ¯ Capacity Estimation:\nâ€¢ Video uploads: 500 hours/minute (YouTube actual)\nâ€¢ Average video: 10 minutes, 500MB (1080p)\nâ€¢ Storage: 500 videos Ã— 500MB = 250GB/minute\nâ€¢ Daily storage: 250GB Ã— 1440 = 360TB/day\nâ€¢ Transcoding: 4 formats Ã— 360TB = 1.44PB/day\n\nğŸ—ï¸ Architecture:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚            VIDEO UPLOAD PIPELINE               â”‚\nâ””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n     â”‚\n     â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 1. Upload Service                               â”‚\nâ”‚    â€¢ Chunked upload (100MB chunks)              â”‚\nâ”‚    â€¢ Resume capability (S3 multipart)           â”‚\nâ””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n      â”‚\n      â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 2. Transcoding Service (AWS Elastic Transcoder) â”‚\nâ”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\nâ”‚    â”‚ Original Video (4K, 2GB)         â”‚        â”‚\nâ”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\nâ”‚           â”‚                                     â”‚\nâ”‚    â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\nâ”‚    â–¼      â–¼     â–¼          â–¼         â–¼        â”‚\nâ”‚ 360p   480p   720p      1080p      4K         â”‚\nâ”‚ 50MB   100MB  200MB     500MB     2GB         â”‚\nâ”‚                                                 â”‚\nâ”‚ Parallel Processing (10 servers):              â”‚\nâ”‚ Time: 20 minutes â†’ 2 minutes                   â”‚\nâ””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n      â”‚\n      â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 3. Thumbnail Generation                         â”‚\nâ”‚    â€¢ Extract 10 frames                          â”‚\nâ”‚    â€¢ Resize to 320Ã—180                          â”‚\nâ”‚    â€¢ Upload to S3                               â”‚\nâ””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n      â”‚\n      â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 4. CDN Distribution (CloudFront)                â”‚\nâ”‚    â€¢ Replicate to 100+ edge locations          â”‚\nâ”‚    â€¢ 95% of traffic served from CDN             â”‚\nâ”‚    â€¢ <50ms latency globally                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ¬ Adaptive Bitrate Streaming (ABR):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Video split into 10-second chunks               â”‚\nâ”‚                                                  â”‚\nâ”‚ chunk_001.m3u8 (manifest file)                  â”‚\nâ”‚ â”œâ”€â”€ 360p_chunk_001.ts                           â”‚\nâ”‚ â”œâ”€â”€ 720p_chunk_001.ts                           â”‚\nâ”‚ â”œâ”€â”€ 1080p_chunk_001.ts                          â”‚\nâ”‚ â””â”€â”€ 4K_chunk_001.ts                             â”‚\nâ”‚                                                  â”‚\nâ”‚ Client Algorithm:                               â”‚\nâ”‚ 1. Measure bandwidth (5 Mbps)                   â”‚\nâ”‚ 2. Request 720p chunk                           â”‚\nâ”‚ 3. Bandwidth drops (1 Mbps)                     â”‚\nâ”‚ 4. Switch to 360p chunk                         â”‚\nâ”‚ 5. Seamless quality change                      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nProtocol: HLS (Apple) or DASH (open standard)\n\nğŸ“Š Database Design:\nVideos Table (Cassandra):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚video_id  â”‚ user_id â”‚ title  â”‚ s3_urls   â”‚ views   â”‚\nâ”‚ (PK)     â”‚         â”‚        â”‚ (JSON)    â”‚ COUNTER â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nMetadata Cache (Redis):\nKey: video:123:metadata\nValue: {title, thumbnail, views, likes}\nTTL: 1 hour\n\nView Counter (Redis + Cassandra):\nâ€¢ Redis: Increment counter (fast)\nâ€¢ Batch write to Cassandra every 5 minutes\nâ€¢ Acceptable inconsistency for view count\n\nğŸ¤– Recommendation Engine:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Data Sources:                                    â”‚\nâ”‚ â€¢ Watch history                                  â”‚\nâ”‚ â€¢ Search queries                                 â”‚\nâ”‚ â€¢ Like/dislike                                   â”‚\nâ”‚ â€¢ Video metadata (title, tags)                   â”‚\nâ”‚                                                   â”‚\nâ”‚ ML Model (TensorFlow):                           â”‚\nâ”‚ â€¢ Collaborative filtering                        â”‚\nâ”‚ â€¢ Content-based filtering                        â”‚\nâ”‚ â€¢ Deep neural networks                           â”‚\nâ”‚                                                   â”‚\nâ”‚ Training:                                        â”‚\nâ”‚ â€¢ Offline: Daily batch (Apache Spark)            â”‚\nâ”‚ â€¢ Online: Real-time updates (Kafka â†’ Flink)      â”‚\nâ”‚                                                   â”‚\nâ”‚ Serving:                                         â”‚\nâ”‚ â€¢ Pre-compute top 100 videos per user            â”‚\nâ”‚ â€¢ Store in Redis                                 â”‚\nâ”‚ â€¢ Fetch in <50ms                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸš€ Netflix's Actual Tech Stack:\nâ€¢ CDN: Open Connect (custom, 95% traffic)\nâ€¢ Storage: S3 (origin), Open Connect (edge)\nâ€¢ Database: Cassandra (metadata), EVCache (Redis fork)\nâ€¢ Encoding: FFmpeg, x264/x265 codecs\nâ€¢ API: Zuul (gateway), Eureka (service discovery)\nâ€¢ Monitoring: Atlas (metrics), Mantis (stream processing)\n\nğŸ“ˆ Key Metrics:\nâ€¢ Video start time: <3 seconds\nâ€¢ Buffering ratio: <0.5%\nâ€¢ CDN cache hit: >95%\nâ€¢ Transcoding time: <30 minutes\n```\n\n### **3. Design Uber (Ride-Sharing Platform)**\n```\nğŸ“Š Requirements:\nâ€¢ Match riders with drivers (real-time)\nâ€¢ 15 million rides/day\nâ€¢ ETA calculation\nâ€¢ Surge pricing\nâ€¢ Real-time location tracking\n\nğŸ¯ Capacity Estimation:\nâ€¢ Active riders: 100M\nâ€¢ Active drivers: 5M\nâ€¢ Daily rides: 15M\nâ€¢ Peak rides: 1M/hour = 278 rides/sec\nâ€¢ Location updates: 5M drivers Ã— 4 updates/min = 333K updates/sec\n\nğŸ—ï¸ Architecture:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         RIDER APP  |  DRIVER APP                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚            â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           WebSocket Server (Persistent)          â”‚\nâ”‚  â€¢ Maintains 5M+ connections                     â”‚\nâ”‚  â€¢ Location updates every 15 seconds             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚              CORE SERVICES                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                   â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\nâ”‚  â”‚ Matching â”‚  â”‚  Pricing â”‚  â”‚   Maps   â”‚      â”‚\nâ”‚  â”‚  Engine  â”‚  â”‚  Service â”‚  â”‚  Routing â”‚      â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\nâ”‚                                                   â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\nâ”‚  â”‚ Payment  â”‚  â”‚   Trip   â”‚  â”‚   Notif  â”‚      â”‚\nâ”‚  â”‚ Gateway  â”‚  â”‚  Mgmt    â”‚  â”‚  Service â”‚      â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ—ºï¸ Geo-Spatial Indexing (CRITICAL COMPONENT):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Problem: Find drivers within 2km radius         â”‚\nâ”‚                                                  â”‚\nâ”‚ Naive Approach (BAD):                           â”‚\nâ”‚ â€¢ Loop through all 5M drivers                   â”‚\nâ”‚ â€¢ Calculate distance (Haversine formula)        â”‚\nâ”‚ â€¢ Time: O(n) = 5M iterations = SLOW!           â”‚\nâ”‚                                                  â”‚\nâ”‚ Optimized: QuadTree + Redis Geo                 â”‚\nâ”‚                                                  â”‚\nâ”‚ QuadTree (Divide world into cells):             â”‚\nâ”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚\nâ”‚ â”‚          World Map            â”‚              â”‚\nâ”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚\nâ”‚ â”‚ NW        â”‚        NE         â”‚              â”‚\nâ”‚ â”‚  200      â”‚       1500        â”‚              â”‚\nâ”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚\nâ”‚ â”‚ SW        â”‚        SE         â”‚              â”‚\nâ”‚ â”‚  50       â”‚       3249800     â”‚              â”‚\nâ”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\nâ”‚ Recursively divide cells with >500 drivers      â”‚\nâ”‚                                                  â”‚\nâ”‚ Redis Geo Commands:                             â”‚\nâ”‚ GEOADD drivers 13.361389 38.115556 driver:123  â”‚\nâ”‚ GEORADIUS drivers 13.361 38.115 2 km           â”‚\nâ”‚ â†’ Returns: [driver:123, driver:456, ...]       â”‚\nâ”‚                                                  â”‚\nâ”‚ Time Complexity: O(log n) = Instant!            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ¯ Matching Algorithm (Dispatch Optimization):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Step 1: Find nearby drivers (2km radius)        â”‚\nâ”‚ Step 2: Filter available drivers                â”‚\nâ”‚ Step 3: Calculate ETA for each driver           â”‚\nâ”‚ Step 4: Sort by ETA (closest first)             â”‚\nâ”‚ Step 5: Send request to top 3 drivers           â”‚\nâ”‚ Step 6: First to accept wins                    â”‚\nâ”‚ Step 7: Cancel others                           â”‚\nâ”‚                                                  â”‚\nâ”‚ ETA Calculation:                                â”‚\nâ”‚ â€¢ Distance (Google Maps API)                    â”‚\nâ”‚ â€¢ Current traffic (real-time)                   â”‚\nâ”‚ â€¢ Historical data (ML model)                    â”‚\nâ”‚ â€¢ Driver's current speed                        â”‚\nâ”‚                                                  â”‚\nâ”‚ Formula:                                        â”‚\nâ”‚ Score = Distance Ã— 0.5 + Rating Ã— 0.3           â”‚\nâ”‚         + Acceptance_Rate Ã— 0.2                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ’° Surge Pricing (Dynamic Pricing):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Demand > Supply â†’ Increase price                â”‚\nâ”‚                                                  â”‚\nâ”‚ Algorithm:                                      â”‚\nâ”‚ 1. Count rider requests (last 5 min)            â”‚\nâ”‚ 2. Count available drivers (current)            â”‚\nâ”‚ 3. Calculate ratio: requests / drivers          â”‚\nâ”‚ 4. Apply multiplier:                            â”‚\nâ”‚    â€¢ 1.0x (normal)                              â”‚\nâ”‚    â€¢ 1.5x (high demand)                         â”‚\nâ”‚    â€¢ 2.0x (very high)                           â”‚\nâ”‚    â€¢ 3.0x+ (extreme)                            â”‚\nâ”‚                                                  â”‚\nâ”‚ Updates every 30 seconds                        â”‚\nâ”‚ Broadcast to all users in area (WebSocket)      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ“Š Database Design:\nTrips Table (PostgreSQL):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ trip_id  â”‚rider_id â”‚driver_id â”‚ pickup  â”‚dropoff â”‚\nâ”‚ (PK)     â”‚         â”‚          â”‚ (lat,ln)â”‚(lat,ln)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nDriver Locations (Redis Geo):\nKey: drivers:city:SF\nGeo data: (lat, lon, driver_id)\nExpiry: 5 minutes (if no update)\n\nTrip Events (Cassandra - Time series):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ trip_id  â”‚timestamp â”‚  event  â”‚  location  â”‚\nâ”‚          â”‚          â”‚(pickup) â”‚  (lat,ln)  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPartition Key: trip_id\nClustering Key: timestamp\n\nğŸš€ Uber's Actual Stack:\nâ€¢ Maps: Google Maps API + custom routing\nâ€¢ Geo: H3 (Hexagonal grid), Redis Geo\nâ€¢ Database: PostgreSQL (transactional), Cassandra (trips)\nâ€¢ Real-time: WebSocket, Redis Pub/Sub\nâ€¢ Queue: Kafka (events), RabbitMQ (tasks)\nâ€¢ ML: Michelangelo (prediction platform)\n\nğŸ”¥ Challenges & Solutions:\n1. Driver goes offline suddenly\n   â†’ Timeout (30 sec), reassign to next driver\n   \n2. Two riders request same driver\n   â†’ Optimistic locking, first request wins\n   \n3. Million simultaneous requests\n   â†’ Horizontal scaling, sharding by city\n   \n4. Real-time location accuracy\n   â†’ GPS fusion (GPS + Accelerometer + Gyroscope)\n```\n\n### **4. Design WhatsApp (Messaging System)**\n```\nğŸ“Š Requirements:\nâ€¢ 2 billion users\nâ€¢ 100 billion messages/day\nâ€¢ End-to-end encryption\nâ€¢ Online status\nâ€¢ Read receipts\nâ€¢ Media sharing (images, videos)\n\nğŸ¯ Capacity Estimation:\nâ€¢ Messages: 100B/day = 1.16M/sec\nâ€¢ Average message: 100 bytes (text) or 2MB (media)\nâ€¢ Storage: 1.16M Ã— 100 bytes = 116 MB/sec = 10TB/day\nâ€¢ Connection: 100M concurrent users\n\nğŸ—ï¸ Architecture:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚           MOBILE APPS (iOS/Android)              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚ Persistent WebSocket\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚        Chat Server (Erlang/Elixir - WhatsApp)    â”‚\nâ”‚  â€¢ Handles millions of connections per server    â”‚\nâ”‚  â€¢ Lightweight processes (not threads)           â”‚\nâ”‚  â€¢ Built for telecom (99.99% uptime)            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚              MESSAGE FLOW                         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                   â”‚\nâ”‚  User A â†’ Gateway â†’ Message Queue â†’ User B      â”‚\nâ”‚           (Check if online)                       â”‚\nâ”‚           If offline â†’ Store in DB                â”‚\nâ”‚           If online â†’ Push via WebSocket          â”‚\nâ”‚                                                   â”‚\nâ”‚  Delivery Status:                                â”‚\nâ”‚  âœ“ Sent (received by server)                    â”‚\nâ”‚  âœ“âœ“ Delivered (received by recipient)           â”‚\nâ”‚  âœ“âœ“ Read (blue ticks)                           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ” End-to-End Encryption (Signal Protocol):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 1. Key Exchange (Diffie-Hellman)                â”‚\nâ”‚    User A â†â†’ Server â†â†’ User B                   â”‚\nâ”‚    Exchange public keys, derive shared secret   â”‚\nâ”‚                                                  â”‚\nâ”‚ 2. Message Encryption (AES-256)                 â”‚\nâ”‚    Plain: \"Hello\"                               â”‚\nâ”‚    Encrypted: \"x7#9kL@4...\"                     â”‚\nâ”‚    Only User B can decrypt (has private key)    â”‚\nâ”‚                                                  â”‚\nâ”‚ 3. Server sees encrypted data ONLY              â”‚\nâ”‚    Cannot read messages (true E2EE)             â”‚\nâ”‚                                                  â”‚\nâ”‚ 4. Forward Secrecy                              â”‚\nâ”‚    New keys for each session                    â”‚\nâ”‚    Old messages can't be decrypted if key leak  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ“Š Database Design:\nMessages Table (Cassandra):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ conversation â”‚ message_id â”‚ sender  â”‚  content â”‚\nâ”‚    _id (PK)  â”‚   (Sort)   â”‚         â”‚(encryptedâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPartition: conversation_id (1-to-1 or group)\nClustering: message_id (timestamp-based)\n\nUser Sessions (Redis):\nKey: user:123:session\nValue: {socket_id, last_seen, device_id}\nTTL: 24 hours\n\nOnline Status:\nâ€¢ Last seen: Timestamp in Redis\nâ€¢ Online indicator: WebSocket connection exists\nâ€¢ Privacy: User can hide last seen\n\nGroup Chat (100K members):\nâ€¢ Fan-out on write (send to all members)\nâ€¢ Optimization: Batch sending\nâ€¢ Message ID deduplication\n\nğŸ“± Media Handling:\n1. Sender uploads to S3/CDN\n2. Server stores URL (not file)\n3. Thumbnail generated (100KB)\n4. Recipient downloads from CDN\n5. Auto-delete after 30 days (privacy)\n\nğŸš€ WhatsApp's Stack:\nâ€¢ Server: Erlang/OTP (built for telecom)\nâ€¢ Database: Cassandra (messages), MySQL (users)\nâ€¢ Cache: Redis (sessions, status)\nâ€¢ Media: S3, CloudFront CDN\nâ€¢ Encryption: Signal Protocol (open source)\nâ€¢ Push: FCM (Firebase Cloud Messaging)\n\nğŸ”¥ Key Optimizations:\nâ€¢ Message compression (reduce bandwidth)\nâ€¢ Lazy loading (load recent messages first)\nâ€¢ Image compression (reduce quality for thumbnails)\nâ€¢ Offline queueing (send when back online)\nâ€¢ Delta updates (sync only new messages)\n\nğŸ’¡ Interview Tips:\nâ€¢ Emphasize E2E encryption (security)\nâ€¢ Discuss WebSocket vs polling\nâ€¢ Explain Erlang choice (concurrency)\nâ€¢ Talk about group chat scalability\n```\n\n### **5. Design Twitter Timeline**\n```\nğŸ“Š Requirements:\nâ€¢ 400M active users\nâ€¢ 500M tweets/day\nâ€¢ Average user follows 200 people\nâ€¢ Timeline loads <500ms\nâ€¢ Real-time updates\n\nğŸ¯ Capacity Estimation:\nâ€¢ Tweets: 500M/day = 5,787 tweets/sec\nâ€¢ Peak: 15,000 tweets/sec\nâ€¢ Storage: 5,787 Ã— 280 chars Ã— 4 bytes = 6.5 MB/sec\nâ€¢ Timeline: 400M users Ã— 200 follows Ã— 800 tweets = 64PB!\n\nğŸ—ï¸ Architecture & Fan-out Strategy:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ WRITE PATH (Tweet creation)                      â”‚\nâ””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n     â”‚\n     â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 1. User tweets                                   â”‚\nâ”‚ 2. Store in database (Cassandra)                â”‚\nâ”‚ 3. Determine fan-out strategy                   â”‚\nâ””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n      â”‚\n      â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ FAN-OUT DECISION TREE                            â”‚\nâ”‚                                                   â”‚\nâ”‚ IF follower_count < 10,000:                      â”‚\nâ”‚   â†’ Fan-out on WRITE                             â”‚\nâ”‚   â†’ Push to all follower timelines (Redis)       â”‚\nâ”‚   â†’ Time: O(n) where n = follower count         â”‚\nâ”‚   â†’ Fast for users with <10K followers           â”‚\nâ”‚                                                   â”‚\nâ”‚ ELSE (Celebrity with 50M followers):             â”‚\nâ”‚   â†’ Fan-out on READ                              â”‚\nâ”‚   â†’ Don't push to followers                      â”‚\nâ”‚   â†’ Fetch when user requests timeline            â”‚\nâ”‚   â†’ Merge with pre-generated feed                â”‚\nâ”‚   â†’ Time: O(1) write, O(k) read (k celebrities)  â”‚\nâ”‚                                                   â”‚\nâ”‚ Example: Elon Musk tweets                        â”‚\nâ”‚ - NOT written to 100M+ follower timelines        â”‚\nâ”‚ - Fetched on-demand when you load Twitter        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ“Š Database Schema:\nTweets Table (Cassandra):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ tweet_id â”‚ user_id â”‚ content â”‚ created_at â”‚ likes  â”‚\nâ”‚ (UUID)   â”‚         â”‚ (280)   â”‚ TIMESTAMP  â”‚COUNTER â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nPartition: user_id (for user timeline)\nClustering: created_at DESC\n\nTimeline Cache (Redis Sorted Set):\nKey: timeline:user:123\nScore: timestamp (sort by time)\nMembers: tweet_ids (top 800 tweets)\nCommands:\n  ZADD timeline:user:123 1234567890 tweet:abc123\n  ZREVRANGE timeline:user:123 0 20 (get latest 20)\n\nFollowers Graph (Redis/Graph DB):\nKey: follows:user:123\nValue: Set of user_ids\n\nğŸ”„ Timeline Generation (READ PATH):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ User opens Twitter:                              â”‚\nâ”‚                                                   â”‚\nâ”‚ 1. Fetch from Redis cache                       â”‚\nâ”‚    GET timeline:user:123                         â”‚\nâ”‚    â†’ Returns 800 pre-computed tweet IDs          â”‚\nâ”‚                                                   â”‚\nâ”‚ 2. Hydrate tweet details (batch query)          â”‚\nâ”‚    MGET tweet:1, tweet:2, tweet:3, ...           â”‚\nâ”‚    â†’ Get content, author, likes, etc.            â”‚\nâ”‚                                                   â”‚\nâ”‚ 3. Fetch celebrity tweets (on-demand)           â”‚\nâ”‚    - User follows: @elonmusk, @nasa, @nyt       â”‚\nâ”‚    - Query their latest tweets                   â”‚\nâ”‚    - Merge with cached timeline                  â”‚\nâ”‚                                                   â”‚\nâ”‚ 4. Rank tweets (ML algorithm)                    â”‚\nâ”‚    Score = Recency Ã— 0.4 +                       â”‚\nâ”‚            Engagement Ã— 0.3 +                    â”‚\nâ”‚            Relevance Ã— 0.3                       â”‚\nâ”‚                                                   â”‚\nâ”‚ 5. Return top 20 tweets                          â”‚\nâ”‚                                                   â”‚\nâ”‚ Total time: <200ms                               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ¯ API Design:\nGET /api/v1/timeline\n  Response:\n  {\n    \"tweets\": [...],\n    \"cursor\": \"abc123\" // for pagination\n  }\n\nPOST /api/v1/tweets\n  Body: {\"content\": \"Hello World\"}\n  â†’ Async fan-out job triggered\n\nğŸš€ Twitter's Actual Stack:\nâ€¢ Cache: Manhattan (in-house key-value store)\nâ€¢ Database: MySQL, Cassandra, Manhattan\nâ€¢ Queue: Kafka (event stream)\nâ€¢ Search: Earlybird (custom Lucene fork)\nâ€¢ Recommendation: Cortex (TensorFlow)\n\nğŸ“ˆ Key Metrics:\nâ€¢ Timeline load: <500ms (P95)\nâ€¢ Fan-out time: <5 seconds\nâ€¢ Cache hit rate: >95%\nâ€¢ Peak TPS: 15,000 tweets/sec\n```\n\n```python\n# SYSTEM DESIGN FUNDAMENTALS - SCALE TO MILLIONS!\n\nprint(\"ğŸ¯ SYSTEM DESIGN FUNDAMENTALS - CAREER TRANSFORMATION!\")\nprint(\"=\" * 70)\n\nimport math\nfrom typing import Dict, List, Tuple\nfrom enum import Enum\n\n# ===============================================================\n# 1. SCALABILITY CONCEPTS - Handle Growing Load\n# ===============================================================\nprint(\"\\nğŸ”¥ 1. SCALABILITY - HANDLE MILLIONS OF USERS\")\nprint(\"The ability to handle increased load gracefully\")\n\nclass ScalingType(Enum):\n    VERTICAL = \"vertical\"    # Scale UP - bigger machine\n    HORIZONTAL = \"horizontal\"  # Scale OUT - more machines\n\nclass LoadCalculator:\n    \"\"\"Calculate system capacity and scaling needs\"\"\"\n    \n    @staticmethod\n    def estimate_servers_needed(requests_per_second: int, server_capacity: int) -> int:\n        \"\"\"Calculate number of servers needed for given RPS\"\"\"\n        return math.ceil(requests_per_second / server_capacity)\n    \n    @staticmethod\n    def estimate_storage_needed(users: int, data_per_user_mb: float) -> Tuple[float, str]:\n        \"\"\"Calculate storage needs in TB\"\"\"\n        total_mb = users * data_per_user_mb\n        total_gb = total_mb / 1024\n        total_tb = total_gb / 1024\n        \n        if total_tb < 1:\n            return total_gb, \"GB\"\n        else:\n            return total_tb, \"TB\"\n    \n    @staticmethod\n    def estimate_bandwidth(requests_per_second: int, avg_response_kb: float) -> float:\n        \"\"\"Calculate bandwidth needed in Mbps\"\"\"\n        kb_per_second = requests_per_second * avg_response_kb\n        mb_per_second = kb_per_second / 1024\n        mbps = mb_per_second * 8  # Convert to bits per second\n        return mbps\n\n# Demonstrate scaling calculations\nprint(\"\\nğŸ“Š SCALING CALCULATIONS:\")\nprint(\"Scenario: Social Media Platform\")\n\n# User load estimation\ndaily_active_users = 10_000_000  # 10M DAU\npeak_concurrent_users = daily_active_users * 0.1  # 10% concurrent peak\nrequests_per_user_per_minute = 2\npeak_rps = int((peak_concurrent_users * requests_per_user_per_minute) / 60)\n\nprint(f\"  Daily Active Users: {daily_active_users:,}\")\nprint(f\"  Peak Concurrent Users: {peak_concurrent_users:,}\")\nprint(f\"  Peak Requests/Second: {peak_rps:,}\")\n\n# Server capacity planning\nserver_capacity_rps = 1000  # Each server handles 1000 RPS\nservers_needed = LoadCalculator.estimate_servers_needed(peak_rps, server_capacity_rps)\nprint(f\"  Servers Needed: {servers_needed}\")\n\n# Storage estimation\ndata_per_user_mb = 50  # 50MB per user (posts, images, metadata)\nstorage, unit = LoadCalculator.estimate_storage_needed(daily_active_users, data_per_user_mb)\nprint(f\"  Storage Required: {storage:.2f} {unit}\")\n\n# Bandwidth calculation\navg_response_kb = 100  # 100KB average response\nbandwidth_mbps = LoadCalculator.estimate_bandwidth(peak_rps, avg_response_kb)\nprint(f\"  Bandwidth Required: {bandwidth_mbps:.2f} Mbps\")\n\n# ===============================================================\n# 2. CAP THEOREM - The Fundamental Trade-off\n# ===============================================================\nprint(\"\\n\\nğŸ”¥ 2. CAP THEOREM - CHOOSE YOUR TRADE-OFFS\")\nprint(\"You can only guarantee 2 out of 3: Consistency, Availability, Partition Tolerance\")\n\nclass CAPChoice(Enum):\n    CP = \"CP\"  # Consistency + Partition Tolerance (sacrifice Availability)\n    AP = \"AP\"  # Availability + Partition Tolerance (sacrifice Consistency)\n    CA = \"CA\"  # Consistency + Availability (sacrifice Partition Tolerance - single node only)\n\nclass SystemExample:\n    def __init__(self, name: str, cap_choice: CAPChoice, use_case: str, trade_off: str):\n        self.name = name\n        self.cap_choice = cap_choice\n        self.use_case = use_case\n        self.trade_off = trade_off\n\n# Real-world CAP theorem examples\ncap_examples = [\n    SystemExample(\n        \"Banking System\", \n        CAPChoice.CP,\n        \"Financial transactions, account balances\",\n        \"System goes down rather than show wrong balance\"\n    ),\n    SystemExample(\n        \"Social Media Feed\", \n        CAPChoice.AP,\n        \"Facebook/Twitter timeline, likes, comments\",\n        \"Show slightly stale data rather than error page\"\n    ),\n    SystemExample(\n        \"Traditional RDBMS\", \n        CAPChoice.CA,\n        \"Single-node PostgreSQL/MySQL\",\n        \"Perfect consistency until network partitions occur\"\n    ),\n    SystemExample(\n        \"DNS System\", \n        CAPChoice.AP,\n        \"Domain name resolution\",\n        \"Always available, eventual consistency is fine\"\n    ),\n    SystemExample(\n        \"MongoDB (default)\", \n        CAPChoice.CP,\n        \"Document database with strong consistency\",\n        \"Becomes read-only if can't reach majority of nodes\"\n    )\n]\n\nprint(\"\\nğŸ“š REAL-WORLD CAP EXAMPLES:\")\nfor example in cap_examples:\n    print(f\"  {example.name} ({example.cap_choice.value}):\")\n    print(f\"    Use Case: {example.use_case}\")\n    print(f\"    Trade-off: {example.trade_off}\")\n    print()\n\n# ===============================================================\n# 3. CONSISTENCY MODELS - Data Consistency Patterns\n# ===============================================================\nprint(\"\\nğŸ”¥ 3. CONSISTENCY MODELS - DATA SYNCHRONIZATION\")\nprint(\"Different levels of data consistency across distributed systems\")\n\nclass ConsistencyLevel(Enum):\n    STRONG = \"strong\"           # All nodes have same data immediately\n    EVENTUAL = \"eventual\"       # All nodes will eventually have same data\n    WEAK = \"weak\"              # No guarantees about when data will be consistent\n    CAUSAL = \"causal\"          # Causally related operations are seen in order\n\nclass ConsistencyExample:\n    def __init__(self, level: ConsistencyLevel, description: str, use_case: str, latency: str):\n        self.level = level\n        self.description = description\n        self.use_case = use_case\n        self.latency = latency\n\nconsistency_examples = [\n    ConsistencyExample(\n        ConsistencyLevel.STRONG,\n        \"All reads receive the most recent write immediately\",\n        \"Banking transactions, inventory management\",\n        \"High latency, lower availability\"\n    ),\n    ConsistencyExample(\n        ConsistencyLevel.EVENTUAL,\n        \"System will become consistent over time\",\n        \"Social media feeds, DNS updates, email delivery\",\n        \"Low latency, high availability\"\n    ),\n    ConsistencyExample(\n        ConsistencyLevel.WEAK,\n        \"No guarantees about consistency timing\",\n        \"Real-time gaming, live streaming metrics\",\n        \"Very low latency\"\n    ),\n    ConsistencyExample(\n        ConsistencyLevel.CAUSAL,\n        \"Related operations are seen in correct order\",\n        \"Chat applications, collaborative editing\",\n        \"Moderate latency\"\n    )\n]\n\nprint(\"\\nğŸ“Š CONSISTENCY MODELS:\")\nfor example in consistency_examples:\n    print(f\"  {example.level.value.upper()} CONSISTENCY:\")\n    print(f\"    Definition: {example.description}\")\n    print(f\"    Use Case: {example.use_case}\")\n    print(f\"    Trade-off: {example.latency}\")\n    print()\n\n# ===============================================================\n# 4. PARTITIONING STRATEGIES - Divide and Conquer Data\n# ===============================================================\nprint(\"\\nğŸ”¥ 4. DATA PARTITIONING - DIVIDE TO SCALE\")\nprint(\"Split large datasets across multiple machines\")\n\nclass PartitionStrategy(Enum):\n    HORIZONTAL = \"horizontal\"   # Sharding - split rows\n    VERTICAL = \"vertical\"       # Split columns/tables\n    FUNCTIONAL = \"functional\"   # Split by feature/service\n\nclass PartitioningCalculator:\n    @staticmethod\n    def hash_partition(user_id: int, num_shards: int) -> int:\n        \"\"\"Simple hash-based partitioning\"\"\"\n        return user_id % num_shards\n    \n    @staticmethod\n    def range_partition(user_id: int, ranges: List[Tuple[int, int]]) -> int:\n        \"\"\"Range-based partitioning\"\"\"\n        for i, (start, end) in enumerate(ranges):\n            if start <= user_id <= end:\n                return i\n        return -1  # Not found\n    \n    @staticmethod\n    def consistent_hash_partition(key: str, num_virtual_nodes: int = 100) -> int:\n        \"\"\"Simplified consistent hashing\"\"\"\n        hash_value = hash(key) % (num_virtual_nodes * 1000)\n        return hash_value % num_virtual_nodes\n\n# Demonstrate partitioning strategies\nprint(\"\\nğŸ“Š PARTITIONING EXAMPLES:\")\n\n# Hash partitioning example\nnum_shards = 4\nsample_user_ids = [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008]\n\nprint(\"  HASH PARTITIONING:\")\nfor user_id in sample_user_ids:\n    shard = PartitioningCalculator.hash_partition(user_id, num_shards)\n    print(f\"    User {user_id} â†’ Shard {shard}\")\n\n# Range partitioning example\nranges = [(1, 2500), (2501, 5000), (5001, 7500), (7501, 10000)]\nprint(\"\\n  RANGE PARTITIONING:\")\ntest_users = [1500, 3000, 6000, 8500]\nfor user_id in test_users:\n    shard = PartitioningCalculator.range_partition(user_id, ranges)\n    print(f\"    User {user_id} â†’ Shard {shard}\")\n\n# ===============================================================\n# 5. REPLICATION STRATEGIES - Data Redundancy for Reliability\n# ===============================================================\nprint(\"\\n\\nğŸ”¥ 5. REPLICATION - RELIABILITY & PERFORMANCE\")\nprint(\"Keep multiple copies of data for fault tolerance and faster reads\")\n\nclass ReplicationType(Enum):\n    MASTER_SLAVE = \"master_slave\"     # One writer, multiple readers\n    MASTER_MASTER = \"master_master\"   # Multiple writers\n    PEER_TO_PEER = \"peer_to_peer\"     # No distinguished master\n\nclass ReplicationExample:\n    def __init__(self, type_: ReplicationType, pros: List[str], cons: List[str], use_case: str):\n        self.type = type_\n        self.pros = pros\n        self.cons = cons\n        self.use_case = use_case\n\nreplication_strategies = [\n    ReplicationExample(\n        ReplicationType.MASTER_SLAVE,\n        [\"Simple to implement\", \"Strong consistency\", \"Clear data flow\"],\n        [\"Single point of failure\", \"Write bottleneck\", \"Read-only slaves\"],\n        \"Traditional databases, read-heavy workloads\"\n    ),\n    ReplicationExample(\n        ReplicationType.MASTER_MASTER,\n        [\"High availability\", \"Write scalability\", \"Load distribution\"],\n        [\"Conflict resolution needed\", \"Complex synchronization\", \"Consistency challenges\"],\n        \"Global applications, high-write workloads\"\n    ),\n    ReplicationExample(\n        ReplicationType.PEER_TO_PEER,\n        [\"Highly available\", \"Decentralized\", \"Fault tolerant\"],\n        [\"Complex consensus\", \"Network overhead\", \"Eventual consistency\"],\n        \"Blockchain, distributed file systems\"\n    )\n]\n\nprint(\"\\nğŸ“Š REPLICATION STRATEGIES:\")\nfor strategy in replication_strategies:\n    print(f\"  {strategy.type.value.upper().replace('_', '-')}:\")\n    print(f\"    Pros: {', '.join(strategy.pros)}\")\n    print(f\"    Cons: {', '.join(strategy.cons)}\")\n    print(f\"    Use Case: {strategy.use_case}\")\n    print()\n\n# ===============================================================\n# SYSTEM DESIGN FUNDAMENTALS SUMMARY\n# ===============================================================\nprint(\"=\" * 70)\nprint(\"ğŸ† SYSTEM DESIGN FUNDAMENTALS MASTERY\")\nprint(\"=\" * 70)\n\nfundamentals = {\n    \"Scalability\": \"Design systems that grow with demand\",\n    \"CAP Theorem\": \"Understand trade-offs in distributed systems\",\n    \"Consistency\": \"Choose appropriate data consistency model\",\n    \"Partitioning\": \"Split data to scale beyond single machine\",\n    \"Replication\": \"Ensure availability and fault tolerance\"\n}\n\nprint(\"\\nğŸ“š CONCEPTS MASTERED:\")\nfor concept, description in fundamentals.items():\n    print(f\"âœ… {concept}: {description}\")\n\nprint(\"\\nğŸ’¼ INTERVIEW IMPACT:\")\nprint(\"ğŸ† Foundation for all system design questions\")\nprint(\"ğŸ† Demonstrates understanding of trade-offs\")\nprint(\"ğŸ† Shows ability to design scalable systems\")\nprint(\"ğŸ† Required for senior+ engineering roles\")\nprint(\"ğŸ† Gateway to system architect positions\")\n\nprint(\"\\nğŸš€ NEXT STEPS:\")\nprint(\"âœ… Master these fundamentals before diving into specific components\")\nprint(\"âœ… Practice applying these concepts to real-world scenarios\")\nprint(\"âœ… Study how major tech companies implement these patterns\")\nprint(\"=\" * 70)\n```\n\n"}