{"id":"load-balancing-ha","title":"üöÄ Load Balancing & High Availability Zero to Hero","content":"# Load Balancing & High Availability: Zero to Hero Guide\n## Complete System Reliability and Scalability Mastery\n\n---\n\n## üìö Table of Contents\n\n1. [Introduction to Load Balancing & HA](#introduction)\n2. [Load Balancer Types & Algorithms](#types)\n3. [High Availability Fundamentals](#ha-fundamentals)\n4. [Session Management Strategies](#sessions)\n5. [Failover & Recovery Strategies](#failover)\n6. [Health Checks & Monitoring](#health-checks)\n7. [Cloud Load Balancing Solutions](#cloud-solutions)\n8. [Database High Availability](#database-ha)\n9. [Caching for High Availability](#caching-ha)\n10. [Disaster Recovery Planning](#disaster-recovery)\n11. [Real-World Implementations](#real-world)\n12. [Best Practices & Patterns](#best-practices)\n\n---\n\n## üéØ Introduction to Load Balancing & High Availability {#introduction}\n\n### What is Load Balancing?\n\n**Load Balancing** distributes incoming network traffic across multiple servers to ensure optimal resource utilization, minimize response times, and avoid server overload.\n\n```\nWithout Load Balancer (Single Point of Failure)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Client  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ   Server    ‚îÇ ‚Üê All traffic here!\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ (Overloaded)‚îÇ\n                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚ùå Problems:\n‚Ä¢ Server overload\n‚Ä¢ Single point of failure  \n‚Ä¢ Poor scalability\n‚Ä¢ Downtime during maintenance\n\nWith Load Balancer (Distributed & Resilient)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Client  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇLoad Balancer ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Server 1    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                       ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Server 2    ‚îÇ\n                       ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                       ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Server 3    ‚îÇ\n                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚úÖ Benefits:\n‚Ä¢ Distributed load\n‚Ä¢ High availability\n‚Ä¢ Horizontal scaling\n‚Ä¢ Zero-downtime deployments\n```\n\n### What is High Availability?\n\n**High Availability (HA)** is the ability of a system to remain operational and accessible for extended periods, typically measured as a percentage of uptime.\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ              Availability Levels                    ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  90.0% (Basic)      = 36.5 days downtime/year      ‚îÇ\n‚îÇ  99.0% (Good)       = 3.65 days downtime/year      ‚îÇ  \n‚îÇ  99.9% (Great)      = 8.76 hours downtime/year     ‚îÇ\n‚îÇ  99.99% (Excellent) = 52.6 minutes downtime/year   ‚îÇ\n‚îÇ  99.999% (Elite)    = 5.26 minutes downtime/year   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Load Balancing + High Availability Architecture\n\n```\n                    Internet\n                        ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n              ‚îÇ   DNS/CDN        ‚îÇ ‚Üê Global load balancing\n              ‚îÇ   (CloudFlare)   ‚îÇ\n              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                        ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n              ‚îÇ  Load Balancer   ‚îÇ ‚Üê Application load balancing\n              ‚îÇ   (NGINX/HAProxy)‚îÇ\n              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚îÇ   ‚îÇ   ‚îÇ\n        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n        ‚îÇ   App       ‚îÇ ‚îÇ ‚îÇ   App       ‚îÇ ‚Üê Redundant app instances\n        ‚îÇ Instance 1  ‚îÇ ‚îÇ ‚îÇ Instance 2  ‚îÇ\n        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                        ‚îÇ\n                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                ‚îÇ   App         ‚îÇ\n                ‚îÇ Instance 3    ‚îÇ\n                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                        ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n              ‚îÇ  Database Cluster ‚îÇ ‚Üê Database high availability\n              ‚îÇ Primary + Replica ‚îÇ\n              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n---\n\n## ‚öñÔ∏è Load Balancer Types & Algorithms {#types}\n\n### Load Balancer Types\n\n**Layer 4 (Transport Layer) Load Balancing**\n- **Operates at**: TCP/UDP level\n- **Decisions based on**: IP addresses and ports\n- **Performance**: Very fast (no content inspection)\n- **Use cases**: High-throughput applications, TCP-based services\n\n**Layer 7 (Application Layer) Load Balancing**\n- **Operates at**: HTTP/HTTPS level\n- **Decisions based on**: Content, headers, URLs, cookies\n- **Performance**: Slower (content inspection required)\n- **Use cases**: Web applications, microservices, API gateways\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ              Layer 4 Load Balancer                  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  Client IP: 192.168.1.100:54321                    ‚îÇ\n‚îÇ  ‚Üì                                                  ‚îÇ\n‚îÇ  Load Balancer decides based on:                   ‚îÇ\n‚îÇ  ‚Ä¢ Source IP                                        ‚îÇ\n‚îÇ  ‚Ä¢ Destination port                                 ‚îÇ\n‚îÇ  ‚Ä¢ Protocol (TCP/UDP)                              ‚îÇ\n‚îÇ  ‚Üì                                                  ‚îÇ\n‚îÇ  Routes to: Server 2:8080                         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ              Layer 7 Load Balancer                  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  HTTP Request:                                      ‚îÇ\n‚îÇ  GET /api/users/123                                 ‚îÇ\n‚îÇ  Host: api.example.com                              ‚îÇ\n‚îÇ  User-Agent: Mozilla...                            ‚îÇ\n‚îÇ  ‚Üì                                                  ‚îÇ\n‚îÇ  Load Balancer decides based on:                   ‚îÇ\n‚îÇ  ‚Ä¢ URL path (/api/users ‚Üí users service)          ‚îÇ\n‚îÇ  ‚Ä¢ Host header                                     ‚îÇ\n‚îÇ  ‚Ä¢ HTTP method                                     ‚îÇ\n‚îÇ  ‚Ä¢ Cookies/Sessions                                ‚îÇ\n‚îÇ  ‚Üì                                                  ‚îÇ\n‚îÇ  Routes to: Users Service on Server 1             ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Load Balancing Algorithms\n\n```python\nimport random\nimport time\nimport hashlib\nfrom typing import List, Dict, Any, Optional\nfrom dataclasses import dataclass\nfrom abc import ABC, abstractmethod\nimport logging\n\n@dataclass\nclass Server:\n    id: str\n    host: str\n    port: int\n    weight: int = 1\n    active_connections: int = 0\n    is_healthy: bool = True\n    last_health_check: float = 0\n    avg_response_time_ms: float = 0\n\nclass LoadBalancingAlgorithm(ABC):\n    @abstractmethod\n    def select_server(self, servers: List[Server], client_info: Dict[str, Any] = None) -> Optional[Server]:\n        pass\n\nclass RoundRobinAlgorithm(LoadBalancingAlgorithm):\n    def __init__(self):\n        self.current_index = 0\n    \n    def select_server(self, servers: List[Server], client_info: Dict[str, Any] = None) -> Optional[Server]:\n        healthy_servers = [s for s in servers if s.is_healthy]\n        \n        if not healthy_servers:\n            return None\n        \n        # Select next server in rotation\n        server = healthy_servers[self.current_index % len(healthy_servers)]\n        self.current_index += 1\n        \n        return server\n\nclass WeightedRoundRobinAlgorithm(LoadBalancingAlgorithm):\n    def __init__(self):\n        self.current_weights = {}\n    \n    def select_server(self, servers: List[Server], client_info: Dict[str, Any] = None) -> Optional[Server]:\n        healthy_servers = [s for s in servers if s.is_healthy]\n        \n        if not healthy_servers:\n            return None\n        \n        # Initialize weights if needed\n        for server in healthy_servers:\n            if server.id not in self.current_weights:\n                self.current_weights[server.id] = 0\n        \n        # Increase all current weights\n        for server in healthy_servers:\n            self.current_weights[server.id] += server.weight\n        \n        # Find server with highest current weight\n        selected_server = max(healthy_servers, key=lambda s: self.current_weights[s.id])\n        \n        # Reduce selected server's current weight by total weight\n        total_weight = sum(s.weight for s in healthy_servers)\n        self.current_weights[selected_server.id] -= total_weight\n        \n        return selected_server\n\nclass LeastConnectionsAlgorithm(LoadBalancingAlgorithm):\n    def select_server(self, servers: List[Server], client_info: Dict[str, Any] = None) -> Optional[Server]:\n        healthy_servers = [s for s in servers if s.is_healthy]\n        \n        if not healthy_servers:\n            return None\n        \n        # Select server with least active connections\n        return min(healthy_servers, key=lambda s: s.active_connections)\n\nclass IPHashAlgorithm(LoadBalancingAlgorithm):\n    def select_server(self, servers: List[Server], client_info: Dict[str, Any] = None) -> Optional[Server]:\n        healthy_servers = [s for s in servers if s.is_healthy]\n        \n        if not healthy_servers:\n            return None\n        \n        # Use client IP for consistent routing\n        client_ip = client_info.get('client_ip', '0.0.0.0')\n        hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)\n        \n        server_index = hash_value % len(healthy_servers)\n        return healthy_servers[server_index]\n\nclass ResponseTimeAlgorithm(LoadBalancingAlgorithm):\n    def select_server(self, servers: List[Server], client_info: Dict[str, Any] = None) -> Optional[Server]:\n        healthy_servers = [s for s in servers if s.is_healthy]\n        \n        if not healthy_servers:\n            return None\n        \n        # Select server with best response time\n        return min(healthy_servers, key=lambda s: s.avg_response_time_ms)\n\n# Advanced Load Balancer Implementation\nclass AdvancedLoadBalancer:\n    def __init__(self, algorithm: LoadBalancingAlgorithm):\n        self.algorithm = algorithm\n        self.servers: List[Server] = []\n        self.health_check_interval = 30  # seconds\n        self.circuit_breakers = {}\n        self.logger = logging.getLogger(__name__)\n        \n        # Metrics\n        self.total_requests = 0\n        self.failed_requests = 0\n        \n        # Start health checking\n        self._start_health_checks()\n    \n    def add_server(self, host: str, port: int, weight: int = 1):\n        \"\"\"Add server to load balancer\"\"\"\n        server = Server(\n            id=f\"{host}:{port}\",\n            host=host,\n            port=port,\n            weight=weight\n        )\n        self.servers.append(server)\n        \n        # Initialize circuit breaker\n        self.circuit_breakers[server.id] = CircuitBreaker(\n            failure_threshold=5,\n            recovery_timeout=60\n        )\n        \n        self.logger.info(f\"Added server: {server.id}\")\n    \n    async def route_request(self, request_data: Dict[str, Any], client_ip: str) -> Optional[str]:\n        \"\"\"Route request to appropriate server\"\"\"\n        \n        client_info = {'client_ip': client_ip}\n        \n        # Select server using algorithm\n        server = self.algorithm.select_server(self.servers, client_info)\n        \n        if not server:\n            self.failed_requests += 1\n            self.logger.error(\"No healthy servers available\")\n            return None\n        \n        # Check circuit breaker\n        circuit_breaker = self.circuit_breakers[server.id]\n        if not circuit_breaker.can_request():\n            self.logger.warning(f\"Circuit breaker open for {server.id}\")\n            # Try another server\n            fallback_servers = [s for s in self.servers if s.id != server.id and s.is_healthy]\n            if fallback_servers:\n                server = self.algorithm.select_server(fallback_servers, client_info)\n            else:\n                return None\n        \n        # Track connection\n        server.active_connections += 1\n        self.total_requests += 1\n        \n        try:\n            # Simulate request processing\n            start_time = time.time()\n            response = await self._forward_request(server, request_data)\n            \n            # Update metrics\n            response_time = (time.time() - start_time) * 1000\n            server.avg_response_time_ms = (server.avg_response_time_ms + response_time) / 2\n            \n            # Mark successful request\n            circuit_breaker.record_success()\n            \n            return response\n            \n        except Exception as e:\n            # Mark failed request\n            circuit_breaker.record_failure()\n            self.failed_requests += 1\n            self.logger.error(f\"Request failed on {server.id}: {e}\")\n            return None\n        \n        finally:\n            server.active_connections = max(0, server.active_connections - 1)\n    \n    async def _forward_request(self, server: Server, request_data: Dict[str, Any]) -> str:\n        \"\"\"Forward request to server\"\"\"\n        import aiohttp\n        \n        url = f\"http://{server.host}:{server.port}/api\"\n        \n        async with aiohttp.ClientSession() as session:\n            async with session.post(url, json=request_data, timeout=aiohttp.ClientTimeout(total=30)) as response:\n                if response.status == 200:\n                    return await response.text()\n                else:\n                    raise Exception(f\"Server returned status {response.status}\")\n    \n    async def _check_server_health(self, server: Server) -> bool:\n        \"\"\"Check if server is healthy\"\"\"\n        try:\n            health_url = f\"http://{server.host}:{server.port}/health\"\n            \n            async with aiohttp.ClientSession() as session:\n                async with session.get(health_url, timeout=aiohttp.ClientTimeout(total=5)) as response:\n                    server.last_health_check = time.time()\n                    \n                    if response.status == 200:\n                        health_data = await response.json()\n                        server.is_healthy = health_data.get('status') == 'healthy'\n                    else:\n                        server.is_healthy = False\n                        \n        except Exception as e:\n            server.is_healthy = False\n            self.logger.warning(f\"Health check failed for {server.id}: {e}\")\n        \n        return server.is_healthy\n    \n    def _start_health_checks(self):\n        \"\"\"Start periodic health checks\"\"\"\n        async def health_check_loop():\n            while True:\n                for server in self.servers:\n                    await self._check_server_health(server)\n                \n                await asyncio.sleep(self.health_check_interval)\n        \n        asyncio.create_task(health_check_loop())\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"Get load balancer status\"\"\"\n        healthy_servers = [s for s in self.servers if s.is_healthy]\n        \n        return {\n            'total_servers': len(self.servers),\n            'healthy_servers': len(healthy_servers),\n            'total_requests': self.total_requests,\n            'failed_requests': self.failed_requests,\n            'success_rate': ((self.total_requests - self.failed_requests) / self.total_requests * 100) if self.total_requests > 0 else 100,\n            'servers': [\n                {\n                    'id': s.id,\n                    'healthy': s.is_healthy,\n                    'active_connections': s.active_connections,\n                    'avg_response_time_ms': s.avg_response_time_ms\n                }\n                for s in self.servers\n            ]\n        }\n\n# Circuit Breaker Pattern for Resilience\nclass CircuitBreakerState:\n    CLOSED = \"CLOSED\"\n    OPEN = \"OPEN\" \n    HALF_OPEN = \"HALF_OPEN\"\n\nclass CircuitBreaker:\n    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.failure_count = 0\n        self.last_failure_time = 0\n        self.state = CircuitBreakerState.CLOSED\n    \n    def can_request(self) -> bool:\n        \"\"\"Check if request is allowed\"\"\"\n        if self.state == CircuitBreakerState.CLOSED:\n            return True\n        elif self.state == CircuitBreakerState.OPEN:\n            # Check if recovery timeout has passed\n            if time.time() - self.last_failure_time > self.recovery_timeout:\n                self.state = CircuitBreakerState.HALF_OPEN\n                return True\n            return False\n        else:  # HALF_OPEN\n            return True\n    \n    def record_success(self):\n        \"\"\"Record successful request\"\"\"\n        if self.state == CircuitBreakerState.HALF_OPEN:\n            self.state = CircuitBreakerState.CLOSED\n        \n        self.failure_count = 0\n    \n    def record_failure(self):\n        \"\"\"Record failed request\"\"\"\n        self.failure_count += 1\n        self.last_failure_time = time.time()\n        \n        if self.failure_count >= self.failure_threshold:\n            self.state = CircuitBreakerState.OPEN\n        elif self.state == CircuitBreakerState.HALF_OPEN:\n            self.state = CircuitBreakerState.OPEN\n```\n\n---\n\n## üìã Session Management Strategies {#sessions}\n\n### Sticky Sessions vs Session Replication\n\n```python\nimport redis\nimport json\nimport hashlib\nimport uuid\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime, timedelta\n\nclass SessionManager:\n    def __init__(self, strategy: str = \"redis\"):\n        self.strategy = strategy\n        \n        if strategy == \"redis\":\n            self.redis_client = redis.Redis(\n                host='localhost', \n                port=6379, \n                decode_responses=True,\n                socket_keepalive=True,\n                socket_keepalive_options={}\n            )\n    \n    # 1. Stateless Sessions (JWT)\n    def create_stateless_session(self, user_data: Dict[str, Any]) -> str:\n        \"\"\"Create JWT token for stateless sessions\"\"\"\n        import jwt\n        \n        payload = {\n            'user_id': user_data['user_id'],\n            'username': user_data['username'],\n            'roles': user_data.get('roles', []),\n            'iat': datetime.utcnow(),\n            'exp': datetime.utcnow() + timedelta(hours=24)\n        }\n        \n        token = jwt.encode(payload, 'secret-key', algorithm='HS256')\n        return token\n    \n    def validate_stateless_session(self, token: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Validate JWT token\"\"\"\n        import jwt\n        \n        try:\n            payload = jwt.decode(token, 'secret-key', algorithms=['HS256'])\n            return payload\n        except jwt.ExpiredSignatureError:\n            return None\n        except jwt.InvalidTokenError:\n            return None\n    \n    # 2. Distributed Sessions (Redis)\n    async def create_distributed_session(self, user_data: Dict[str, Any]) -> str:\n        \"\"\"Create session stored in Redis\"\"\"\n        session_id = str(uuid.uuid4())\n        \n        session_data = {\n            'user_id': user_data['user_id'],\n            'username': user_data['username'],\n            'created_at': datetime.now().isoformat(),\n            'last_accessed': datetime.now().isoformat(),\n            'user_agent': user_data.get('user_agent'),\n            'ip_address': user_data.get('ip_address')\n        }\n        \n        # Store in Redis with TTL\n        self.redis_client.setex(\n            f\"session:{session_id}\",\n            3600 * 24,  # 24 hours\n            json.dumps(session_data)\n        )\n        \n        return session_id\n    \n    async def get_distributed_session(self, session_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get session from Redis\"\"\"\n        session_key = f\"session:{session_id}\"\n        \n        session_data_json = self.redis_client.get(session_key)\n        if not session_data_json:\n            return None\n        \n        session_data = json.loads(session_data_json)\n        \n        # Update last accessed time\n        session_data['last_accessed'] = datetime.now().isoformat()\n        self.redis_client.setex(session_key, 3600 * 24, json.dumps(session_data))\n        \n        return session_data\n    \n    async def invalidate_session(self, session_id: str):\n        \"\"\"Invalidate session\"\"\"\n        self.redis_client.delete(f\"session:{session_id}\")\n    \n    # 3. Sticky Sessions (IP Affinity)\n    class StickySessionManager:\n        def __init__(self, servers: List[Server]):\n            self.servers = servers\n            self.client_server_mapping = {}\n        \n        def get_server_for_client(self, client_ip: str) -> Server:\n            \"\"\"Get consistent server for client IP\"\"\"\n            if client_ip in self.client_server_mapping:\n                server_id = self.client_server_mapping[client_ip]\n                server = next((s for s in self.servers if s.id == server_id), None)\n                \n                if server and server.is_healthy:\n                    return server\n            \n            # Assign new server using consistent hashing\n            hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)\n            healthy_servers = [s for s in self.servers if s.is_healthy]\n            \n            if healthy_servers:\n                server_index = hash_value % len(healthy_servers)\n                selected_server = healthy_servers[server_index]\n                self.client_server_mapping[client_ip] = selected_server.id\n                return selected_server\n            \n            return None\n    \n    # 4. Session Replication\n    class SessionReplicator:\n        def __init__(self, redis_nodes: List[str]):\n            self.redis_clients = [\n                redis.Redis.from_url(node, decode_responses=True) \n                for node in redis_nodes\n            ]\n        \n        async def replicate_session(self, session_id: str, session_data: Dict[str, Any]):\n            \"\"\"Replicate session across multiple Redis instances\"\"\"\n            session_key = f\"session:{session_id}\"\n            session_json = json.dumps(session_data)\n            \n            # Write to all Redis instances\n            for client in self.redis_clients:\n                try:\n                    client.setex(session_key, 3600 * 24, session_json)\n                except Exception as e:\n                    print(f\"Failed to replicate to Redis node: {e}\")\n        \n        async def get_replicated_session(self, session_id: str) -> Optional[Dict[str, Any]]:\n            \"\"\"Get session with fallback to other replicas\"\"\"\n            session_key = f\"session:{session_id}\"\n            \n            # Try each Redis instance until we find the session\n            for client in self.redis_clients:\n                try:\n                    session_data_json = client.get(session_key)\n                    if session_data_json:\n                        return json.loads(session_data_json)\n                except Exception as e:\n                    print(f\"Failed to read from Redis node: {e}\")\n                    continue\n            \n            return None\n```\n\n---\n\n## üõ°Ô∏è Failover & Recovery Strategies {#failover}\n\n### Automatic Failover Implementation\n\n```python\nimport asyncio\nimport time\nimport logging\nfrom typing import List, Dict, Any, Optional, Callable\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport aiohttp\nfrom abc import ABC, abstractmethod\n\nclass FailoverStrategy(Enum):\n    ACTIVE_PASSIVE = \"active_passive\"\n    ACTIVE_ACTIVE = \"active_active\"\n    ROLLING_FAILOVER = \"rolling_failover\"\n\n@dataclass\nclass HealthCheckConfig:\n    endpoint: str = \"/health\"\n    interval_seconds: int = 30\n    timeout_seconds: int = 5\n    failure_threshold: int = 3\n    success_threshold: int = 2\n    expected_status_code: int = 200\n    expected_response_contains: Optional[str] = None\n\nclass FailoverManager:\n    def __init__(self, strategy: FailoverStrategy = FailoverStrategy.ACTIVE_PASSIVE):\n        self.strategy = strategy\n        self.primary_servers: List[Server] = []\n        self.secondary_servers: List[Server] = []\n        self.health_check_config = HealthCheckConfig()\n        self.logger = logging.getLogger(__name__)\n        \n        # Failover state\n        self.is_failed_over = False\n        self.failover_timestamp = None\n        self.current_active_servers = []\n        \n        # Start monitoring\n        self._start_monitoring()\n    \n    def add_primary_server(self, host: str, port: int):\n        \"\"\"Add primary server\"\"\"\n        server = Server(id=f\"primary-{host}:{port}\", host=host, port=port)\n        self.primary_servers.append(server)\n        self._update_active_servers()\n        \n        self.logger.info(f\"Added primary server: {server.id}\")\n    \n    def add_secondary_server(self, host: str, port: int):\n        \"\"\"Add secondary server\"\"\"\n        server = Server(id=f\"secondary-{host}:{port}\", host=host, port=port)\n        self.secondary_servers.append(server)\n        \n        self.logger.info(f\"Added secondary server: {server.id}\")\n    \n    def _update_active_servers(self):\n        \"\"\"Update list of currently active servers based on strategy\"\"\"\n        if self.strategy == FailoverStrategy.ACTIVE_PASSIVE:\n            if not self.is_failed_over:\n                self.current_active_servers = [s for s in self.primary_servers if s.is_healthy]\n            else:\n                self.current_active_servers = [s for s in self.secondary_servers if s.is_healthy]\n        \n        elif self.strategy == FailoverStrategy.ACTIVE_ACTIVE:\n            self.current_active_servers = [\n                s for s in (self.primary_servers + self.secondary_servers) \n                if s.is_healthy\n            ]\n    \n    async def _check_server_health(self, server: Server) -> bool:\n        \"\"\"Comprehensive server health check\"\"\"\n        consecutive_failures = getattr(server, 'consecutive_failures', 0)\n        consecutive_successes = getattr(server, 'consecutive_successes', 0)\n        \n        try:\n            health_url = f\"http://{server.host}:{server.port}{self.health_check_config.endpoint}\"\n            \n            timeout = aiohttp.ClientTimeout(total=self.health_check_config.timeout_seconds)\n            \n            async with aiohttp.ClientSession(timeout=timeout) as session:\n                start_time = time.time()\n                \n                async with session.get(health_url) as response:\n                    response_time = (time.time() - start_time) * 1000\n                    response_text = await response.text()\n                    \n                    # Check status code\n                    status_ok = response.status == self.health_check_config.expected_status_code\n                    \n                    # Check response content if specified\n                    content_ok = True\n                    if self.health_check_config.expected_response_contains:\n                        content_ok = self.health_check_config.expected_response_contains in response_text\n                    \n                    # Check response time\n                    response_ok = response_time < 5000  # 5 second max\n                    \n                    if status_ok and content_ok and response_ok:\n                        consecutive_successes += 1\n                        consecutive_failures = 0\n                        \n                        # Mark healthy if enough consecutive successes\n                        if consecutive_successes >= self.health_check_config.success_threshold:\n                            server.is_healthy = True\n                        \n                        server.avg_response_time_ms = response_time\n                        \n                    else:\n                        consecutive_failures += 1\n                        consecutive_successes = 0\n                        \n                        # Mark unhealthy if enough consecutive failures\n                        if consecutive_failures >= self.health_check_config.failure_threshold:\n                            server.is_healthy = False\n        \n        except Exception as e:\n            consecutive_failures += 1\n            consecutive_successes = 0\n            \n            if consecutive_failures >= self.health_check_config.failure_threshold:\n                server.is_healthy = False\n            \n            self.logger.warning(f\"Health check failed for {server.id}: {e}\")\n        \n        finally:\n            server.consecutive_failures = consecutive_failures\n            server.consecutive_successes = consecutive_successes\n            server.last_health_check = time.time()\n        \n        return server.is_healthy\n    \n    async def _monitor_and_failover(self):\n        \"\"\"Monitor servers and perform failover if needed\"\"\"\n        while True:\n            # Check health of all servers\n            health_tasks = [\n                self._check_server_health(server) \n                for server in (self.primary_servers + self.secondary_servers)\n            ]\n            \n            await asyncio.gather(*health_tasks)\n            \n            # Check if failover is needed\n            await self._evaluate_failover_conditions()\n            \n            await asyncio.sleep(self.health_check_config.interval_seconds)\n    \n    async def _evaluate_failover_conditions(self):\n        \"\"\"Evaluate whether failover is needed\"\"\"\n        healthy_primaries = [s for s in self.primary_servers if s.is_healthy]\n        healthy_secondaries = [s for s in self.secondary_servers if s.is_healthy]\n        \n        if self.strategy == FailoverStrategy.ACTIVE_PASSIVE:\n            # Failover to secondary if no healthy primaries\n            if not healthy_primaries and healthy_secondaries and not self.is_failed_over:\n                await self._perform_failover()\n            \n            # Failback to primary if they're healthy again\n            elif healthy_primaries and self.is_failed_over:\n                await self._perform_failback()\n        \n        # Update active servers\n        self._update_active_servers()\n    \n    async def _perform_failover(self):\n        \"\"\"Perform failover to secondary servers\"\"\"\n        self.is_failed_over = True\n        self.failover_timestamp = datetime.now()\n        \n        self.logger.critical(\"FAILOVER: Switching to secondary servers\")\n        \n        # Notify monitoring systems\n        await self._send_failover_alert(\"Failover to secondary servers initiated\")\n        \n        # Update load balancer configuration\n        self._update_active_servers()\n        \n        # Perform any additional failover tasks\n        await self._execute_failover_hooks()\n    \n    async def _perform_failback(self):\n        \"\"\"Perform failback to primary servers\"\"\"\n        self.logger.info(\"FAILBACK: Primary servers healthy, switching back\")\n        \n        # Wait for a stabilization period\n        await asyncio.sleep(30)  # Wait 30 seconds before failback\n        \n        # Double-check primary health\n        health_tasks = [self._check_server_health(s) for s in self.primary_servers]\n        await asyncio.gather(*health_tasks)\n        \n        healthy_primaries = [s for s in self.primary_servers if s.is_healthy]\n        \n        if healthy_primaries:\n            self.is_failed_over = False\n            self.failover_timestamp = None\n            \n            self.logger.info(\"FAILBACK: Successfully switched back to primary servers\")\n            \n            await self._send_failover_alert(\"Failback to primary servers completed\")\n            self._update_active_servers()\n    \n    async def _send_failover_alert(self, message: str):\n        \"\"\"Send alert about failover events\"\"\"\n        alert_data = {\n            'timestamp': datetime.now().isoformat(),\n            'message': message,\n            'primary_servers_healthy': [s.is_healthy for s in self.primary_servers],\n            'secondary_servers_healthy': [s.is_healthy for s in self.secondary_servers],\n            'is_failed_over': self.is_failed_over\n        }\n        \n        # Send to monitoring system (Slack, email, etc.)\n        self.logger.critical(f\"FAILOVER ALERT: {message}\")\n        print(f\"ALERT: {json.dumps(alert_data, indent=2)}\")\n    \n    async def _execute_failover_hooks(self):\n        \"\"\"Execute custom failover logic\"\"\"\n        # Example: Update DNS records, notify dependent services, etc.\n        hooks = [\n            self._update_dns_records,\n            self._notify_dependent_services,\n            self._scale_up_secondary_resources\n        ]\n        \n        for hook in hooks:\n            try:\n                await hook()\n            except Exception as e:\n                self.logger.error(f\"Failover hook failed: {e}\")\n    \n    async def _update_dns_records(self):\n        \"\"\"Update DNS to point to secondary servers\"\"\"\n        # Implementation would use DNS API (Route53, CloudFlare, etc.)\n        self.logger.info(\"DNS records updated for failover\")\n    \n    async def _notify_dependent_services(self):\n        \"\"\"Notify other services about failover\"\"\"\n        # Send notifications to dependent services\n        self.logger.info(\"Dependent services notified of failover\")\n    \n    async def _scale_up_secondary_resources(self):\n        \"\"\"Scale up secondary infrastructure\"\"\"\n        # Auto-scale secondary resources to handle traffic\n        self.logger.info(\"Secondary resources scaled up\")\n    \n    def _start_monitoring(self):\n        \"\"\"Start health monitoring\"\"\"\n        asyncio.create_task(self._monitor_and_failover())\n    \n    def get_failover_status(self) -> Dict[str, Any]:\n        \"\"\"Get current failover status\"\"\"\n        return {\n            'strategy': self.strategy.value,\n            'is_failed_over': self.is_failed_over,\n            'failover_timestamp': self.failover_timestamp.isoformat() if self.failover_timestamp else None,\n            'active_servers': len(self.current_active_servers),\n            'primary_servers': {\n                'total': len(self.primary_servers),\n                'healthy': len([s for s in self.primary_servers if s.is_healthy])\n            },\n            'secondary_servers': {\n                'total': len(self.secondary_servers),\n                'healthy': len([s for s in self.secondary_servers if s.is_healthy])\n            }\n        }\n\n# Database Failover Example\nclass DatabaseFailoverManager:\n    def __init__(self):\n        self.primary_db = None\n        self.replica_dbs = []\n        self.current_db = None\n        self.is_failed_over = False\n        self.logger = logging.getLogger(__name__)\n    \n    async def setup_database_cluster(self, primary_dsn: str, replica_dsns: List[str]):\n        \"\"\"Setup database cluster with primary and replicas\"\"\"\n        \n        # Connect to primary\n        self.primary_db = await asyncpg.create_pool(primary_dsn, max_size=50)\n        self.current_db = self.primary_db\n        \n        # Connect to replicas\n        for replica_dsn in replica_dsns:\n            replica_pool = await asyncpg.create_pool(replica_dsn, max_size=20)\n            self.replica_dbs.append(replica_pool)\n        \n        # Start health monitoring\n        asyncio.create_task(self._monitor_database_health())\n    \n    async def execute_query(self, query: str, *args, read_only: bool = False) -> Any:\n        \"\"\"Execute query with automatic failover\"\"\"\n        \n        # Use replica for read-only queries if available\n        if read_only and self.replica_dbs:\n            for replica_db in self.replica_dbs:\n                try:\n                    async with replica_db.acquire() as conn:\n                        return await conn.fetch(query, *args)\n                except Exception:\n                    continue\n        \n        # Use current database (primary or failed-over)\n        try:\n            async with self.current_db.acquire() as conn:\n                if read_only:\n                    return await conn.fetch(query, *args)\n                else:\n                    return await conn.execute(query, *args)\n        \n        except Exception as e:\n            self.logger.error(f\"Database query failed: {e}\")\n            \n            # Attempt failover if not already failed over\n            if not self.is_failed_over and self.replica_dbs:\n                await self._perform_database_failover()\n                \n                # Retry query on new primary\n                try:\n                    async with self.current_db.acquire() as conn:\n                        return await conn.execute(query, *args)\n                except Exception as retry_error:\n                    self.logger.error(f\"Query failed even after failover: {retry_error}\")\n                    raise\n            else:\n                raise\n    \n    async def _monitor_database_health(self):\n        \"\"\"Monitor database health and trigger failover\"\"\"\n        while True:\n            try:\n                # Check primary database health\n                async with self.primary_db.acquire() as conn:\n                    await conn.execute(\"SELECT 1\")\n                    \n                # Primary is healthy\n                if self.is_failed_over:\n                    self.logger.info(\"Primary database recovered, considering failback...\")\n                    # Implement failback logic here\n            \n            except Exception as e:\n                self.logger.warning(f\"Primary database health check failed: {e}\")\n                \n                if not self.is_failed_over:\n                    await self._perform_database_failover()\n            \n            await asyncio.sleep(10)  # Check every 10 seconds\n    \n    async def _perform_database_failover(self):\n        \"\"\"Perform database failover\"\"\"\n        if not self.replica_dbs:\n            self.logger.error(\"No replica databases available for failover\")\n            return\n        \n        self.logger.critical(\"Performing database failover...\")\n        \n        # Find healthiest replica\n        best_replica = None\n        \n        for replica_db in self.replica_dbs:\n            try:\n                async with replica_db.acquire() as conn:\n                    await conn.execute(\"SELECT 1\")\n                    best_replica = replica_db\n                    break\n            except Exception:\n                continue\n        \n        if best_replica:\n            self.current_db = best_replica\n            self.is_failed_over = True\n            self.logger.critical(\"Database failover completed\")\n            \n            # In production, promote replica to primary\n            await self._promote_replica_to_primary(best_replica)\n        else:\n            self.logger.error(\"No healthy replica found for failover\")\n    \n    async def _promote_replica_to_primary(self, replica_db):\n        \"\"\"Promote replica to primary (PostgreSQL example)\"\"\"\n        # This would typically involve:\n        # 1. Stop replication on the replica\n        # 2. Update application configuration\n        # 3. Update DNS/load balancer\n        # 4. Notify monitoring systems\n        \n        self.logger.info(\"Promoted replica to primary role\")\n\n# Load Balancer with Failover\nclass HighAvailabilityLoadBalancer:\n    def __init__(self):\n        self.load_balancer = AdvancedLoadBalancer(RoundRobinAlgorithm())\n        self.failover_manager = FailoverManager(FailoverStrategy.ACTIVE_PASSIVE)\n        self.logger = logging.getLogger(__name__)\n    \n    async def setup_ha_cluster(self, primary_servers: List[tuple], secondary_servers: List[tuple]):\n        \"\"\"Setup high availability cluster\"\"\"\n        \n        # Add primary servers\n        for host, port in primary_servers:\n            self.load_balancer.add_server(host, port)\n            self.failover_manager.add_primary_server(host, port)\n        \n        # Add secondary servers\n        for host, port in secondary_servers:\n            self.failover_manager.add_secondary_server(host, port)\n        \n        self.logger.info(\"HA cluster setup completed\")\n    \n    async def handle_request(self, request_data: Dict[str, Any], client_ip: str) -> Optional[str]:\n        \"\"\"Handle request with HA support\"\"\"\n        \n        # Update load balancer servers based on failover status\n        active_servers = self.failover_manager.current_active_servers\n        self.load_balancer.servers = active_servers\n        \n        # Route request\n        response = await self.load_balancer.route_request(request_data, client_ip)\n        \n        # Handle response\n        if response is None:\n            # All servers failed, emergency response\n            return await self._handle_total_failure()\n        \n        return response\n    \n    async def _handle_total_failure(self) -> str:\n        \"\"\"Handle complete system failure\"\"\"\n        self.logger.critical(\"Total system failure - all servers unavailable\")\n        \n        # Return maintenance page\n        return json.dumps({\n            \"error\": \"Service temporarily unavailable\",\n            \"message\": \"We're working to restore service. Please try again in a few minutes.\",\n            \"status\": \"maintenance\",\n            \"retry_after\": 300  # 5 minutes\n        })\n```\n\n---\n\n## üèóÔ∏è Real-World High Availability Implementations {#real-world}\n\n### AWS High Availability Setup\n\n```python\nimport boto3\nimport json\nimport time\nfrom typing import Dict, List, Any, Optional\n\nclass AWSHighAvailabilityStack:\n    def __init__(self, region: str = 'us-east-1'):\n        self.region = region\n        self.ec2 = boto3.client('ec2', region_name=region)\n        self.elb = boto3.client('elbv2', region_name=region)\n        self.autoscaling = boto3.client('autoscaling', region_name=region)\n        self.route53 = boto3.client('route53')\n        self.cloudwatch = boto3.client('cloudwatch', region_name=region)\n        \n    def create_multi_az_infrastructure(self):\n        \"\"\"Create multi-AZ infrastructure for high availability\"\"\"\n        \n        # 1. Create VPC across multiple Availability Zones\n        vpc_config = {\n            \"CidrBlock\": \"10.0.0.0/16\",\n            \"EnableDnsHostnames\": True,\n            \"EnableDnsSupport\": True\n        }\n        \n        # 2. Create subnets in different AZs\n        availability_zones = ['us-east-1a', 'us-east-1b', 'us-east-1c']\n        \n        subnet_configs = []\n        for i, az in enumerate(availability_zones):\n            subnet_configs.append({\n                \"AvailabilityZone\": az,\n                \"CidrBlock\": f\"10.0.{i+1}.0/24\",\n                \"MapPublicIpOnLaunch\": True\n            })\n        \n        # 3. Create Application Load Balancer\n        alb_config = {\n            \"Name\": \"ha-app-loadbalancer\",\n            \"Scheme\": \"internet-facing\",\n            \"Type\": \"application\",\n            \"IpAddressType\": \"ipv4\",\n            \"Subnets\": [],  # Subnet IDs from above\n            \"SecurityGroups\": []  # Security group IDs\n        }\n        \n        # 4. Create Auto Scaling Group\n        autoscaling_config = {\n            \"AutoScalingGroupName\": \"ha-app-asg\",\n            \"MinSize\": 2,\n            \"MaxSize\": 10,\n            \"DesiredCapacity\": 3,\n            \"HealthCheckType\": \"ELB\",\n            \"HealthCheckGracePeriod\": 300,\n            \"DefaultCooldown\": 300,\n            \"AvailabilityZones\": availability_zones\n        }\n        \n        return {\n            \"vpc_config\": vpc_config,\n            \"subnet_configs\": subnet_configs,\n            \"alb_config\": alb_config,\n            \"autoscaling_config\": autoscaling_config\n        }\n    \n    def setup_health_checks_and_scaling(self):\n        \"\"\"Setup comprehensive health checks and auto-scaling\"\"\"\n        \n        # Health check configuration\n        health_check_config = {\n            \"HealthCheckIntervalSeconds\": 30,\n            \"HealthCheckPath\": \"/health\",\n            \"HealthCheckProtocol\": \"HTTP\",\n            \"HealthCheckTimeoutSeconds\": 5,\n            \"HealthyThresholdCount\": 2,\n            \"UnhealthyThresholdCount\": 3,\n            \"Matcher\": {\"HttpCode\": \"200\"}\n        }\n        \n        # Auto-scaling policies\n        scaling_policies = [\n            {\n                \"PolicyName\": \"scale-up-cpu\",\n                \"PolicyType\": \"TargetTrackingScaling\",\n                \"TargetTrackingScalingPolicies\": {\n                    \"TargetValue\": 70.0,  # 70% CPU utilization\n                    \"PredefinedMetricSpecification\": {\n                        \"PredefinedMetricType\": \"ASGAverageCPUUtilization\"\n                    },\n                    \"ScaleOutCooldown\": 300,\n                    \"ScaleInCooldown\": 300\n                }\n            },\n            {\n                \"PolicyName\": \"scale-up-requests\",\n                \"PolicyType\": \"TargetTrackingScaling\", \n                \"TargetTrackingScalingPolicies\": {\n                    \"TargetValue\": 1000.0,  # 1000 requests per target\n                    \"PredefinedMetricSpecification\": {\n                        \"PredefinedMetricType\": \"ALBRequestCountPerTarget\"\n                    }\n                }\n            }\n        ]\n        \n        return {\n            \"health_check\": health_check_config,\n            \"scaling_policies\": scaling_policies\n        }\n    \n    def create_multi_region_setup(self):\n        \"\"\"Create multi-region setup with Route53\"\"\"\n        \n        # Route53 health checks and failover\n        route53_config = {\n            \"HostedZoneId\": \"your-hosted-zone-id\",\n            \"RecordSets\": [\n                {\n                    \"Name\": \"api.example.com\",\n                    \"Type\": \"A\",\n                    \"SetIdentifier\": \"us-east-1\",\n                    \"Failover\": \"PRIMARY\",\n                    \"AliasTarget\": {\n                        \"DNSName\": \"us-east-1-alb.elb.amazonaws.com\",\n                        \"EvaluateTargetHealth\": True\n                    },\n                    \"HealthCheckId\": \"health-check-us-east-1\"\n                },\n                {\n                    \"Name\": \"api.example.com\", \n                    \"Type\": \"A\",\n                    \"SetIdentifier\": \"us-west-2\",\n                    \"Failover\": \"SECONDARY\",\n                    \"AliasTarget\": {\n                        \"DNSName\": \"us-west-2-alb.elb.amazonaws.com\",\n                        \"EvaluateTargetHealth\": True\n                    },\n                    \"HealthCheckId\": \"health-check-us-west-2\"\n                }\n            ]\n        }\n        \n        return route53_config\n\n# Kubernetes High Availability\nclass KubernetesHAManager:\n    def __init__(self, kubectl_config: str):\n        self.kubectl_config = kubectl_config\n        \n    def create_ha_deployment_manifests(self):\n        \"\"\"Create Kubernetes manifests for HA deployment\"\"\"\n        \n        # 1. Deployment with multiple replicas and anti-affinity\n        deployment_manifest = {\n            \"apiVersion\": \"apps/v1\",\n            \"kind\": \"Deployment\", \n            \"metadata\": {\n                \"name\": \"ha-web-app\",\n                \"labels\": {\"app\": \"web-app\"}\n            },\n            \"spec\": {\n                \"replicas\": 3,\n                \"selector\": {\"matchLabels\": {\"app\": \"web-app\"}},\n                \"template\": {\n                    \"metadata\": {\"labels\": {\"app\": \"web-app\"}},\n                    \"spec\": {\n                        # Pod anti-affinity for distribution across nodes\n                        \"affinity\": {\n                            \"podAntiAffinity\": {\n                                \"preferredDuringSchedulingIgnoredDuringExecution\": [\n                                    {\n                                        \"weight\": 100,\n                                        \"podAffinityTerm\": {\n                                            \"labelSelector\": {\n                                                \"matchExpressions\": [\n                                                    {\n                                                        \"key\": \"app\",\n                                                        \"operator\": \"In\",\n                                                        \"values\": [\"web-app\"]\n                                                    }\n                                                ]\n                                            },\n                                            \"topologyKey\": \"kubernetes.io/hostname\"\n                                        }\n                                    }\n                                ]\n                            }\n                        },\n                        \"containers\": [\n                            {\n                                \"name\": \"web-app\",\n                                \"image\": \"my-app:latest\",\n                                \"ports\": [{\"containerPort\": 8080}],\n                                \"resources\": {\n                                    \"requests\": {\n                                        \"memory\": \"256Mi\",\n                                        \"cpu\": \"250m\"\n                                    },\n                                    \"limits\": {\n                                        \"memory\": \"512Mi\", \n                                        \"cpu\": \"500m\"\n                                    }\n                                },\n                                \"livenessProbe\": {\n                                    \"httpGet\": {\n                                        \"path\": \"/health\",\n                                        \"port\": 8080\n                                    },\n                                    \"initialDelaySeconds\": 30,\n                                    \"periodSeconds\": 10\n                                },\n                                \"readinessProbe\": {\n                                    \"httpGet\": {\n                                        \"path\": \"/ready\",\n                                        \"port\": 8080\n                                    },\n                                    \"initialDelaySeconds\": 5,\n                                    \"periodSeconds\": 5\n                                }\n                            }\n                        ]\n                    }\n                }\n            }\n        }\n        \n        # 2. Service for load balancing\n        service_manifest = {\n            \"apiVersion\": \"v1\",\n            \"kind\": \"Service\",\n            \"metadata\": {\n                \"name\": \"ha-web-app-service\"\n            },\n            \"spec\": {\n                \"selector\": {\"app\": \"web-app\"},\n                \"ports\": [\n                    {\n                        \"protocol\": \"TCP\",\n                        \"port\": 80,\n                        \"targetPort\": 8080\n                    }\n                ],\n                \"type\": \"ClusterIP\"\n            }\n        }\n        \n        # 3. Horizontal Pod Autoscaler\n        hpa_manifest = {\n            \"apiVersion\": \"autoscaling/v2\",\n            \"kind\": \"HorizontalPodAutoscaler\",\n            \"metadata\": {\n                \"name\": \"ha-web-app-hpa\"\n            },\n            \"spec\": {\n                \"scaleTargetRef\": {\n                    \"apiVersion\": \"apps/v1\",\n                    \"kind\": \"Deployment\",\n                    \"name\": \"ha-web-app\"\n                },\n                \"minReplicas\": 3,\n                \"maxReplicas\": 20,\n                \"metrics\": [\n                    {\n                        \"type\": \"Resource\",\n                        \"resource\": {\n                            \"name\": \"cpu\",\n                            \"target\": {\n                                \"type\": \"Utilization\",\n                                \"averageUtilization\": 70\n                            }\n                        }\n                    },\n                    {\n                        \"type\": \"Resource\", \n                        \"resource\": {\n                            \"name\": \"memory\",\n                            \"target\": {\n                                \"type\": \"Utilization\",\n                                \"averageUtilization\": 80\n                            }\n                        }\n                    }\n                ]\n            }\n        }\n        \n        return {\n            \"deployment\": deployment_manifest,\n            \"service\": service_manifest,\n            \"hpa\": hpa_manifest\n        }\n\n# Complete HA Example\nasync def ha_example():\n    \"\"\"Complete high availability example\"\"\"\n    \n    # Create load balancer\n    lb = AdvancedLoadBalancer(WeightedRoundRobinAlgorithm())\n    \n    # Add servers with different weights\n    lb.add_server(\"192.168.1.10\", 8080, weight=3)  # More powerful server\n    lb.add_server(\"192.168.1.11\", 8080, weight=2)\n    lb.add_server(\"192.168.1.12\", 8080, weight=1)\n    \n    # Setup failover\n    failover_manager = FailoverManager(FailoverStrategy.ACTIVE_PASSIVE)\n    \n    # Add primary and secondary servers\n    failover_manager.add_primary_server(\"192.168.1.10\", 8080)\n    failover_manager.add_primary_server(\"192.168.1.11\", 8080)\n    \n    failover_manager.add_secondary_server(\"192.168.1.20\", 8080)\n    failover_manager.add_secondary_server(\"192.168.1.21\", 8080)\n    \n    # Setup database failover\n    db_failover = DatabaseFailoverManager()\n    await db_failover.setup_database_cluster(\n        primary_dsn=\"postgresql://primary:5432/db\",\n        replica_dsns=[\n            \"postgresql://replica1:5432/db\",\n            \"postgresql://replica2:5432/db\"\n        ]\n    )\n    \n    # Setup session management\n    session_manager = SessionManager(strategy=\"redis\")\n    \n    # Simulate load for 30 seconds\n    print(\"Running HA system simulation...\")\n    \n    for i in range(30):\n        # Simulate multiple concurrent requests\n        tasks = []\n        \n        for j in range(10):  # 10 concurrent requests\n            request_data = {\n                'user_id': f'user_{j}',\n                'action': 'get_data',\n                'timestamp': time.time()\n            }\n            \n            task = lb.route_request(request_data, f'192.168.1.{100 + j}')\n            tasks.append(task)\n        \n        # Execute requests\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        # Count successes and failures\n        successes = sum(1 for r in results if r is not None and not isinstance(r, Exception))\n        failures = len(results) - successes\n        \n        print(f\"Second {i+1}: {successes} successful, {failures} failed requests\")\n        \n        await asyncio.sleep(1)\n    \n    # Print final status\n    status = lb.get_status()\n    failover_status = failover_manager.get_failover_status()\n    \n    print(f\"\\nFinal Load Balancer Status: {json.dumps(status, indent=2)}\")\n    print(f\"Final Failover Status: {json.dumps(failover_status, indent=2)}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(ha_example())\n```\n\n---\n\n## üéØ Best Practices Summary {#best-practices}\n\n### High Availability Checklist\n- ‚úÖ **Multiple Availability Zones**: Deploy across different AZs/regions\n- ‚úÖ **Auto-scaling**: Configure horizontal and vertical scaling\n- ‚úÖ **Health Checks**: Implement comprehensive health monitoring\n- ‚úÖ **Circuit Breakers**: Prevent cascading failures\n- ‚úÖ **Graceful Degradation**: Maintain core functionality during failures\n- ‚úÖ **Database Replication**: Master-slave or master-master setup\n- ‚úÖ **Load Balancing**: Distribute traffic effectively\n- ‚úÖ **Disaster Recovery**: Regular backups and recovery procedures\n\n### Load Balancing Best Practices\n- ‚úÖ **Choose Right Algorithm**: Based on application characteristics\n- ‚úÖ **Health Monitoring**: Regular health checks with proper thresholds\n- ‚úÖ **Session Handling**: Stateless design or proper session management\n- ‚úÖ **SSL Termination**: Handle SSL at load balancer level\n- ‚úÖ **Rate Limiting**: Implement per-client rate limiting\n- ‚úÖ **Monitoring & Alerting**: Track performance and availability metrics\n- ‚úÖ **Regular Testing**: Practice failover scenarios\n- ‚úÖ **Documentation**: Maintain runbooks for common scenarios\n\n### Disaster Recovery Planning\n1. **RTO (Recovery Time Objective)**: Maximum acceptable downtime\n2. **RPO (Recovery Point Objective)**: Maximum acceptable data loss\n3. **Backup Strategy**: Regular automated backups with testing\n4. **Failover Procedures**: Documented and practiced procedures\n5. **Communication Plan**: Stakeholder notification procedures\n\n---\n\n## üèÜ Congratulations!\n\nYou now have comprehensive knowledge of:\n\n- ‚úÖ **Load Balancing**: All algorithms, types, and implementations\n- ‚úÖ **High Availability**: Failover strategies and architectures  \n- ‚úÖ **Session Management**: Stateless, sticky, and distributed approaches\n- ‚úÖ **Real-World Implementations**: AWS, Kubernetes, and custom solutions\n- ‚úÖ **Monitoring & Recovery**: Health checks, disaster recovery, and best practices\n\n**Career Impact**: These skills are essential for:\n- **DevOps Engineer** roles ($90k-150k)\n- **Site Reliability Engineer** positions ($120k-200k)\n- **Solutions Architect** roles ($130k-250k)\n- **Principal Engineer** positions ($200k+)\n\nKeep building resilient, scalable systems! üöÄ‚ö°\n\n---\n\n*\"Availability is not just about keeping systems running; it's about ensuring business continuity and customer trust.\"*\n\nBuild systems that never sleep! üí™üåü"}